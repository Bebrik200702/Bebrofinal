{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756740a8-b71a-42a3-88ec-442e2b30e9c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:21.927570Z",
     "iopub.status.busy": "2024-10-06T14:52:21.927051Z",
     "iopub.status.idle": "2024-10-06T14:52:27.202599Z",
     "shell.execute_reply": "2024-10-06T14:52:27.201991Z",
     "shell.execute_reply.started": "2024-10-06T14:52:21.927549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from src import CustomClassifierEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GroupKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import rankdata\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import get_cosine_schedule_with_warmup,get_linear_schedule_with_warmup, AutoModel, AutoTokenizer, AutoModelForMultipleChoice, AutoConfig\n",
    "import wandb\n",
    "pl.seed_everything(56)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94cc50a-c29b-4368-8a7a-d40bf38a83c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea67ea5eaf8403c98d450bef9b156ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for gemma 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\n",
    "# for llama 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\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731f98cf-68d7-441b-bac4-267a8bf2d1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.203908Z",
     "iopub.status.busy": "2024-10-06T14:52:27.203685Z",
     "iopub.status.idle": "2024-10-06T14:52:27.211833Z",
     "shell.execute_reply": "2024-10-06T14:52:27.211290Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.203898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    class data:\n",
    "        train_path = 'train.csv'\n",
    "        test_path = 'test.csv'\n",
    "        tokenizer = 'BAAI/bge-multilingual-gemma2'#'microsoft/mdeberta-v3-base'\n",
    "        num_workers = 8\n",
    "        nfolds = 5\n",
    "        batch_size = 4\n",
    "        use_prefix = False\n",
    "        max_length = 105 \n",
    "        seed = 56\n",
    "    class model:\n",
    "        model = 'BAAI/bge-multilingual-gemma2'#'microsoft/mdeberta-v3-base'\n",
    "        optim = torch.optim.AdamW\n",
    "        use_only_encoder=False\n",
    "        grad_acum_steps = 1\n",
    "        torch_dtype = torch.bfloat16\n",
    "        scheduler= 'cosine'\n",
    "        warnap_steps = 0.0 #0.25\n",
    "        num_labels = 50\n",
    "        label_smoothing = 0.0\n",
    "        lr = lr_fn = 1e-5 #1e-4\n",
    "        cls_drop_type = None\n",
    "        cls_drop = 0.0\n",
    "        pool = 'last_token'\n",
    "        max_epoches = 10\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        turn_off_drop = True\n",
    "        num_cycles = 0.5\n",
    "        eps = 1e-7\n",
    "        weight_decay = 0.0\n",
    "        weight_decay_fn = 0.0\n",
    "        betas = (0.9, 0.999)\n",
    "        use_lora = True\n",
    "        class lora:\n",
    "            r = 64\n",
    "            lora_alpha = 128\n",
    "            lora_dropout = 0.05\n",
    "            bias = 'none'\n",
    "            use_dora = False\n",
    "            target_modules = ['down_proj','o_proj','k_proj','q_proj','gate_proj','up_proj','v_proj']\n",
    "            layers_to_transform = None#list(range(42))\n",
    "\n",
    "    seed = 56\n",
    "    fold_number = 0\n",
    "\n",
    "def set_wandb_cfg():\n",
    "    config = {}\n",
    "    for k,v in CFG.model.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    for k,v in CFG.data.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    config['fold_number'] = CFG.fold_number\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a4057d-e5b9-4a3c-a997-ffd24219ba3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.212989Z",
     "iopub.status.busy": "2024-10-06T14:52:27.212810Z",
     "iopub.status.idle": "2024-10-06T14:52:27.220367Z",
     "shell.execute_reply": "2024-10-06T14:52:27.219954Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.212972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(path,is_test=False):\n",
    "    data = pd.read_csv(path)\n",
    "    df = pd.DataFrame()\n",
    "    if is_test:\n",
    "        df['label'] = [[0] * 50] * len(df)\n",
    "    else:\n",
    "        df['label'] = data.apply(lambda x: [x[f'trend_id_res{i}'] for i in range(50)],axis=1)\n",
    "    df['text'] = data['text']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea959bbb-4502-4489-b1b7-e29dc320e827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.221706Z",
     "iopub.status.busy": "2024-10-06T14:52:27.221411Z",
     "iopub.status.idle": "2024-10-06T14:52:27.225555Z",
     "shell.execute_reply": "2024-10-06T14:52:27.225212Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.221706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]        \n",
    "        \n",
    "        encodes = self.tokenizer.encode_plus(\n",
    "            row['text'],\n",
    "            max_length=self.cfg.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encodes.input_ids.squeeze(0),\n",
    "            'attention_mask': encodes.attention_mask.squeeze(0),\n",
    "            #'token_type_ids': encodes.token_type_ids.squeeze(0),\n",
    "            'labels': torch.tensor(row['label'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa988de6-c9e1-4deb-b61e-ef6f0c78f7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.226647Z",
     "iopub.status.busy": "2024-10-06T14:52:27.226114Z",
     "iopub.status.idle": "2024-10-06T14:52:27.232359Z",
     "shell.execute_reply": "2024-10-06T14:52:27.232000Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.226632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.is_setup = False\n",
    "        self.is_prepared = False\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        if self.is_prepared: return None\n",
    "        self.df = make_df(self.cfg.train_path)\n",
    "        self.test_df = make_df(self.cfg.test_path,is_test=True)\n",
    "        self.test_df['text'] = self.test_df['text'].fillna('')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg.tokenizer)\n",
    "        self.is_prepared = True\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup: return None\n",
    "        kf = MultilabelStratifiedKFold(n_splits=self.cfg.nfolds, shuffle=True, random_state=self.cfg.seed)\n",
    "        splits = [(x,y) for x,y in  kf.split(self.df.values,np.stack(dm.df['label'].values))][CFG.fold_number]\n",
    "        self.train_df, self.val_df = self.df.iloc[splits[0]], self.df.iloc[splits[1]]\n",
    "        self.train_dataset = PLDataset(self.train_df,self.tokenizer)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.tokenizer)\n",
    "        self.predict_dataset = PLDataset(self.test_df,self.tokenizer)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                         batch_size=self.cfg.batch_size,\n",
    "                         num_workers=self.cfg.num_workers,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "699f4a09-f9d3-4f3e-b062-2d1487142ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.233412Z",
     "iopub.status.busy": "2024-10-06T14:52:27.232902Z",
     "iopub.status.idle": "2024-10-06T14:52:27.237484Z",
     "shell.execute_reply": "2024-10-06T14:52:27.237189Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.233412Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.history = []\n",
    "    \n",
    "    def update(self,y_t,y_p):\n",
    "        self.labels += y_t\n",
    "        self.preds += y_p\n",
    "        \n",
    "    def clean(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        metrics = {}\n",
    "\n",
    "        preds = [list(map(lambda y: str(round(y)),x)) for x in self.preds]\n",
    "        labels = [''.join(map(str,x)) for x in self.labels]\n",
    "        for i in range(len(self.preds)):\n",
    "            preds[i][np.argmax(self.preds[i])] = '1'\n",
    "        preds = [''.join(x) for x in preds]\n",
    "        \n",
    "        metrics['accuracy'] = accuracy_score(labels, preds)\n",
    "        self.history.append(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f08e127-e05a-408d-9fa6-7fe4ab7e157e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.238572Z",
     "iopub.status.busy": "2024-10-06T14:52:27.238049Z",
     "iopub.status.idle": "2024-10-06T14:52:27.246748Z",
     "shell.execute_reply": "2024-10-06T14:52:27.246402Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.238547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.model = CustomClassifierEncoder(self.cfg)\n",
    "        self.avg_meter = AverageMeter()\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        output = self.model(**batch)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, i):\n",
    "        logits = self(batch).logits\n",
    "        loss = self.criterion(logits, batch['labels'].float())\n",
    "        self.log('train_loss', loss.item())\n",
    "        return loss\n",
    "            \n",
    "    def validation_step(self, batch, i):\n",
    "        logits = self(batch).logits\n",
    "        loss = self.criterion(logits, batch['labels'].float())\n",
    "        self.log('val_loss',loss.item())\n",
    "        \n",
    "        preds = logits.sigmoid().tolist()\n",
    "        labels = batch['labels'].tolist()\n",
    "        \n",
    "        self.avg_meter.update(labels,preds)\n",
    "    \n",
    "    def predict_step(self, batch, i):\n",
    "        logits = self(batch).logits\n",
    "        return logits.sigmoid().tolist()\n",
    "                \n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.avg_meter.calc_metrics()\n",
    "        self.log_dict(metrics)\n",
    "        self.avg_meter.clean()\n",
    "            \n",
    "    def configure_optimizers(self):        \n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in self.model.model.named_parameters() if not any(nd in n for nd in self.cfg.no_decay)],\n",
    "             'lr': self.cfg.lr, 'weight_decay': self.cfg.weight_decay},\n",
    "            {'params': [p for n, p in self.model.model.named_parameters() if any(nd in n for nd in self.cfg.no_decay)],\n",
    "             'lr': self.cfg.lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if \"model\" not in n],\n",
    "             'lr': self.cfg.lr_fn, 'weight_decay': self.cfg.weight_decay_fn}\n",
    "        ]\n",
    "        \n",
    "        optim = self.cfg.optim(\n",
    "            optimizer_parameters,\n",
    "            lr=self.cfg.lr,\n",
    "            betas=self.cfg.betas,\n",
    "            weight_decay=self.cfg.weight_decay,\n",
    "            eps=self.cfg.eps\n",
    "        )\n",
    "        \n",
    "        if self.cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warnap_steps,\n",
    "                                                        num_cycles=self.cfg.num_cycles)\n",
    "        elif self.cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warnap_steps)\n",
    "        else:\n",
    "            return optim\n",
    "        \n",
    "        scheduler = {'scheduler': scheduler,'interval': 'step', 'frequency': 1}\n",
    "\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c56345f-a659-4ccd-bb1b-f716b4f8129a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:27.703473Z",
     "iopub.status.busy": "2024-10-06T14:52:27.702804Z",
     "iopub.status.idle": "2024-10-06T14:52:29.886150Z",
     "shell.execute_reply": "2024-10-06T14:52:29.885686Z",
     "shell.execute_reply.started": "2024-10-06T14:52:27.703448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b578175f7f48b188abc7008ec469d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfa8d21448a4a038d0b5e0ca11d3544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862d0f001e8d43de81cf22077e084fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b03322ad76644f0b104773fd483bfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "971ca6d2-7982-4728-b2f8-f2d742f06afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:29.889266Z",
     "iopub.status.busy": "2024-10-06T14:52:29.888641Z",
     "iopub.status.idle": "2024-10-06T14:52:29.891630Z",
     "shell.execute_reply": "2024-10-06T14:52:29.891256Z",
     "shell.execute_reply.started": "2024-10-06T14:52:29.889238Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dm.tokenizer.pad_token = dm.tokenizer.eos_token\n",
    "dm.tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c155de9-3dd1-4f46-8e17-cdc753fe33de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:30.027594Z",
     "iopub.status.busy": "2024-10-06T14:52:30.027052Z",
     "iopub.status.idle": "2024-10-06T14:52:30.030439Z",
     "shell.execute_reply": "2024-10-06T14:52:30.030025Z",
     "shell.execute_reply.started": "2024-10-06T14:52:30.027557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG.model.num_training_steps = len(dm.train_dataloader()) * CFG.model.max_epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5f61db-2177-4602-b86c-2172ac96721b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:52:30.463318Z",
     "iopub.status.busy": "2024-10-06T14:52:30.462896Z",
     "iopub.status.idle": "2024-10-06T14:55:16.336520Z",
     "shell.execute_reply": "2024-10-06T14:55:16.335929Z",
     "shell.execute_reply.started": "2024-10-06T14:52:30.463318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689ac14b1bdb47178a4867112b437ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for BAAI/bge-reranker-v2.5-gemma2-lightweight contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/BAAI/bge-reranker-v2.5-gemma2-lightweight.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9742987db5574bbdb8df975f94a33ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gemma_config.py:   0%|          | 0.00/3.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight:\n",
      "- gemma_config.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for BAAI/bge-reranker-v2.5-gemma2-lightweight contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/BAAI/bge-reranker-v2.5-gemma2-lightweight.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10724612f9d742d1b093af57af7effec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gemma_model.py:   0%|          | 0.00/35.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight:\n",
      "- gemma_model.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dbc0b5b4aa41a99e582bd8b5f4bfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/41.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de458595770416f9cbcc1d227849c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1f81420d954cc793f052a08f814a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/9.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea27dcf9c1084a1e9592cd316ce68b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dae2afcbd947ce9de466f7e3594196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/9.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35592c77acbd48ddaaacc5d7a02e202f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/7.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027530650ad84c7bba95a00800ce2a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PLModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38db5475-ff4b-4d4d-9433-22005ad8b89b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:55:16.338905Z",
     "iopub.status.busy": "2024-10-06T14:55:16.338766Z",
     "iopub.status.idle": "2024-10-06T14:55:17.560935Z",
     "shell.execute_reply": "2024-10-06T14:55:17.560503Z",
     "shell.execute_reply.started": "2024-10-06T14:55:16.338890Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewkhl\u001b[0m (\u001b[33mandlh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20241006_145517-h2tzlhu8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/DLS/runs/h2tzlhu8' target=\"_blank\">BAAI/bge-reranker-v2.5-gemma2-lightweight</a></strong> to <a href='https://wandb.ai/andlh/DLS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/DLS' target=\"_blank\">https://wandb.ai/andlh/DLS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/DLS/runs/h2tzlhu8' target=\"_blank\">https://wandb.ai/andlh/DLS/runs/h2tzlhu8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andlh/DLS/runs/h2tzlhu8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8ef37f3ad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"31520b01739d418e5d77a11fd8a79a70b189b8bc\")\n",
    "os.environ['WANDB_API_KEY'] = \"31520b01739d418e5d77a11fd8a79a70b189b8bc\"\n",
    "wandb.init(project='DLS',name='BAAI/bge-reranker-v2.5-gemma2-lightweight',config=set_wandb_cfg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475c92bd-c501-4f74-b67f-207edf15cff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:55:17.563179Z",
     "iopub.status.busy": "2024-10-06T14:55:17.563035Z",
     "iopub.status.idle": "2024-10-06T14:55:17.585374Z",
     "shell.execute_reply": "2024-10-06T14:55:17.584928Z",
     "shell.execute_reply.started": "2024-10-06T14:55:17.563164Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:571: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs/',\n",
    "    filename='model_{epoch:02d}-{accuracy:.4f}',\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision='bf16',\n",
    "    callbacks = [lr_monitor],\n",
    "    logger = pl.loggers.WandbLogger(save_code=True),\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=CFG.model.grad_acum_steps,\n",
    "    enable_checkpointing=False,\n",
    "    min_epochs=1,\n",
    "    devices=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=CFG.model.max_epoches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66647b8c-fc77-46ce-92f7-e535a54ca8c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:55:17.587302Z",
     "iopub.status.busy": "2024-10-06T14:55:17.587172Z",
     "iopub.status.idle": "2024-10-06T16:03:17.911725Z",
     "shell.execute_reply": "2024-10-06T16:03:17.911161Z",
     "shell.execute_reply.started": "2024-10-06T14:55:17.587289Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                    | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model     | CustomClassifierEncoder | 9.5 B  | train\n",
      "1 | criterion | BCEWithLogitsLoss       | 0      | train\n",
      "--------------------------------------------------------------\n",
      "216 M     Trainable params\n",
      "9.2 B     Non-trainable params\n",
      "9.5 B     Total params\n",
      "37,831.830Total estimated model params size (MB)\n",
      "2947      Modules in train mode\n",
      "676       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0613fe30435439eac6215df9395f17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c769a50cdf349c386576b28d8810f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8dbe2b707a46f8bd2356aaf7de8f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c321a75d41448b7afd37e90eb7cc167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1010a40a370a4aacae41378868f8e567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3febe13f1c0d468e831d82a876f130d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036abbb2c17c47dcb94f63c00876783c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93306a2d9582439f984cfc142ecdc895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7ebeb6814b40cb8ec05ac0a0887b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38b222792a941279509011532c55f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cf3e4995654488a0d3d0ca3f803d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d588bf296974555bffea741e020c121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db3d428-4d3d-40bb-98e5-e376492da049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:03:17.914873Z",
     "iopub.status.busy": "2024-10-06T16:03:17.914518Z",
     "iopub.status.idle": "2024-10-06T16:04:12.887673Z",
     "shell.execute_reply": "2024-10-06T16:04:12.887145Z",
     "shell.execute_reply.started": "2024-10-06T16:03:17.914852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47568c4578c9498b87ac3505518f7f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_val = trainer.predict(model,dm.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e1fbf3b-4cbb-4812-a755-11bf4a7cd9e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:04:12.890179Z",
     "iopub.status.busy": "2024-10-06T16:04:12.890027Z",
     "iopub.status.idle": "2024-10-06T16:10:24.715674Z",
     "shell.execute_reply": "2024-10-06T16:10:24.715041Z",
     "shell.execute_reply.started": "2024-10-06T16:04:12.890158Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b767b1991c841dcad022adb2237f722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_test = trainer.predict(model,dm.predict_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78642b43-9845-46af-a55e-e8f2dbb9d716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"BAAI-bge-multilingual-gemma2-val-fold_attn_lrnk-0.npy\",np.concatenate(preds_val))\n",
    "np.save(\"BAAI/bge-multilingual-gemma2-test-fold_attnlrnk-0.npy\",np.concatenate(preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "763cefbd-0be9-488a-99e7-6ce8eaab5184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:27:50.961632Z",
     "iopub.status.busy": "2024-10-06T14:27:50.961011Z",
     "iopub.status.idle": "2024-10-06T14:27:50.971261Z",
     "shell.execute_reply": "2024-10-06T14:27:50.969257Z",
     "shell.execute_reply.started": "2024-10-06T14:27:50.961608Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_predict(pred):\n",
    "    preds_r = list(map(lambda y: str(round(y)),pred))\n",
    "    preds_r[np.argmax(pred)] = '1'\n",
    "    return ' '.join([str(i) for i,x in enumerate(preds_r) if x == '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e1854f0-29c6-43ee-b0de-5a6180c4752e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_pr = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe078051-2555-4e7f-904f-dbdd7cc07a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35973096e-07, 9.92187500e-01, 1.00000000e+00, 1.47223473e-05,\n",
       "       4.50015068e-06, 3.46451998e-07, 9.53674316e-06, 1.04773790e-08,\n",
       "       3.12328339e-05, 2.14576721e-05, 4.04357910e-04, 3.93018126e-07,\n",
       "       9.60937500e-01, 1.52504072e-08, 5.14984131e-05, 3.52859497e-05,\n",
       "       6.34463504e-09, 6.89178705e-07, 4.94765118e-09, 1.04773790e-08,\n",
       "       1.18743628e-08, 2.11596489e-06, 5.69969416e-07, 3.25962901e-07,\n",
       "       3.84170562e-09, 6.00703061e-08, 3.25962901e-07, 2.72691250e-06,\n",
       "       3.25962901e-07, 1.20699406e-06, 1.29938126e-05, 2.23517418e-07,\n",
       "       4.50015068e-06, 1.44354999e-07, 6.89178705e-07, 3.29315662e-06,\n",
       "       1.66992188e-01, 5.78165054e-06, 4.45172191e-07, 1.44354999e-07,\n",
       "       5.36441803e-07, 8.58562998e-10, 9.53674316e-06, 6.84522092e-08,\n",
       "       2.99769454e-09, 7.72997737e-08, 3.25962901e-07, 2.11596489e-06,\n",
       "       1.52504072e-08, 6.48200512e-07])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_pr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2369914a-0442-4f3f-815e-e07b6e5417b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_pr = [prepare_predict(x) for x in preds_pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4c214df-0653-4b0c-ba77-0227e37582e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_submission_formated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3453a74-37ad-4d88-8cbd-a431be97f94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['target'] = preds_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a1cf41-d8bd-48a0-a75f-6a35a7deaa24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('simple_subv2_nlp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa0824-6375-40a0-9a5d-78741a0c1186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
