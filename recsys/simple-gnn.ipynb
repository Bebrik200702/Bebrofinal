{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install torch-geometric","metadata":{"execution":{"iopub.status.busy":"2024-06-20T21:44:56.155935Z","iopub.execute_input":"2024-06-20T21:44:56.156384Z","iopub.status.idle":"2024-06-20T21:45:12.196960Z","shell.execute_reply.started":"2024-06-20T21:44:56.156347Z","shell.execute_reply":"2024-06-20T21:45:12.195631Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm, trange\nfrom sklearn.metrics import f1_score, accuracy_score\nimport networkx as nx\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl","metadata":{"execution":{"iopub.status.busy":"2024-06-20T21:45:12.199667Z","iopub.execute_input":"2024-06-20T21:45:12.200078Z","iopub.status.idle":"2024-06-20T21:45:20.937377Z","shell.execute_reply.started":"2024-06-20T21:45:12.200037Z","shell.execute_reply":"2024-06-20T21:45:20.936557Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.datasets import Planetoid\n\n# Import dataset from PyTorch Geometric\ndataset = Planetoid(root=\".\", name=\"CiteSeer\")\n\n# Print information about the dataset\nprint(f'Number of graphs: {len(dataset)}')\nprint(f'Number of nodes: {dataset[0].x.shape[0]}')\nprint(f'Number of features: {dataset.num_features}')\nprint(f'Number of classes: {dataset.num_classes}')\nprint(f'Has isolated nodes: {dataset[0].has_isolated_nodes()}')","metadata":{"execution":{"iopub.status.busy":"2024-06-20T21:45:20.943226Z","iopub.execute_input":"2024-06-20T21:45:20.943819Z","iopub.status.idle":"2024-06-20T21:45:25.154386Z","shell.execute_reply.started":"2024-06-20T21:45:20.943784Z","shell.execute_reply":"2024-06-20T21:45:25.153331Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\nProcessing...\n","output_type":"stream"},{"name":"stdout","text":"Number of graphs: 1\nNumber of nodes: 3327\nNumber of features: 3703\nNumber of classes: 6\nHas isolated nodes: True\n","output_type":"stream"},{"name":"stderr","text":"Done!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## GCN","metadata":{}},{"cell_type":"code","source":"test_mask = dataset.test_mask\nval_mask = dataset.val_mask\ntrain_mask = ~(test_mask + val_mask)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:08:01.724924Z","iopub.execute_input":"2024-06-19T14:08:01.725547Z","iopub.status.idle":"2024-06-19T14:08:01.734379Z","shell.execute_reply.started":"2024-06-19T14:08:01.725515Z","shell.execute_reply":"2024-06-19T14:08:01.733086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ModelCFG:\n        model ='GCN'\n        num_labels = 6\n        scheduler= False\n        warnap = False\n        max_epoches=175\n        lr = 3e-4\n        eps=1e-6\n        betas=(0.9, 0.999)\n        drop = 0.1\n        depths = [3703,256]\n        act = nn.GELU()\n        _act = 'gelu'\n        weight_decay = 1e-4\n        \ncfg = ModelCFG()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:10.124013Z","iopub.execute_input":"2024-06-19T14:22:10.124381Z","iopub.status.idle":"2024-06-19T14:22:10.131502Z","shell.execute_reply.started":"2024-06-19T14:22:10.124352Z","shell.execute_reply":"2024-06-19T14:22:10.130167Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n\nclass GCNModel(nn.Module):\n    def __init__(self,CFG):\n        super().__init__()\n        self.convs = nn.ModuleList()\n        self.act = CFG.act\n        self.drop = nn.Dropout(CFG.drop)\n        for i in range(len(CFG.depths)-1):\n            self.convs.append(GCNConv(CFG.depths[i],CFG.depths[i+1]))\n        self.head = nn.Linear(CFG.depths[-1],CFG.num_labels)\n    \n    def forward(self, x, edge_index):\n        x = self.drop(x)\n        for conv in self.convs:\n            x = conv(x,edge_index)\n            x = self.act(x)\n        x = self.head(x).softmax(dim=-1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:10.283959Z","iopub.execute_input":"2024-06-19T14:22:10.284337Z","iopub.status.idle":"2024-06-19T14:22:10.294122Z","shell.execute_reply.started":"2024-06-19T14:22:10.284306Z","shell.execute_reply":"2024-06-19T14:22:10.292995Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"def train(model, data, criterion, optimizer, epochs):\n    \n\n    model.train()\n    for epoch in trange(epochs):\n        \n        pl.seed_everything(56)\n        optimizer.zero_grad()\n        logits = model(data.x.cuda(), data.edge_index.cuda())\n        loss = criterion(logits[train_mask], data.y[train_mask].cuda())\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 10 == 0:\n            val_acc = accuracy_score(logits[val_mask].argmax(dim=1).cpu().detach().numpy(),\n                                     data.y[val_mask].cpu().detach().numpy())\n            print(val_acc)\n    \n    test_acc = accuracy_score(logits[test_mask].argmax(dim=1).cpu().detach().numpy(),\n                             data.y[test_mask].cpu().detach().numpy())\n    \n    print(f'Test Score {test_acc}')\n    return val_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:10.438105Z","iopub.execute_input":"2024-06-19T14:22:10.438532Z","iopub.status.idle":"2024-06-19T14:22:10.448993Z","shell.execute_reply.started":"2024-06-19T14:22:10.438487Z","shell.execute_reply":"2024-06-19T14:22:10.447718Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"# Experements\nif False:\n    Experements = {\n        'epoches': [],\n        'lr': [],\n        'drop': [],\n        'depths': [],\n        'act': [],\n        'weight_decay': [],\n        'test_score': [],\n        'val_score': []\n    }\n\ndef ExperementsUpgrade(cfg,test_score,val_score,Experements):\n    Experements['epoches'].append(cfg.max_epoches)\n    Experements['lr'].append(cfg.lr)\n    Experements['drop'].append(cfg.drop)\n    Experements['depths'].append(cfg.depths)\n    Experements['act'].append(cfg._act)\n    Experements['weight_decay'].append(cfg.weight_decay)\n    Experements['test_score'].append(test_score)\n    Experements['val_score'].append(val_score)\n    return Experements","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:10.585761Z","iopub.execute_input":"2024-06-19T14:22:10.586632Z","iopub.status.idle":"2024-06-19T14:22:10.594404Z","shell.execute_reply.started":"2024-06-19T14:22:10.586582Z","shell.execute_reply":"2024-06-19T14:22:10.593263Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"model = GCNModel(cfg).cuda()\n\noptimizer = torch.optim.AdamW(model.parameters(),\n                              lr = cfg.lr,\n                              eps = cfg.eps,\n                              betas = cfg.betas,\n                              weight_decay = cfg.weight_decay)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:10.889598Z","iopub.execute_input":"2024-06-19T14:22:10.889996Z","iopub.status.idle":"2024-06-19T14:22:10.919466Z","shell.execute_reply.started":"2024-06-19T14:22:10.889966Z","shell.execute_reply":"2024-06-19T14:22:10.918257Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"val_acc, test_acc = train(model, dataset, criterion, optimizer, cfg.max_epoches)\nExperements = ExperementsUpgrade(cfg,test_acc,val_acc,Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:11.533715Z","iopub.execute_input":"2024-06-19T14:22:11.534402Z","iopub.status.idle":"2024-06-19T14:22:18.951273Z","shell.execute_reply.started":"2024-06-19T14:22:11.534367Z","shell.execute_reply":"2024-06-19T14:22:18.950142Z"},"trusted":true},"execution_count":201,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/175 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cc19498afc34d168d7dc97f12a5ab8e"}},"metadata":{}},{"name":"stdout","text":"0.106\n0.68\n0.726\n0.734\n0.744\n0.748\n0.762\n0.776\n0.778\n0.78\n0.776\n0.784\n0.784\n0.784\n0.782\n0.786\n0.788\n0.782\nTest Score 0.789\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:22:18.953551Z","iopub.execute_input":"2024-06-19T14:22:18.953888Z","iopub.status.idle":"2024-06-19T14:22:18.996618Z","shell.execute_reply.started":"2024-06-19T14:22:18.953858Z","shell.execute_reply":"2024-06-19T14:22:18.995439Z"},"trusted":true},"execution_count":202,"outputs":[{"execution_count":202,"output_type":"execute_result","data":{"text/plain":"    epoches      lr  drop               depths   act  weight_decay  \\\n0       200  0.0003   0.1           [3703, 64]  gelu        0.0001   \n1       175  0.0003   0.1           [3703, 64]  gelu        0.0001   \n2       150  0.0003   0.1           [3703, 64]  gelu        0.0001   \n3       100  0.0003   0.1           [3703, 64]  gelu        0.0001   \n4       250  0.0003   0.1           [3703, 64]  gelu        0.0001   \n5       200  0.0003   0.2           [3703, 64]  gelu        0.0001   \n6       250  0.0003   0.2           [3703, 64]  gelu        0.0001   \n7       150  0.0003   0.2           [3703, 64]  gelu        0.0001   \n8       200  0.0003   0.0           [3703, 64]  gelu        0.0001   \n9       175  0.0003   0.0           [3703, 64]  gelu        0.0001   \n10      200  0.0003   0.0           [3703, 64]  relu        0.0001   \n11      200  0.0003   0.5           [3703, 64]  gelu        0.0001   \n12      200  0.0003   0.0           [3703, 64]  gelu        0.0200   \n13      200  0.0003   0.1           [3703, 64]  gelu        0.0200   \n14      200  0.0003   0.1          [3703, 128]  gelu        0.0200   \n15      200  0.0003   0.1          [3703, 128]  gelu        0.0001   \n16      200  0.0003   0.1          [3703, 256]  gelu        0.0001   \n17      175  0.0003   0.1          [3703, 256]  gelu        0.0001   \n18      175  0.0003   0.1      [3703, 256, 64]  gelu        0.0001   \n19      150  0.0003   0.1      [3703, 256, 64]  gelu        0.0001   \n20      150  0.0003   0.1     [3703, 256, 128]  gelu        0.0001   \n21      150  0.0003   0.1      [3703, 256, 64]  gelu        0.0001   \n22      150  0.0003   0.1  [3703, 256, 64, 16]  gelu        0.0001   \n23      150  0.0003   0.1     [3703, 256, 128]  gelu        0.0001   \n24      150  0.0003   0.1     [3703, 512, 128]  gelu        0.0001   \n25      175  0.0003   0.1      [3703, 256, 32]  gelu        0.0001   \n26      175  0.0003   0.1          [3703, 256]  gelu        0.0001   \n\n    test_score  val_score  \n0        0.777      0.780  \n1        0.778      0.778  \n2        0.779      0.778  \n3        0.752      0.768  \n4        0.775      0.774  \n5        0.769      0.774  \n6        0.770      0.764  \n7        0.770      0.774  \n8        0.776      0.782  \n9        0.778      0.782  \n10       0.773      0.782  \n11       0.753      0.752  \n12       0.776      0.782  \n13       0.777      0.780  \n14       0.789      0.782  \n15       0.789      0.782  \n16       0.781      0.770  \n17       0.789      0.782  \n18       0.784      0.772  \n19       0.786      0.800  \n20       0.780      0.784  \n21       0.786      0.800  \n22       0.755      0.764  \n23       0.780      0.784  \n24       0.779      0.776  \n25       0.781      0.782  \n26       0.789      0.782  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoches</th>\n      <th>lr</th>\n      <th>drop</th>\n      <th>depths</th>\n      <th>act</th>\n      <th>weight_decay</th>\n      <th>test_score</th>\n      <th>val_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.777</td>\n      <td>0.780</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.778</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.779</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.752</td>\n      <td>0.768</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>250</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.775</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.2</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.769</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>250</td>\n      <td>0.0003</td>\n      <td>0.2</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.2</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.778</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>relu</td>\n      <td>0.0001</td>\n      <td>0.773</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.5</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.753</td>\n      <td>0.752</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0200</td>\n      <td>0.776</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0200</td>\n      <td>0.777</td>\n      <td>0.780</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>0.0200</td>\n      <td>0.789</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.789</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.781</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.789</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.784</td>\n      <td>0.772</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.786</td>\n      <td>0.800</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 128]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.780</td>\n      <td>0.784</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.786</td>\n      <td>0.800</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 64, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.755</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 128]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.780</td>\n      <td>0.784</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 512, 128]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.779</td>\n      <td>0.776</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.781</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.1</td>\n      <td>[3703, 256]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.789</td>\n      <td>0.782</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## GAT","metadata":{}},{"cell_type":"code","source":"test_mask = dataset.test_mask\nval_mask = dataset.val_mask\ntrain_mask = ~(test_mask + val_mask)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:44:48.333542Z","iopub.execute_input":"2024-06-19T14:44:48.333983Z","iopub.status.idle":"2024-06-19T14:44:48.339722Z","shell.execute_reply.started":"2024-06-19T14:44:48.333947Z","shell.execute_reply":"2024-06-19T14:44:48.338667Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"code","source":"class ModelCFG:\n        model ='GAT'\n        num_labels = 6\n        scheduler= False\n        warnap = False\n        max_epoches=200\n        lr = 2e-4\n        eps=1e-6\n        betas=(0.9, 0.999)\n        drop = 0.0\n        depths = [3703,64,16]\n        heads = [8,2]\n        act = nn.GELU()\n        _act = 'gelu'\n        weight_decay = 1e-4\n        \ncfg = ModelCFG()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:08.266050Z","iopub.execute_input":"2024-06-19T14:53:08.266540Z","iopub.status.idle":"2024-06-19T14:53:08.272737Z","shell.execute_reply.started":"2024-06-19T14:53:08.266507Z","shell.execute_reply":"2024-06-19T14:53:08.271671Z"},"trusted":true},"execution_count":454,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n\nclass GATModel(nn.Module):\n    def __init__(self,CFG):\n        super().__init__()\n        self.convs = nn.ModuleList()\n        self.act = CFG.act\n        self.drop = nn.Dropout(CFG.drop)\n        for i in range(len(CFG.depths)-1):\n            if i == 0:\n                self.convs.append(GATConv(CFG.depths[i],CFG.depths[i+1],heads=CFG.heads[i]))\n            else:\n                self.convs.append(GATConv(CFG.depths[i] * CFG.heads[i-1],CFG.depths[i+1],heads=CFG.heads[i]))\n        self.head = nn.Linear(CFG.depths[-1] * CFG.heads[-1],CFG.num_labels)\n    \n    def forward(self, x, edge_index):\n        x = self.drop(x)\n        for conv in self.convs:\n            x = conv(x,edge_index)\n            x = self.act(x)\n        x = self.head(x).softmax(dim=-1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:08.429986Z","iopub.execute_input":"2024-06-19T14:53:08.431243Z","iopub.status.idle":"2024-06-19T14:53:08.443986Z","shell.execute_reply.started":"2024-06-19T14:53:08.431192Z","shell.execute_reply":"2024-06-19T14:53:08.442772Z"},"trusted":true},"execution_count":455,"outputs":[]},{"cell_type":"code","source":"def train(model, data, criterion, optimizer, epochs):\n    \n\n    model.train()\n    for epoch in trange(epochs):\n        \n        pl.seed_everything(56)\n        optimizer.zero_grad()\n        logits = model(data.x.cuda(), data.edge_index.cuda())\n        loss = criterion(logits[train_mask], data.y[train_mask].cuda())\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 10 == 0:\n            val_acc = accuracy_score(logits[val_mask].argmax(dim=1).cpu().detach().numpy(),\n                                     data.y[val_mask].cpu().detach().numpy())\n            print(val_acc)\n    \n    test_acc = accuracy_score(logits[test_mask].argmax(dim=1).cpu().detach().numpy(),\n                             data.y[test_mask].cpu().detach().numpy())\n    \n    print(f'Test Score {test_acc}')\n    return val_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:08.585513Z","iopub.execute_input":"2024-06-19T14:53:08.585915Z","iopub.status.idle":"2024-06-19T14:53:08.595084Z","shell.execute_reply.started":"2024-06-19T14:53:08.585880Z","shell.execute_reply":"2024-06-19T14:53:08.593977Z"},"trusted":true},"execution_count":456,"outputs":[]},{"cell_type":"code","source":"# Experements\nif False:\n    Experements = {\n        'epoches': [],\n        'lr': [],\n        'drop': [],\n        'depths': [],\n        'act': [],\n        'weight_decay': [],\n        'test_score': [],\n        'val_score': [],\n        'heads': []\n    }\n\ndef ExperementsUpgrade(cfg,test_score,val_score,Experements):\n    Experements['epoches'].append(cfg.max_epoches)\n    Experements['lr'].append(cfg.lr)\n    Experements['drop'].append(cfg.drop)\n    Experements['depths'].append(cfg.depths)\n    Experements['act'].append(cfg._act)\n    Experements['weight_decay'].append(cfg.weight_decay)\n    Experements['test_score'].append(test_score)\n    Experements['val_score'].append(val_score)\n    Experements['heads'].append(cfg.heads)\n    return Experements","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:08.743686Z","iopub.execute_input":"2024-06-19T14:53:08.744114Z","iopub.status.idle":"2024-06-19T14:53:08.753639Z","shell.execute_reply.started":"2024-06-19T14:53:08.744077Z","shell.execute_reply":"2024-06-19T14:53:08.752605Z"},"trusted":true},"execution_count":457,"outputs":[]},{"cell_type":"code","source":"model = GATModel(cfg).cuda()\n\noptimizer = torch.optim.AdamW(model.parameters(),\n                              lr = cfg.lr,\n                              eps = cfg.eps,\n                              betas = cfg.betas,\n                              weight_decay = cfg.weight_decay)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:08.914714Z","iopub.execute_input":"2024-06-19T14:53:08.915647Z","iopub.status.idle":"2024-06-19T14:53:08.962089Z","shell.execute_reply.started":"2024-06-19T14:53:08.915608Z","shell.execute_reply":"2024-06-19T14:53:08.960954Z"},"trusted":true},"execution_count":458,"outputs":[]},{"cell_type":"code","source":"val_acc, test_acc = train(model, dataset, criterion, optimizer, cfg.max_epoches)\nExperements = ExperementsUpgrade(cfg,test_acc,val_acc,Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:09.109281Z","iopub.execute_input":"2024-06-19T14:53:09.109668Z","iopub.status.idle":"2024-06-19T14:53:17.893632Z","shell.execute_reply.started":"2024-06-19T14:53:09.109635Z","shell.execute_reply":"2024-06-19T14:53:17.892616Z"},"trusted":true},"execution_count":459,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb994ac09eda4ba3b4991f67cd36fdb7"}},"metadata":{}},{"name":"stdout","text":"0.188\n0.288\n0.502\n0.604\n0.616\n0.62\n0.634\n0.676\n0.736\n0.774\n0.78\n0.794\n0.79\n0.792\n0.798\n0.798\n0.786\n0.784\n0.784\n0.784\nTest Score 0.765\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T14:53:38.372446Z","iopub.execute_input":"2024-06-19T14:53:38.372875Z","iopub.status.idle":"2024-06-19T14:53:38.418281Z","shell.execute_reply.started":"2024-06-19T14:53:38.372842Z","shell.execute_reply":"2024-06-19T14:53:38.417200Z"},"trusted":true},"execution_count":460,"outputs":[{"execution_count":460,"output_type":"execute_result","data":{"text/plain":"    epoches      lr  drop          depths   act  weight_decay  test_score  \\\n0       175  0.0003   0.0      [3703, 64]  gelu        0.0001       0.776   \n1       200  0.0003   0.0      [3703, 64]  gelu        0.0001       0.763   \n2       150  0.0003   0.0      [3703, 64]  gelu        0.0001       0.779   \n3       125  0.0003   0.0      [3703, 64]  gelu        0.0001       0.778   \n4       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.784   \n5       150  0.0002   0.0      [3703, 64]  gelu        0.0001       0.771   \n6       200  0.0002   0.1      [3703, 64]  gelu        0.0001       0.776   \n7       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.768   \n8       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.775   \n9       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.776   \n10      200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.783   \n11      175  0.0002   0.0      [3703, 64]  gelu        0.0001       0.782   \n12      150  0.0002   0.0      [3703, 64]  gelu        0.0001       0.772   \n13      200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.784   \n14      200  0.0002   0.0      [3703, 32]  gelu        0.0001       0.782   \n15      175  0.0002   0.0      [3703, 32]  gelu        0.0001       0.777   \n16      200  0.0002   0.0  [3703, 64, 16]  gelu        0.0001       0.765   \n17      200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.784   \n18      200  0.0002   0.0  [3703, 64, 16]  gelu        0.0001       0.774   \n19      200  0.0002   0.0  [3703, 64, 16]  gelu        0.0001       0.776   \n20      200  0.0002   0.0  [3703, 64, 16]  gelu        0.0001       0.765   \n\n    val_score   heads  \n0       0.766     [8]  \n1       0.758     [8]  \n2       0.766     [8]  \n3       0.776     [8]  \n4       0.770     [8]  \n5       0.788     [8]  \n6       0.774     [8]  \n7       0.778     [4]  \n8       0.774     [2]  \n9       0.772     [6]  \n10      0.768    [10]  \n11      0.768    [10]  \n12      0.794    [10]  \n13      0.766    [12]  \n14      0.774    [12]  \n15      0.788    [12]  \n16      0.782  [8, 1]  \n17      0.770     [8]  \n18      0.780  [8, 8]  \n19      0.780  [8, 4]  \n20      0.784  [8, 2]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoches</th>\n      <th>lr</th>\n      <th>drop</th>\n      <th>depths</th>\n      <th>act</th>\n      <th>weight_decay</th>\n      <th>test_score</th>\n      <th>val_score</th>\n      <th>heads</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.766</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.763</td>\n      <td>0.758</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.779</td>\n      <td>0.766</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>125</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.778</td>\n      <td>0.776</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.784</td>\n      <td>0.770</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>150</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.771</td>\n      <td>0.788</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.1</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.774</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.768</td>\n      <td>0.778</td>\n      <td>[4]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.775</td>\n      <td>0.774</td>\n      <td>[2]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.772</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.783</td>\n      <td>0.768</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>175</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.782</td>\n      <td>0.768</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>150</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.772</td>\n      <td>0.794</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.784</td>\n      <td>0.766</td>\n      <td>[12]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.782</td>\n      <td>0.774</td>\n      <td>[12]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>175</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.777</td>\n      <td>0.788</td>\n      <td>[12]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.765</td>\n      <td>0.782</td>\n      <td>[8, 1]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.784</td>\n      <td>0.770</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.774</td>\n      <td>0.780</td>\n      <td>[8, 8]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.780</td>\n      <td>[8, 4]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.765</td>\n      <td>0.784</td>\n      <td>[8, 2]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## GATV2","metadata":{}},{"cell_type":"code","source":"test_mask = dataset.test_mask\nval_mask = dataset.val_mask\ntrain_mask = ~(test_mask + val_mask)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:00:21.051299Z","iopub.execute_input":"2024-06-19T15:00:21.052274Z","iopub.status.idle":"2024-06-19T15:00:21.057474Z","shell.execute_reply.started":"2024-06-19T15:00:21.052236Z","shell.execute_reply":"2024-06-19T15:00:21.056025Z"},"trusted":true},"execution_count":471,"outputs":[]},{"cell_type":"code","source":"class ModelCFG:\n        model ='GATV2'\n        num_labels = 6\n        scheduler= False\n        warnap = False\n        max_epoches=200\n        lr = 2e-4\n        eps=1e-6\n        betas=(0.9, 0.999)\n        drop = 0.0\n        depths = [3703,32]\n        heads = [16]\n        act = nn.GELU()\n        _act = 'gelu'\n        weight_decay = 1e-4\n        \ncfg = ModelCFG()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:15.944034Z","iopub.execute_input":"2024-06-19T15:08:15.944395Z","iopub.status.idle":"2024-06-19T15:08:15.950684Z","shell.execute_reply.started":"2024-06-19T15:08:15.944364Z","shell.execute_reply":"2024-06-19T15:08:15.949485Z"},"trusted":true},"execution_count":572,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n\nclass GATV2Model(nn.Module):\n    def __init__(self,CFG):\n        super().__init__()\n        self.convs = nn.ModuleList()\n        self.act = CFG.act\n        self.drop = nn.Dropout(CFG.drop)\n        for i in range(len(CFG.depths)-1):\n            if i == 0:\n                self.convs.append(GATv2Conv(CFG.depths[i],CFG.depths[i+1],heads=CFG.heads[i]))\n            else:\n                self.convs.append(GATv2Conv(CFG.depths[i] * CFG.heads[i-1],CFG.depths[i+1],heads=CFG.heads[i]))\n        self.head = nn.Linear(CFG.depths[-1] * CFG.heads[-1],CFG.num_labels)\n    \n    def forward(self, x, edge_index):\n        x = self.drop(x)\n        for conv in self.convs:\n            x = conv(x,edge_index)\n            x = self.act(x)\n        x = self.head(x).softmax(dim=-1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:16.097428Z","iopub.execute_input":"2024-06-19T15:08:16.097830Z","iopub.status.idle":"2024-06-19T15:08:16.109205Z","shell.execute_reply.started":"2024-06-19T15:08:16.097798Z","shell.execute_reply":"2024-06-19T15:08:16.108066Z"},"trusted":true},"execution_count":573,"outputs":[]},{"cell_type":"code","source":"def train(model, data, criterion, optimizer, epochs):\n    \n\n    model.train()\n    for epoch in trange(epochs):\n        \n        pl.seed_everything(56)\n        optimizer.zero_grad()\n        logits = model(data.x.cuda(), data.edge_index.cuda())\n        loss = criterion(logits[train_mask], data.y[train_mask].cuda())\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 10 == 0:\n            val_acc = accuracy_score(logits[val_mask].argmax(dim=1).cpu().detach().numpy(),\n                                     data.y[val_mask].cpu().detach().numpy())\n            print(val_acc)\n    \n    test_acc = accuracy_score(logits[test_mask].argmax(dim=1).cpu().detach().numpy(),\n                             data.y[test_mask].cpu().detach().numpy())\n    \n    print(f'Test Score {test_acc}')\n    return val_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:16.253768Z","iopub.execute_input":"2024-06-19T15:08:16.254747Z","iopub.status.idle":"2024-06-19T15:08:16.263532Z","shell.execute_reply.started":"2024-06-19T15:08:16.254708Z","shell.execute_reply":"2024-06-19T15:08:16.262424Z"},"trusted":true},"execution_count":574,"outputs":[]},{"cell_type":"code","source":"# Experements\nif False:\n    Experements = {\n        'epoches': [],\n        'lr': [],\n        'drop': [],\n        'depths': [],\n        'act': [],\n        'weight_decay': [],\n        'test_score': [],\n        'val_score': [],\n        'heads': []\n    }\n\ndef ExperementsUpgrade(cfg,test_score,val_score,Experements):\n    Experements['epoches'].append(cfg.max_epoches)\n    Experements['lr'].append(cfg.lr)\n    Experements['drop'].append(cfg.drop)\n    Experements['depths'].append(cfg.depths)\n    Experements['act'].append(cfg._act)\n    Experements['weight_decay'].append(cfg.weight_decay)\n    Experements['test_score'].append(test_score)\n    Experements['val_score'].append(val_score)\n    Experements['heads'].append(cfg.heads)\n    return Experements","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:16.437656Z","iopub.execute_input":"2024-06-19T15:08:16.438046Z","iopub.status.idle":"2024-06-19T15:08:16.446232Z","shell.execute_reply.started":"2024-06-19T15:08:16.438014Z","shell.execute_reply":"2024-06-19T15:08:16.445127Z"},"trusted":true},"execution_count":575,"outputs":[]},{"cell_type":"code","source":"model = GATV2Model(cfg).cuda()\n\noptimizer = torch.optim.AdamW(model.parameters(),\n                              lr = cfg.lr,\n                              eps = cfg.eps,\n                              betas = cfg.betas,\n                              weight_decay = cfg.weight_decay)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:16.609386Z","iopub.execute_input":"2024-06-19T15:08:16.609805Z","iopub.status.idle":"2024-06-19T15:08:16.694113Z","shell.execute_reply.started":"2024-06-19T15:08:16.609773Z","shell.execute_reply":"2024-06-19T15:08:16.692972Z"},"trusted":true},"execution_count":576,"outputs":[]},{"cell_type":"code","source":"val_acc, test_acc = train(model, dataset, criterion, optimizer, cfg.max_epoches)\nExperements = ExperementsUpgrade(cfg,test_acc,val_acc,Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:16.881291Z","iopub.execute_input":"2024-06-19T15:08:16.882068Z","iopub.status.idle":"2024-06-19T15:08:26.401132Z","shell.execute_reply.started":"2024-06-19T15:08:16.882034Z","shell.execute_reply":"2024-06-19T15:08:26.400125Z"},"trusted":true},"execution_count":577,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4febaeeeb53415997157b9b6bfd5250"}},"metadata":{}},{"name":"stdout","text":"0.274\n0.604\n0.672\n0.69\n0.702\n0.718\n0.728\n0.756\n0.768\n0.776\n0.784\n0.784\n0.792\n0.792\n0.794\n0.792\n0.792\n0.782\n0.778\n0.768\nTest Score 0.791\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T15:08:26.403261Z","iopub.execute_input":"2024-06-19T15:08:26.403987Z","iopub.status.idle":"2024-06-19T15:08:26.436255Z","shell.execute_reply.started":"2024-06-19T15:08:26.403944Z","shell.execute_reply":"2024-06-19T15:08:26.435154Z"},"trusted":true},"execution_count":578,"outputs":[{"execution_count":578,"output_type":"execute_result","data":{"text/plain":"    epoches      lr  drop          depths   act  weight_decay  test_score  \\\n0       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.784   \n1       175  0.0002   0.0      [3703, 64]  gelu        0.0001       0.782   \n2       150  0.0002   0.0      [3703, 64]  gelu        0.0001       0.776   \n3       150  0.0002   0.0      [3703, 32]  gelu        0.0001       0.774   \n4       200  0.0002   0.0  [3703, 64, 16]  gelu        0.0001       0.777   \n5       200  0.0002   0.0  [3703, 64, 32]  gelu        0.0001       0.773   \n6       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.786   \n7       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.779   \n8       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.792   \n9       200  0.0002   0.0      [3703, 64]  gelu        0.0001       0.786   \n10      200  0.0002   0.0      [3703, 32]  gelu        0.0001       0.789   \n11      200  0.0002   0.0      [3703, 16]  gelu        0.0001       0.784   \n12      200  0.0002   0.0      [3703, 32]  gelu        0.0001       0.791   \n\n    val_score   heads  \n0       0.766     [8]  \n1       0.780     [8]  \n2       0.790     [8]  \n3       0.784     [8]  \n4       0.782  [8, 4]  \n5       0.774  [8, 4]  \n6       0.766     [9]  \n7       0.774    [10]  \n8       0.772     [7]  \n9       0.774     [6]  \n10      0.770    [12]  \n11      0.774    [24]  \n12      0.768    [16]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoches</th>\n      <th>lr</th>\n      <th>drop</th>\n      <th>depths</th>\n      <th>act</th>\n      <th>weight_decay</th>\n      <th>test_score</th>\n      <th>val_score</th>\n      <th>heads</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.784</td>\n      <td>0.766</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>175</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.782</td>\n      <td>0.780</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.790</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>150</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.774</td>\n      <td>0.784</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.777</td>\n      <td>0.782</td>\n      <td>[8, 4]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.773</td>\n      <td>0.774</td>\n      <td>[8, 4]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.786</td>\n      <td>0.766</td>\n      <td>[9]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.779</td>\n      <td>0.774</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.792</td>\n      <td>0.772</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.786</td>\n      <td>0.774</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.789</td>\n      <td>0.770</td>\n      <td>[12]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 16]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.784</td>\n      <td>0.774</td>\n      <td>[24]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>200</td>\n      <td>0.0002</td>\n      <td>0.0</td>\n      <td>[3703, 32]</td>\n      <td>gelu</td>\n      <td>0.0001</td>\n      <td>0.791</td>\n      <td>0.768</td>\n      <td>[16]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Graph Sage","metadata":{}},{"cell_type":"code","source":"test_mask = dataset.test_mask\nval_mask = dataset.val_mask\ntrain_mask = ~(test_mask + val_mask)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T21:47:41.825859Z","iopub.execute_input":"2024-06-20T21:47:41.827107Z","iopub.status.idle":"2024-06-20T21:47:41.835927Z","shell.execute_reply.started":"2024-06-20T21:47:41.827073Z","shell.execute_reply":"2024-06-20T21:47:41.835167Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ModelCFG:\n        model ='GraphSage'\n        num_labels = 6\n        scheduler= False\n        warnap = False\n        max_epoches=150\n        aggr = 'mean'\n        lr = 3e-4\n        eps=1e-6\n        betas=(0.9, 0.999)\n        drop = 0.0\n        depths = [3703,128]\n        act = nn.GELU()\n        _act = 'gelu'\n        weight_decay = 2e-4\n        \ncfg = ModelCFG()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:35.215092Z","iopub.execute_input":"2024-06-20T22:12:35.215476Z","iopub.status.idle":"2024-06-20T22:12:35.221762Z","shell.execute_reply.started":"2024-06-20T22:12:35.215445Z","shell.execute_reply":"2024-06-20T22:12:35.220642Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv, GATConv, GATv2Conv, SAGEConv\n\nclass GraphSageModel(nn.Module):\n    def __init__(self,CFG):\n        super().__init__()\n        self.convs = nn.ModuleList()\n        self.act = CFG.act\n        self.drop = nn.Dropout(CFG.drop)\n        for i in range(len(CFG.depths)-1):\n            self.convs.append(SAGEConv(CFG.depths[i],CFG.depths[i+1],aggr=CFG.aggr))\n        self.head = nn.Linear(CFG.depths[-1],CFG.num_labels)\n    \n    def forward(self, x, edge_index):\n        x = self.drop(x)\n        for conv in self.convs:\n            x = conv(x,edge_index)\n            x = self.act(x)\n        x = self.head(x).softmax(dim=-1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:38.532849Z","iopub.execute_input":"2024-06-20T22:12:38.533244Z","iopub.status.idle":"2024-06-20T22:12:38.542711Z","shell.execute_reply.started":"2024-06-20T22:12:38.533211Z","shell.execute_reply":"2024-06-20T22:12:38.541611Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"code","source":"def train(model, data, criterion, optimizer, epochs):\n    \n\n    model.train()\n    for epoch in trange(epochs):\n        \n        pl.seed_everything(56)\n        optimizer.zero_grad()\n        logits = model(data.x.cuda(), data.edge_index.cuda())\n        loss = criterion(logits[train_mask], data.y[train_mask].cuda())\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 10 == 0:\n            val_acc = accuracy_score(logits[val_mask].argmax(dim=1).cpu().detach().numpy(),\n                                     data.y[val_mask].cpu().detach().numpy())\n            print(val_acc)\n    \n    test_acc = accuracy_score(logits[test_mask].argmax(dim=1).cpu().detach().numpy(),\n                             data.y[test_mask].cpu().detach().numpy())\n    \n    print(f'Test Score {test_acc}')\n    return val_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:38.679083Z","iopub.execute_input":"2024-06-20T22:12:38.679489Z","iopub.status.idle":"2024-06-20T22:12:38.689472Z","shell.execute_reply.started":"2024-06-20T22:12:38.679457Z","shell.execute_reply":"2024-06-20T22:12:38.688254Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"code","source":"# Experements\nif False:\n    Experements = {\n        'epoches': [],\n        'lr': [],\n        'drop': [],\n        'depths': [],\n        'act': [],\n        'aggr':[],\n        'weight_decay': [],\n        'test_score': [],\n        'val_score': []\n    }\n\ndef ExperementsUpgrade(cfg,test_score,val_score,Experements):\n    Experements['epoches'].append(cfg.max_epoches)\n    Experements['lr'].append(cfg.lr)\n    Experements['drop'].append(cfg.drop)\n    Experements['depths'].append(cfg.depths)\n    Experements['act'].append(cfg._act)\n    Experements['weight_decay'].append(cfg.weight_decay)\n    Experements['test_score'].append(test_score)\n    Experements['val_score'].append(val_score)\n    Experements['aggr'].append(cfg.aggr)\n    return Experements","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:38.850838Z","iopub.execute_input":"2024-06-20T22:12:38.851201Z","iopub.status.idle":"2024-06-20T22:12:38.859739Z","shell.execute_reply.started":"2024-06-20T22:12:38.851174Z","shell.execute_reply":"2024-06-20T22:12:38.858647Z"},"trusted":true},"execution_count":262,"outputs":[]},{"cell_type":"code","source":"model = GraphSageModel(cfg).cuda()\n\noptimizer = torch.optim.AdamW(model.parameters(),\n                              lr = cfg.lr,\n                              eps = cfg.eps,\n                              betas = cfg.betas,\n                              weight_decay = cfg.weight_decay)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:38.998586Z","iopub.execute_input":"2024-06-20T22:12:38.998983Z","iopub.status.idle":"2024-06-20T22:12:39.025074Z","shell.execute_reply.started":"2024-06-20T22:12:38.998950Z","shell.execute_reply":"2024-06-20T22:12:39.024120Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"code","source":"val_acc, test_acc = train(model, dataset, criterion, optimizer, cfg.max_epoches)\nExperements = ExperementsUpgrade(cfg,test_acc,val_acc,Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:39.186483Z","iopub.execute_input":"2024-06-20T22:12:39.186922Z","iopub.status.idle":"2024-06-20T22:12:45.535134Z","shell.execute_reply.started":"2024-06-20T22:12:39.186890Z","shell.execute_reply":"2024-06-20T22:12:45.534133Z"},"trusted":true},"execution_count":264,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/150 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a7112d401b34c44928d4dec397fcebf"}},"metadata":{}},{"name":"stdout","text":"0.136\n0.632\n0.69\n0.714\n0.722\n0.736\n0.756\n0.772\n0.782\n0.778\n0.788\n0.786\n0.782\n0.78\n0.78\nTest Score 0.779\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:12:51.650932Z","iopub.execute_input":"2024-06-20T22:12:51.651403Z","iopub.status.idle":"2024-06-20T22:12:51.694358Z","shell.execute_reply.started":"2024-06-20T22:12:51.651371Z","shell.execute_reply":"2024-06-20T22:12:51.693355Z"},"trusted":true},"execution_count":266,"outputs":[{"execution_count":266,"output_type":"execute_result","data":{"text/plain":"    epoches      lr  drop           depths   act  aggr  weight_decay  \\\n0       150  0.0003  0.10       [3703, 64]  gelu  mean        0.0001   \n1       100  0.0003  0.10       [3703, 64]  gelu  mean        0.0001   \n2       125  0.0003  0.10       [3703, 64]  gelu  mean        0.0001   \n3       175  0.0003  0.10       [3703, 64]  gelu  mean        0.0001   \n4       200  0.0003  0.10       [3703, 64]  gelu  mean        0.0001   \n5       150  0.0003  0.00       [3703, 64]  gelu  mean        0.0001   \n6       200  0.0003  0.00       [3703, 64]  gelu  mean        0.0001   \n7       100  0.0003  0.00       [3703, 64]  gelu  mean        0.0001   \n8       125  0.0003  0.00       [3703, 64]  gelu  mean        0.0001   \n9       150  0.0003  0.05       [3703, 64]  gelu  mean        0.0001   \n10      150  0.0003  0.00       [3703, 64]  gelu   max        0.0001   \n11      150  0.0003  0.00       [3703, 64]  gelu   sum        0.0001   \n12      150  0.0003  0.00       [3703, 64]  gelu   min        0.0001   \n13      150  0.0003  0.00       [3703, 64]  gelu  mean        0.0001   \n14      150  0.0003  0.00      [3703, 128]  gelu  mean        0.0001   \n15      150  0.0003  0.00      [3703, 256]  gelu  mean        0.0001   \n16      150  0.0003  0.00  [3703, 256, 32]  gelu  mean        0.0001   \n17      100  0.0003  0.00  [3703, 256, 32]  gelu  mean        0.0001   \n18      150  0.0003  0.00  [3703, 128, 32]  gelu  mean        0.0001   \n19      100  0.0003  0.00  [3703, 128, 32]  gelu  mean        0.0001   \n20      100  0.0003  0.00  [3703, 128, 64]  gelu  mean        0.0001   \n21      100  0.0003  0.00  [3703, 128, 16]  gelu  mean        0.0001   \n22      100  0.0003  0.00   [3703, 64, 32]  gelu  mean        0.0001   \n23      150  0.0003  0.00   [3703, 64, 32]  gelu  mean        0.0001   \n24      150  0.0003  0.00      [3703, 128]  gelu  mean        0.0001   \n25      150  0.0003  0.00   [3703, 128, 8]  gelu  mean        0.0001   \n26      150  0.0003  0.00  [3703, 128, 32]  gelu  mean        0.0001   \n27      150  0.0003  0.00  [3703, 512, 64]  gelu  mean        0.0001   \n28      100  0.0003  0.00  [3703, 512, 64]  gelu  mean        0.0001   \n29      150  0.0003  0.00      [3703, 128]  gelu  mean        0.2000   \n30      150  0.0003  0.00      [3703, 128]  gelu  mean        0.0002   \n\n    test_score  val_score  \n0        0.770      0.766  \n1        0.762      0.764  \n2        0.766      0.766  \n3        0.768      0.766  \n4        0.762      0.764  \n5        0.779      0.778  \n6        0.770      0.776  \n7        0.763      0.784  \n8        0.775      0.776  \n9        0.766      0.764  \n10       0.764      0.770  \n11       0.768      0.760  \n12       0.760      0.760  \n13       0.779      0.778  \n14       0.782      0.778  \n15       0.777      0.764  \n16       0.767      0.756  \n17       0.770      0.786  \n18       0.768      0.774  \n19       0.773      0.794  \n20       0.776      0.784  \n21       0.771      0.802  \n22       0.762      0.800  \n23       0.770      0.786  \n24       0.782      0.778  \n25       0.707      0.704  \n26       0.768      0.774  \n27       0.765      0.760  \n28       0.770      0.772  \n29       0.782      0.778  \n30       0.779      0.780  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoches</th>\n      <th>lr</th>\n      <th>drop</th>\n      <th>depths</th>\n      <th>act</th>\n      <th>aggr</th>\n      <th>weight_decay</th>\n      <th>test_score</th>\n      <th>val_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.10</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.766</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.10</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.762</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>125</td>\n      <td>0.0003</td>\n      <td>0.10</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.766</td>\n      <td>0.766</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.10</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.768</td>\n      <td>0.766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.10</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.762</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.779</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.776</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.763</td>\n      <td>0.784</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>125</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.775</td>\n      <td>0.776</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.05</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.766</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>max</td>\n      <td>0.0001</td>\n      <td>0.764</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>sum</td>\n      <td>0.0001</td>\n      <td>0.768</td>\n      <td>0.760</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>min</td>\n      <td>0.0001</td>\n      <td>0.760</td>\n      <td>0.760</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.779</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.782</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 256]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.777</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 256, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.767</td>\n      <td>0.756</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 256, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.786</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.768</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.773</td>\n      <td>0.794</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.776</td>\n      <td>0.784</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128, 16]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.771</td>\n      <td>0.802</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.762</td>\n      <td>0.800</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 64, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.786</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.782</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128, 8]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.707</td>\n      <td>0.704</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128, 32]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.768</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 512, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.765</td>\n      <td>0.760</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 512, 64]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0001</td>\n      <td>0.770</td>\n      <td>0.772</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.2000</td>\n      <td>0.782</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.00</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>mean</td>\n      <td>0.0002</td>\n      <td>0.779</td>\n      <td>0.780</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# GinConv","metadata":{}},{"cell_type":"code","source":"test_mask = dataset.test_mask\nval_mask = dataset.val_mask\ntrain_mask = ~(test_mask + val_mask)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:16:39.892809Z","iopub.execute_input":"2024-06-20T22:16:39.893235Z","iopub.status.idle":"2024-06-20T22:16:39.898965Z","shell.execute_reply.started":"2024-06-20T22:16:39.893204Z","shell.execute_reply":"2024-06-20T22:16:39.897817Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"class ModelCFG:\n        model ='GinConv'\n        num_labels = 6\n        scheduler= False\n        warnap = False\n        max_epoches=80\n        lr = 3e-4\n        eps=1e-6\n        betas=(0.9, 0.999)\n        drop = 0.0\n        depths = [3703,80]\n        act = nn.GELU()\n        _act = 'gelu'\n        weight_decay = 2e-4\n        \ncfg = ModelCFG()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:41.923750Z","iopub.execute_input":"2024-06-20T22:27:41.924870Z","iopub.status.idle":"2024-06-20T22:27:41.931772Z","shell.execute_reply.started":"2024-06-20T22:27:41.924819Z","shell.execute_reply":"2024-06-20T22:27:41.930819Z"},"trusted":true},"execution_count":382,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.nn import GINConv\n\nclass GINModel(nn.Module):\n    def __init__(self,CFG):\n        super().__init__()\n        self.convs = nn.ModuleList()\n        self.act = CFG.act\n        self.drop = nn.Dropout(CFG.drop)\n        for i in range(len(CFG.depths)-1):\n            self.convs.append(GINConv(nn.Linear(CFG.depths[i],CFG.depths[i+1])))\n        self.head = nn.Linear(CFG.depths[-1],CFG.num_labels)\n    \n    def forward(self, x, edge_index):\n        x = self.drop(x)\n        for conv in self.convs:\n            x = conv(x,edge_index)\n            x = self.act(x)\n        x = self.head(x).softmax(dim=-1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:42.097683Z","iopub.execute_input":"2024-06-20T22:27:42.098040Z","iopub.status.idle":"2024-06-20T22:27:42.107015Z","shell.execute_reply.started":"2024-06-20T22:27:42.098015Z","shell.execute_reply":"2024-06-20T22:27:42.105919Z"},"trusted":true},"execution_count":383,"outputs":[]},{"cell_type":"code","source":"def train(model, data, criterion, optimizer, epochs):\n    \n\n    model.train()\n    for epoch in trange(epochs):\n        \n        pl.seed_everything(56)\n        optimizer.zero_grad()\n        logits = model(data.x.cuda(), data.edge_index.cuda())\n        loss = criterion(logits[train_mask], data.y[train_mask].cuda())\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 10 == 0:\n            val_acc = accuracy_score(logits[val_mask].argmax(dim=1).cpu().detach().numpy(),\n                                     data.y[val_mask].cpu().detach().numpy())\n            print(val_acc)\n    \n    test_acc = accuracy_score(logits[test_mask].argmax(dim=1).cpu().detach().numpy(),\n                             data.y[test_mask].cpu().detach().numpy())\n    \n    print(f'Test Score {test_acc}')\n    return val_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:42.253166Z","iopub.execute_input":"2024-06-20T22:27:42.253585Z","iopub.status.idle":"2024-06-20T22:27:42.264004Z","shell.execute_reply.started":"2024-06-20T22:27:42.253534Z","shell.execute_reply":"2024-06-20T22:27:42.262855Z"},"trusted":true},"execution_count":384,"outputs":[]},{"cell_type":"code","source":"# Experements\nif False:\n    Experements = {\n        'epoches': [],\n        'lr': [],\n        'drop': [],\n        'depths': [],\n        'act': [],\n        'weight_decay': [],\n        'test_score': [],\n        'val_score': []\n    }\n\ndef ExperementsUpgrade(cfg,test_score,val_score,Experements):\n    Experements['epoches'].append(cfg.max_epoches)\n    Experements['lr'].append(cfg.lr)\n    Experements['drop'].append(cfg.drop)\n    Experements['depths'].append(cfg.depths)\n    Experements['act'].append(cfg._act)\n    Experements['weight_decay'].append(cfg.weight_decay)\n    Experements['test_score'].append(test_score)\n    Experements['val_score'].append(val_score)\n    return Experements","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:42.391648Z","iopub.execute_input":"2024-06-20T22:27:42.392438Z","iopub.status.idle":"2024-06-20T22:27:42.400138Z","shell.execute_reply.started":"2024-06-20T22:27:42.392407Z","shell.execute_reply":"2024-06-20T22:27:42.398967Z"},"trusted":true},"execution_count":385,"outputs":[]},{"cell_type":"code","source":"model = GINModel(cfg).cuda()\n\noptimizer = torch.optim.AdamW(model.parameters(),\n                              lr = cfg.lr,\n                              eps = cfg.eps,\n                              betas = cfg.betas,\n                              weight_decay = cfg.weight_decay)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:42.555552Z","iopub.execute_input":"2024-06-20T22:27:42.556513Z","iopub.status.idle":"2024-06-20T22:27:42.571645Z","shell.execute_reply.started":"2024-06-20T22:27:42.556480Z","shell.execute_reply":"2024-06-20T22:27:42.570538Z"},"trusted":true},"execution_count":386,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:42.709385Z","iopub.execute_input":"2024-06-20T22:27:42.710087Z","iopub.status.idle":"2024-06-20T22:27:42.716706Z","shell.execute_reply.started":"2024-06-20T22:27:42.710055Z","shell.execute_reply":"2024-06-20T22:27:42.715603Z"},"trusted":true},"execution_count":387,"outputs":[{"execution_count":387,"output_type":"execute_result","data":{"text/plain":"GINModel(\n  (convs): ModuleList(\n    (0): GINConv(nn=Linear(in_features=3703, out_features=80, bias=True))\n  )\n  (act): GELU(approximate='none')\n  (drop): Dropout(p=0.0, inplace=False)\n  (head): Linear(in_features=80, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"val_acc, test_acc = train(model, dataset, criterion, optimizer, cfg.max_epoches)\nExperements = ExperementsUpgrade(cfg,test_acc,val_acc,Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:42.867483Z","iopub.execute_input":"2024-06-20T22:27:42.868682Z","iopub.status.idle":"2024-06-20T22:27:46.248887Z","shell.execute_reply.started":"2024-06-20T22:27:42.868634Z","shell.execute_reply":"2024-06-20T22:27:46.247728Z"},"trusted":true},"execution_count":388,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/80 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9b0675676848a1865bd0c8e9e42a0e"}},"metadata":{}},{"name":"stdout","text":"0.138\n0.644\n0.692\n0.758\n0.772\n0.774\n0.78\n0.784\nTest Score 0.779\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(Experements)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T22:27:46.250833Z","iopub.execute_input":"2024-06-20T22:27:46.251156Z","iopub.status.idle":"2024-06-20T22:27:46.278158Z","shell.execute_reply.started":"2024-06-20T22:27:46.251128Z","shell.execute_reply":"2024-06-20T22:27:46.277036Z"},"trusted":true},"execution_count":389,"outputs":[{"execution_count":389,"output_type":"execute_result","data":{"text/plain":"    epoches      lr  drop          depths   act  weight_decay  test_score  \\\n0       200  0.0003   0.0      [3703, 64]  gelu        0.0002       0.775   \n1       150  0.0003   0.0      [3703, 64]  gelu        0.0002       0.781   \n2       175  0.0003   0.0      [3703, 64]  gelu        0.0002       0.777   \n3       125  0.0003   0.0      [3703, 64]  gelu        0.0002       0.787   \n4       100  0.0003   0.0      [3703, 64]  gelu        0.0002       0.792   \n5        75  0.0003   0.0      [3703, 64]  gelu        0.0002       0.774   \n6       100  0.0003   0.0     [3703, 128]  gelu        0.0002       0.790   \n7        75  0.0003   0.0     [3703, 128]  gelu        0.0002       0.783   \n8       125  0.0003   0.0     [3703, 128]  gelu        0.0002       0.778   \n9       100  0.0003   0.0  [3703, 64, 32]  gelu        0.0002       0.775   \n10      150  0.0003   0.0     [3703, 128]  gelu        0.0002       0.778   \n11      100  0.0003   0.0      [3703, 32]  gelu        0.0002       0.775   \n12      100  0.0003   0.0      [3703, 80]  gelu        0.0002       0.785   \n13       80  0.0003   0.0      [3703, 80]  gelu        0.0002       0.779   \n\n    val_score  \n0       0.766  \n1       0.774  \n2       0.772  \n3       0.770  \n4       0.774  \n5       0.780  \n6       0.774  \n7       0.778  \n8       0.774  \n9       0.772  \n10      0.774  \n11      0.770  \n12      0.784  \n13      0.784  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoches</th>\n      <th>lr</th>\n      <th>drop</th>\n      <th>depths</th>\n      <th>act</th>\n      <th>weight_decay</th>\n      <th>test_score</th>\n      <th>val_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.775</td>\n      <td>0.766</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.781</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>175</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.777</td>\n      <td>0.772</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>125</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.787</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.792</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>75</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.774</td>\n      <td>0.780</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.790</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>75</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.783</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>125</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.778</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 64, 32]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.775</td>\n      <td>0.772</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>150</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 128]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.778</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 32]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.775</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>100</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 80]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.785</td>\n      <td>0.784</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>80</td>\n      <td>0.0003</td>\n      <td>0.0</td>\n      <td>[3703, 80]</td>\n      <td>gelu</td>\n      <td>0.0002</td>\n      <td>0.779</td>\n      <td>0.784</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}