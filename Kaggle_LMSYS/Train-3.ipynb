{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4224c2d0-e7ad-409c-bdad-ad53cb494f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from src import CustomLLamaForSeqClassification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from transformers import get_cosine_schedule_with_warmup,get_linear_schedule_with_warmup, AutoModel, AutoTokenizer, AutoModelForMultipleChoice, AutoConfig\n",
    "import wandb\n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cc43d0-8925-481f-b86c-f3b3436e7ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e31bcc70cfd457da94b47898e9be6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login() #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 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10758924-0ad8-4441-93f9-f40c456bcf23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89374ef-836d-47de-a29c-380cc6437c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    class data:\n",
    "        train_path = 'lmsys-chatbot-arena/train.csv'\n",
    "        tokenizer = 'meta-llama/Meta-Llama-3-8B'\n",
    "        num_workers = 8\n",
    "        nfolds = 5\n",
    "        batch_size = 4\n",
    "        use_prefix = False\n",
    "        max_length_prompt = 150\n",
    "        max_length_response = 600\n",
    "        max_length = 150 + 600 + 600 + 10\n",
    "        seed = 56\n",
    "    class model:\n",
    "        model = 'meta-llama/Meta-Llama-3-8B'\n",
    "        optim = torch.optim.AdamW\n",
    "        num_labels = 3\n",
    "        torch_dtype = torch.bfloat16\n",
    "        scheduler= 'cosine'\n",
    "        warnap_steps = 0.0 #0.25\n",
    "        label_smoothing = 0.0\n",
    "        pool = 'last_token'\n",
    "        max_epoches = 5\n",
    "        cls_drop_type = None\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        cls_drop = 0.0\n",
    "        lr_fn = 1e-4\n",
    "        lr = 1e-4\n",
    "        turn_off_drop = True\n",
    "        num_cycles = 0.5\n",
    "        eps = 1e-7\n",
    "        weight_decay = 0.0\n",
    "        weight_decay_fn = 0.0\n",
    "        betas = (0.9, 0.999)\n",
    "        use_lora = True\n",
    "        class lora:\n",
    "            r = 16\n",
    "            lora_alpha = 32\n",
    "            lora_dropout = 0.0\n",
    "            bias = 'none'\n",
    "            use_dora = False\n",
    "            target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"]\n",
    "    seed = 56\n",
    "    fold_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad99276c-f909-4c51-89fd-026d8c79d6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(path):\n",
    "    data = pd.read_csv(path)\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = data['id']\n",
    "    df['label'] = data.apply(lambda x: np.argmax([x.winner_model_a, x.winner_model_b, x.winner_tie]),axis=1)\n",
    "    \n",
    "    df['prompt'] = data['prompt'].apply(eval)\n",
    "    df['prompt'] = df['prompt'].apply(lambda x: ' Next Sentence: '.join(x))\n",
    "    \n",
    "    data['response_a'] = data['response_a'].apply(lambda x: x.replace('null',\"'null'\"))\n",
    "    df['response_a'] = data['response_a'].apply(eval)\n",
    "    df['response_a'] = df['response_a'].apply(lambda x: ' Next Sentence: '.join(x))\n",
    "    \n",
    "    data['response_b'] = data['response_b'].apply(lambda x: x.replace('null',\"'null'\"))\n",
    "    df['response_b'] = data['response_b'].apply(eval)\n",
    "    df['response_b'] = df['response_b'].apply(lambda x: ' Next Sentence: '.join(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf90cffe-334d-468d-b135-3c2bd22fc977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _truc_text(self, text,max_length):\n",
    "        ids = self.tokenizer.encode(text,max_length=max_length,truncation=True,add_special_tokens=False)\n",
    "        return self.tokenizer.decode(ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        label, prompt, response_a, response_b = row['label'], row['prompt'], row['response_a'], row['response_b']\n",
    "        if np.random.random() > 100:\n",
    "            response_a, response_b = response_b, response_a\n",
    "            label = [1,0,2][label]\n",
    "        \n",
    "        prompt = self._truc_text(prompt, self.cfg.max_length_prompt)\n",
    "        response_a = self._truc_text(response_a, self.cfg.max_length_response)\n",
    "        response_b = self._truc_text(response_b, self.cfg.max_length_response)\n",
    "        \n",
    "        text = f\"Prompt {prompt} Response A: {response_a} Response B: {response_b}\"\n",
    "        \n",
    "        encode = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.cfg.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encode.input_ids.squeeze(0),\n",
    "            'attention_mask': encode.attention_mask.squeeze(0),\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31de29de-948e-4d76-832b-115bf12e26fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.is_setup = False\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        self.df = make_df(self.cfg.train_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg.tokenizer)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        kf = StratifiedKFold(n_splits=self.cfg.nfolds, shuffle=True, random_state=self.cfg.seed)\n",
    "        splits = [(x,y) for x,y in  kf.split(self.df,self.df['label'])][CFG.fold_number]\n",
    "        self.train_df, self.val_df = self.df.iloc[splits[0]], self.df.iloc[splits[1]]\n",
    "        self.train_dataset = PLDataset(self.train_df,self.tokenizer)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.tokenizer)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                         batch_size=self.cfg.batch_size,\n",
    "                         num_workers=self.cfg.num_workers,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa6905f-8bba-4a74-81b4-6e7f0ee09bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.preds = []\n",
    "        self.preds_pr = []\n",
    "        self.labels = []\n",
    "        self.history = []\n",
    "    \n",
    "    def update(self,y_t,y_p,y_pr):\n",
    "        self.labels += y_t\n",
    "        self.preds += y_p\n",
    "        self.preds_pr += y_pr\n",
    "        \n",
    "    def clean(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.preds_pr = []\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        metrics = {}\n",
    "        metrics['accuracy'] = accuracy_score(self.labels, self.preds)\n",
    "        try:\n",
    "            metrics['log_loss'] = log_loss(self.labels, self.preds_pr)\n",
    "        except:\n",
    "            print('Metric Error')\n",
    "        self.history.append(metrics)\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd8a4c2-f354-4740-aad8-6f309604c61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.model = CustomLLamaForSeqClassification(self.cfg)\n",
    "        self.avg_meter = AverageMeter()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        output = self.model(**batch)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, i):\n",
    "        out = self(batch)\n",
    "        loss = out.loss\n",
    "        self.log('train_loss', loss.item())\n",
    "        return loss\n",
    "            \n",
    "    def validation_step(self, batch, i):\n",
    "        out = self(batch)\n",
    "        loss = out.loss\n",
    "        self.log('val_loss',loss.item())\n",
    "        preds = out.logits.argmax(dim=-1).tolist()\n",
    "        self.avg_meter.update(batch['labels'].tolist(),preds,out.logits.tolist())\n",
    "    \n",
    "    def predict_step(self, batch, i):\n",
    "        out = self(batch)\n",
    "        logits = out.logits\n",
    "        return logits.argmax(dim=-1).tolist()\n",
    "                \n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.avg_meter.calc_metrics()\n",
    "        self.log_dict(metrics)\n",
    "        self.avg_meter.clean()\n",
    "            \n",
    "    def configure_optimizers(self):        \n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in self.model.model.named_parameters() if not any(nd in n for nd in self.cfg.no_decay)],\n",
    "             'lr': self.cfg.lr, 'weight_decay': self.cfg.weight_decay},\n",
    "            {'params': [p for n, p in self.model.model.named_parameters() if any(nd in n for nd in self.cfg.no_decay)],\n",
    "             'lr': self.cfg.lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if \"model\" not in n],\n",
    "             'lr': self.cfg.lr_fn, 'weight_decay': self.cfg.weight_decay_fn}\n",
    "        ]\n",
    "        \n",
    "        optim = self.cfg.optim(\n",
    "            optimizer_parameters,\n",
    "            lr=self.cfg.lr,\n",
    "            betas=self.cfg.betas,\n",
    "            weight_decay=self.cfg.weight_decay,\n",
    "            eps=self.cfg.eps\n",
    "        )\n",
    "        \n",
    "        if self.cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warnap_steps,\n",
    "                                                        num_cycles=self.cfg.num_cycles)\n",
    "        elif self.cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warnap_steps)\n",
    "        else:\n",
    "            return optim\n",
    "        \n",
    "        scheduler = {'scheduler': scheduler,'interval': 'step', 'frequency': 1}\n",
    "\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7af8fd-25f2-401c-af57-d2cbd9f2afb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86eee930cfa74a239aeef0645890666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e05bfaedb5545a09e9eea1a44fea8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7e5dd9a5914ff0bf94ea1ac91d3628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa3e24b-d572-41da-b012-ba100987da00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG.model.num_training_steps = len(dm.train_dataloader()) * CFG.model.max_epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ebed4-0956-4f1e-960e-1b3222f7a9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b99df9b73b49dbaab3101893945afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fbd7985ee24398bb9263a51a331c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046423ea46714d4db1b08d5e203f8d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9f50f7cdfc4f6187b8cb41bb8eb96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1597a9b71fb460ea2495a3797e02ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PLModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d066959-33c3-45dc-a3d7-3870ebf68034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.login(key=\"31520b01739d418e5d77a11fd8a79a70b189b8bc\")\n",
    "os.environ['WANDB_API_KEY'] = \"31520b01739d418e5d77a11fd8a79a70b189b8bc\"\n",
    "wandb.init(project='KAGGLE_LMSYS',name='llama31_lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35147838-b8f3-4664-97aa-69540fe642f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs/',\n",
    "    filename='model_{epoch:02d}-{accuracy:.4f}',\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision='bf16',\n",
    "    callbacks = [lr_monitor],#[lr_monitor,checkpoint_cb],\n",
    "    logger = pl.loggers.WandbLogger(save_code=True),\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=2,\n",
    "    enable_checkpointing=False,\n",
    "    min_epochs=1,\n",
    "    devices=1,\n",
    "    val_check_interval=0.25,\n",
    "    max_epochs=CFG.model.max_epoches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9a206-3e93-48b6-9b73-608cc0da80e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c7dd6-37a1-4614-ac45-4e26ae46207e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
