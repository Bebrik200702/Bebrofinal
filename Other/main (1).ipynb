{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time(x):\n",
    "    hour, minutes, seconds = x.split(':')\n",
    "    return int(hour) * 3600 + int(minutes) * 60 + int(seconds)\n",
    "\n",
    "df = pd.read_excel('../data/разметка 1 тайм.xlsx')\n",
    "df['time'] = df['time'].apply(change_time)\n",
    "\n",
    "s = {x: y for x,y in zip(df['time'], df['action'])}\n",
    "max_value = df['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20226757369614512\n",
      "0.20272108843537415\n",
      "0.20317460317460317\n",
      "0.2036281179138322\n",
      "0.20408163265306123\n",
      "0.20453514739229026\n",
      "0.20498866213151928\n",
      "0.2054421768707483\n",
      "0.2058956916099773\n",
      "0.20634920634920634\n",
      "0.20680272108843537\n",
      "0.2072562358276644\n",
      "0.20770975056689342\n",
      "0.20816326530612245\n",
      "0.20861678004535147\n",
      "0.2090702947845805\n",
      "0.20952380952380953\n",
      "0.20997732426303856\n",
      "0.21043083900226758\n",
      "0.2108843537414966\n",
      "0.2113378684807256\n",
      "0.21179138321995464\n",
      "0.21224489795918366\n",
      "0.2126984126984127\n",
      "0.21315192743764172\n",
      "0.21360544217687075\n",
      "0.21405895691609977\n",
      "0.2145124716553288\n",
      "0.21496598639455783\n",
      "0.21541950113378686\n",
      "0.21587301587301588\n",
      "0.2163265306122449\n",
      "0.2167800453514739\n",
      "0.21723356009070294\n",
      "0.21768707482993196\n",
      "0.218140589569161\n",
      "0.21859410430839002\n",
      "0.21904761904761905\n",
      "0.21950113378684807\n",
      "0.2199546485260771\n",
      "0.22040816326530613\n",
      "0.22086167800453516\n",
      "0.22131519274376418\n",
      "0.2217687074829932\n",
      "0.2222222222222222\n",
      "0.22267573696145124\n",
      "0.22312925170068026\n",
      "0.2235827664399093\n",
      "0.22403628117913832\n",
      "0.22448979591836735\n",
      "0.22494331065759637\n",
      "0.2253968253968254\n",
      "0.22585034013605443\n",
      "0.22630385487528346\n",
      "0.22675736961451248\n",
      "0.2272108843537415\n",
      "0.2276643990929705\n",
      "0.22811791383219954\n",
      "0.22857142857142856\n",
      "0.2290249433106576\n",
      "0.22947845804988662\n",
      "0.22993197278911565\n",
      "0.23038548752834467\n",
      "0.2308390022675737\n",
      "0.23129251700680273\n",
      "0.23174603174603176\n",
      "0.23219954648526078\n",
      "0.23265306122448978\n",
      "0.2331065759637188\n",
      "0.23356009070294784\n",
      "0.23401360544217686\n",
      "0.2344671201814059\n",
      "0.23492063492063492\n",
      "0.23537414965986395\n",
      "0.23582766439909297\n",
      "0.236281179138322\n",
      "0.23673469387755103\n",
      "0.23718820861678006\n",
      "0.23764172335600908\n",
      "0.23809523809523808\n",
      "0.2385487528344671\n",
      "0.23900226757369614\n",
      "0.23945578231292516\n",
      "0.2399092970521542\n",
      "0.24036281179138322\n",
      "0.24081632653061225\n",
      "0.24126984126984127\n",
      "0.2417233560090703\n",
      "0.24217687074829933\n",
      "0.24263038548752835\n",
      "0.24308390022675738\n",
      "0.24353741496598638\n",
      "0.2439909297052154\n",
      "0.24444444444444444\n",
      "0.24489795918367346\n",
      "0.2453514739229025\n",
      "0.24580498866213152\n",
      "0.24625850340136055\n",
      "0.24671201814058957\n",
      "0.2471655328798186\n",
      "0.24761904761904763\n",
      "0.24807256235827665\n",
      "0.24852607709750568\n",
      "0.24897959183673468\n",
      "0.2494331065759637\n",
      "0.24988662131519274\n",
      "0.2503401360544218\n",
      "0.2507936507936508\n",
      "0.25124716553287985\n",
      "0.25170068027210885\n",
      "0.25215419501133784\n",
      "0.2526077097505669\n",
      "0.2530612244897959\n",
      "0.25351473922902495\n",
      "0.25396825396825395\n",
      "0.254421768707483\n",
      "0.254875283446712\n",
      "0.25532879818594106\n",
      "0.25578231292517006\n",
      "0.2562358276643991\n",
      "0.2566893424036281\n",
      "0.2571428571428571\n",
      "0.2575963718820862\n",
      "0.25804988662131517\n",
      "0.2585034013605442\n",
      "0.2589569160997732\n",
      "0.2594104308390023\n",
      "0.2598639455782313\n",
      "0.26031746031746034\n",
      "0.26077097505668934\n",
      "0.2612244897959184\n",
      "0.2616780045351474\n",
      "0.2621315192743764\n",
      "0.26258503401360545\n",
      "0.26303854875283444\n",
      "0.2634920634920635\n",
      "0.2639455782312925\n",
      "0.26439909297052155\n",
      "0.26485260770975055\n",
      "0.2653061224489796\n",
      "0.2657596371882086\n",
      "0.26621315192743766\n",
      "0.26666666666666666\n",
      "0.2671201814058957\n",
      "0.2675736961451247\n",
      "0.2680272108843537\n",
      "0.26848072562358277\n",
      "0.26893424036281177\n",
      "0.2693877551020408\n",
      "0.2698412698412698\n",
      "0.2702947845804989\n",
      "0.2707482993197279\n",
      "0.27120181405895694\n",
      "0.27165532879818594\n",
      "0.272108843537415\n",
      "0.272562358276644\n",
      "0.273015873015873\n",
      "0.27346938775510204\n",
      "0.27392290249433104\n",
      "0.2743764172335601\n",
      "0.2748299319727891\n",
      "0.27528344671201815\n",
      "0.27573696145124715\n",
      "0.2761904761904762\n",
      "0.2766439909297052\n",
      "0.27709750566893426\n",
      "0.27755102040816326\n",
      "0.2780045351473923\n",
      "0.2784580498866213\n",
      "0.2789115646258503\n",
      "0.27936507936507937\n",
      "0.27981859410430837\n",
      "0.2802721088435374\n",
      "0.2807256235827664\n",
      "0.2811791383219955\n",
      "0.2816326530612245\n",
      "0.28208616780045354\n",
      "0.28253968253968254\n",
      "0.2829931972789116\n",
      "0.2834467120181406\n",
      "0.2839002267573696\n",
      "0.28435374149659864\n",
      "0.28480725623582764\n",
      "0.2852607709750567\n",
      "0.2857142857142857\n",
      "0.28616780045351475\n",
      "0.28662131519274375\n",
      "0.2870748299319728\n",
      "0.2875283446712018\n",
      "0.28798185941043086\n",
      "0.28843537414965986\n",
      "0.28888888888888886\n",
      "0.2893424036281179\n",
      "0.2897959183673469\n",
      "0.29024943310657597\n",
      "0.29070294784580497\n",
      "0.291156462585034\n",
      "0.291609977324263\n",
      "0.2920634920634921\n",
      "0.2925170068027211\n",
      "0.29297052154195014\n",
      "0.29342403628117913\n",
      "0.2938775510204082\n",
      "0.2943310657596372\n",
      "0.2947845804988662\n",
      "0.29523809523809524\n",
      "0.29569160997732424\n",
      "0.2961451247165533\n",
      "0.2965986394557823\n",
      "0.29705215419501135\n",
      "0.29750566893424035\n",
      "0.2979591836734694\n",
      "0.2984126984126984\n",
      "0.29886621315192746\n",
      "0.29931972789115646\n",
      "0.29977324263038546\n",
      "0.3002267573696145\n",
      "0.3006802721088435\n",
      "0.30113378684807257\n",
      "0.30158730158730157\n",
      "0.3020408163265306\n",
      "0.3024943310657596\n",
      "0.3029478458049887\n",
      "0.3034013605442177\n",
      "0.30385487528344673\n",
      "0.30430839002267573\n",
      "0.3047619047619048\n",
      "0.3052154195011338\n",
      "0.3056689342403628\n",
      "0.30612244897959184\n",
      "0.30657596371882084\n",
      "0.3070294784580499\n",
      "0.3074829931972789\n",
      "0.30793650793650795\n",
      "0.30839002267573695\n",
      "0.308843537414966\n",
      "0.309297052154195\n",
      "0.30975056689342406\n",
      "0.31020408163265306\n",
      "0.31065759637188206\n",
      "0.3111111111111111\n",
      "0.3115646258503401\n",
      "0.31201814058956917\n",
      "0.31247165532879817\n",
      "0.3129251700680272\n",
      "0.3133786848072562\n",
      "0.3138321995464853\n",
      "0.3142857142857143\n",
      "0.31473922902494333\n",
      "0.31519274376417233\n",
      "0.31564625850340133\n",
      "0.3160997732426304\n",
      "0.3165532879818594\n",
      "0.31700680272108844\n",
      "0.31746031746031744\n",
      "0.3179138321995465\n",
      "0.3183673469387755\n",
      "0.31882086167800455\n",
      "0.31927437641723355\n",
      "0.3197278911564626\n",
      "0.3201814058956916\n",
      "0.32063492063492066\n",
      "0.32108843537414966\n",
      "0.32154195011337866\n",
      "0.3219954648526077\n",
      "0.3224489795918367\n",
      "0.32290249433106577\n",
      "0.32335600907029477\n",
      "0.3238095238095238\n",
      "0.3242630385487528\n",
      "0.3247165532879819\n",
      "0.3251700680272109\n",
      "0.32562358276643993\n",
      "0.32607709750566893\n",
      "0.32653061224489793\n",
      "0.326984126984127\n",
      "0.327437641723356\n",
      "0.32789115646258504\n",
      "0.32834467120181404\n",
      "0.3287981859410431\n",
      "0.3292517006802721\n",
      "0.32970521541950115\n",
      "0.33015873015873015\n",
      "0.3306122448979592\n",
      "0.3310657596371882\n",
      "0.33151927437641726\n",
      "0.33197278911564626\n",
      "0.33242630385487526\n",
      "0.3328798185941043\n",
      "0.3333333333333333\n",
      "0.33378684807256237\n",
      "0.33424036281179137\n",
      "0.3346938775510204\n",
      "0.3351473922902494\n",
      "0.3356009070294785\n",
      "0.3360544217687075\n",
      "0.33650793650793653\n",
      "0.33696145124716553\n",
      "0.33741496598639453\n",
      "0.3378684807256236\n",
      "0.3383219954648526\n",
      "0.33877551020408164\n",
      "0.33922902494331064\n",
      "0.3396825396825397\n",
      "0.3401360544217687\n",
      "0.34058956916099775\n",
      "0.34104308390022675\n",
      "0.3414965986394558\n",
      "0.3419501133786848\n",
      "0.3424036281179138\n",
      "0.34285714285714286\n",
      "0.34331065759637186\n",
      "0.3437641723356009\n",
      "0.3442176870748299\n",
      "0.34467120181405897\n",
      "0.34512471655328797\n",
      "0.345578231292517\n",
      "0.346031746031746\n",
      "0.3464852607709751\n",
      "0.3469387755102041\n",
      "0.34739229024943313\n",
      "0.34784580498866213\n",
      "0.34829931972789113\n",
      "0.3487528344671202\n",
      "0.3492063492063492\n",
      "0.34965986394557824\n",
      "0.35011337868480724\n",
      "0.3505668934240363\n",
      "0.3510204081632653\n",
      "0.35147392290249435\n",
      "0.35192743764172335\n",
      "0.3523809523809524\n",
      "0.3528344671201814\n",
      "0.3532879818594104\n",
      "0.35374149659863946\n",
      "0.35419501133786846\n",
      "0.3546485260770975\n",
      "0.3551020408163265\n",
      "0.35555555555555557\n",
      "0.35600907029478457\n",
      "0.3564625850340136\n",
      "0.3569160997732426\n",
      "0.3573696145124717\n",
      "0.3578231292517007\n",
      "0.35827664399092973\n",
      "0.35873015873015873\n",
      "0.35918367346938773\n",
      "0.3596371882086168\n",
      "0.3600907029478458\n",
      "0.36054421768707484\n",
      "0.36099773242630384\n",
      "0.3614512471655329\n",
      "0.3619047619047619\n",
      "0.36235827664399095\n",
      "0.36281179138321995\n",
      "0.363265306122449\n",
      "0.363718820861678\n",
      "0.364172335600907\n",
      "0.36462585034013606\n",
      "0.36507936507936506\n",
      "0.3655328798185941\n",
      "0.3659863945578231\n",
      "0.36643990929705217\n",
      "0.36689342403628117\n",
      "0.3673469387755102\n",
      "0.3678004535147392\n",
      "0.3682539682539683\n",
      "0.3687074829931973\n",
      "0.3691609977324263\n",
      "0.36961451247165533\n",
      "0.37006802721088433\n",
      "0.3705215419501134\n",
      "0.3709750566893424\n",
      "0.37142857142857144\n",
      "0.37188208616780044\n",
      "0.3723356009070295\n",
      "0.3727891156462585\n",
      "0.37324263038548755\n",
      "0.37369614512471655\n",
      "0.3741496598639456\n",
      "0.3746031746031746\n",
      "0.3750566893424036\n",
      "0.37551020408163266\n",
      "0.37596371882086166\n",
      "0.3764172335600907\n",
      "0.3768707482993197\n",
      "0.37732426303854877\n",
      "0.37777777777777777\n",
      "0.3782312925170068\n",
      "0.3786848072562358\n",
      "0.3791383219954649\n",
      "0.3795918367346939\n",
      "0.3800453514739229\n",
      "0.38049886621315193\n",
      "0.38095238095238093\n",
      "0.38140589569161\n",
      "0.381859410430839\n",
      "0.38231292517006804\n",
      "0.38276643990929704\n",
      "0.3832199546485261\n",
      "0.3836734693877551\n",
      "0.38412698412698415\n",
      "0.38458049886621315\n",
      "0.38503401360544215\n",
      "0.3854875283446712\n",
      "0.3859410430839002\n",
      "0.38639455782312926\n",
      "0.38684807256235826\n",
      "0.3873015873015873\n",
      "0.3877551020408163\n",
      "0.38820861678004537\n",
      "0.38866213151927437\n",
      "0.3891156462585034\n",
      "0.3895691609977324\n",
      "0.3900226757369615\n",
      "0.3904761904761905\n",
      "0.3909297052154195\n",
      "0.39138321995464853\n",
      "0.39183673469387753\n",
      "0.3922902494331066\n",
      "0.3927437641723356\n",
      "0.39319727891156464\n",
      "0.39365079365079364\n",
      "0.3941043083900227\n",
      "0.3945578231292517\n",
      "0.39501133786848075\n",
      "0.39546485260770975\n",
      "0.39591836734693875\n",
      "0.3963718820861678\n",
      "0.3968253968253968\n",
      "0.39727891156462586\n",
      "0.39773242630385486\n",
      "0.3981859410430839\n",
      "0.3986394557823129\n",
      "0.39909297052154197\n",
      "0.39954648526077097\n",
      "0.4\n",
      "0.400453514739229\n",
      "0.4009070294784581\n",
      "0.4013605442176871\n",
      "0.4018140589569161\n",
      "0.40226757369614513\n",
      "0.40272108843537413\n",
      "0.4031746031746032\n",
      "0.4036281179138322\n",
      "0.40408163265306124\n",
      "0.40453514739229024\n",
      "0.4049886621315193\n",
      "0.4054421768707483\n",
      "0.40589569160997735\n",
      "0.40634920634920635\n",
      "0.40680272108843535\n",
      "0.4072562358276644\n",
      "0.4077097505668934\n",
      "0.40816326530612246\n",
      "0.40861678004535146\n",
      "0.4090702947845805\n",
      "0.4095238095238095\n",
      "0.40997732426303857\n",
      "0.41043083900226757\n",
      "0.4108843537414966\n",
      "0.4113378684807256\n",
      "0.4117913832199546\n",
      "0.4122448979591837\n",
      "0.4126984126984127\n",
      "0.41315192743764173\n",
      "0.41360544217687073\n",
      "0.4140589569160998\n",
      "0.4145124716553288\n",
      "0.41496598639455784\n",
      "0.41541950113378684\n",
      "0.4158730158730159\n",
      "0.4163265306122449\n",
      "0.41678004535147395\n",
      "0.41723356009070295\n",
      "0.41768707482993195\n",
      "0.418140589569161\n",
      "0.41859410430839\n",
      "0.41904761904761906\n",
      "0.41950113378684806\n",
      "0.4199546485260771\n",
      "0.4204081632653061\n",
      "0.42086167800453517\n",
      "0.42131519274376417\n",
      "0.4217687074829932\n",
      "0.4222222222222222\n",
      "0.4226757369614512\n",
      "0.4231292517006803\n",
      "0.4235827664399093\n",
      "0.42403628117913833\n",
      "0.42448979591836733\n",
      "0.4249433106575964\n",
      "0.4253968253968254\n",
      "0.42585034013605444\n",
      "0.42630385487528344\n",
      "0.4267573696145125\n",
      "0.4272108843537415\n",
      "0.42766439909297055\n",
      "0.42811791383219955\n",
      "0.42857142857142855\n",
      "0.4290249433106576\n",
      "0.4294784580498866\n",
      "0.42993197278911566\n",
      "0.43038548752834466\n",
      "0.4308390022675737\n",
      "0.4312925170068027\n",
      "0.43174603174603177\n",
      "0.43219954648526077\n",
      "0.4326530612244898\n",
      "0.4331065759637188\n",
      "0.4335600907029478\n",
      "0.4340136054421769\n",
      "0.4344671201814059\n",
      "0.43492063492063493\n",
      "0.43537414965986393\n",
      "0.435827664399093\n",
      "0.436281179138322\n",
      "0.43673469387755104\n",
      "0.43718820861678004\n",
      "0.4376417233560091\n",
      "0.4380952380952381\n",
      "0.4385487528344671\n",
      "0.43900226757369615\n",
      "0.43945578231292515\n",
      "0.4399092970521542\n",
      "0.4403628117913832\n",
      "0.44081632653061226\n",
      "0.44126984126984126\n",
      "0.4417233560090703\n",
      "0.4421768707482993\n",
      "0.44263038548752837\n",
      "0.44308390022675737\n",
      "0.4435374149659864\n",
      "0.4439909297052154\n",
      "0.4444444444444444\n",
      "0.4448979591836735\n",
      "0.4453514739229025\n",
      "0.44580498866213153\n",
      "0.44625850340136053\n",
      "0.4467120181405896\n",
      "0.4471655328798186\n",
      "0.44761904761904764\n",
      "0.44807256235827664\n",
      "0.4485260770975057\n",
      "0.4489795918367347\n",
      "0.4494331065759637\n",
      "0.44988662131519275\n",
      "0.45034013605442175\n",
      "0.4507936507936508\n",
      "0.4512471655328798\n",
      "0.45170068027210886\n",
      "0.45215419501133786\n",
      "0.4526077097505669\n",
      "0.4530612244897959\n",
      "0.45351473922902497\n",
      "0.45396825396825397\n",
      "0.454421768707483\n",
      "0.454875283446712\n",
      "0.455328798185941\n",
      "0.4557823129251701\n",
      "0.4562358276643991\n",
      "0.45668934240362813\n",
      "0.45714285714285713\n",
      "0.4575963718820862\n",
      "0.4580498866213152\n",
      "0.45850340136054424\n",
      "0.45895691609977324\n",
      "0.4594104308390023\n",
      "0.4598639455782313\n",
      "0.4603174603174603\n",
      "0.46077097505668935\n",
      "0.46122448979591835\n",
      "0.4616780045351474\n",
      "0.4621315192743764\n",
      "0.46258503401360546\n",
      "0.46303854875283446\n",
      "0.4634920634920635\n",
      "0.4639455782312925\n",
      "0.46439909297052157\n",
      "0.46485260770975056\n",
      "0.46530612244897956\n",
      "0.4657596371882086\n",
      "0.4662131519274376\n",
      "0.4666666666666667\n",
      "0.4671201814058957\n",
      "0.46757369614512473\n",
      "0.46802721088435373\n",
      "0.4684807256235828\n",
      "0.4689342403628118\n",
      "0.46938775510204084\n",
      "0.46984126984126984\n",
      "0.4702947845804989\n",
      "0.4707482993197279\n",
      "0.4712018140589569\n",
      "0.47165532879818595\n",
      "0.47210884353741495\n",
      "0.472562358276644\n",
      "0.473015873015873\n",
      "0.47346938775510206\n",
      "0.47392290249433106\n",
      "0.4743764172335601\n",
      "0.4748299319727891\n",
      "0.47528344671201816\n",
      "0.47573696145124716\n",
      "0.47619047619047616\n",
      "0.4766439909297052\n",
      "0.4770975056689342\n",
      "0.4775510204081633\n",
      "0.4780045351473923\n",
      "0.47845804988662133\n",
      "0.47891156462585033\n",
      "0.4793650793650794\n",
      "0.4798185941043084\n",
      "0.48027210884353744\n",
      "0.48072562358276644\n",
      "0.4811791383219955\n",
      "0.4816326530612245\n",
      "0.4820861678004535\n",
      "0.48253968253968255\n",
      "0.48299319727891155\n",
      "0.4834467120181406\n",
      "0.4839002267573696\n",
      "0.48435374149659866\n",
      "0.48480725623582765\n",
      "0.4852607709750567\n",
      "0.4857142857142857\n",
      "0.48616780045351476\n",
      "0.48662131519274376\n",
      "0.48707482993197276\n",
      "0.4875283446712018\n",
      "0.4879818594104308\n",
      "0.4884353741496599\n",
      "0.4888888888888889\n",
      "0.48934240362811793\n",
      "0.4897959183673469\n",
      "0.490249433106576\n",
      "0.490702947845805\n",
      "0.49115646258503404\n",
      "0.49160997732426304\n",
      "0.49206349206349204\n",
      "0.4925170068027211\n",
      "0.4929705215419501\n",
      "0.49342403628117915\n",
      "0.49387755102040815\n",
      "0.4943310657596372\n",
      "0.4947845804988662\n",
      "0.49523809523809526\n",
      "0.49569160997732425\n",
      "0.4961451247165533\n",
      "0.4965986394557823\n",
      "0.49705215419501136\n",
      "0.49750566893424036\n",
      "0.49795918367346936\n",
      "0.4984126984126984\n",
      "0.4988662131519274\n",
      "0.4993197278911565\n",
      "0.4997732426303855\n",
      "0.5002267573696145\n",
      "0.5006802721088436\n",
      "0.5011337868480725\n",
      "0.5015873015873016\n",
      "0.5020408163265306\n",
      "0.5024943310657597\n",
      "0.5029478458049886\n",
      "0.5034013605442177\n",
      "0.5038548752834467\n",
      "0.5043083900226757\n",
      "0.5047619047619047\n",
      "0.5052154195011338\n",
      "0.5056689342403629\n",
      "0.5061224489795918\n",
      "0.5065759637188209\n",
      "0.5070294784580499\n",
      "0.507482993197279\n",
      "0.5079365079365079\n",
      "0.508390022675737\n",
      "0.508843537414966\n",
      "0.509297052154195\n",
      "0.509750566893424\n",
      "0.5102040816326531\n",
      "0.5106575963718821\n",
      "0.5111111111111111\n",
      "0.5115646258503401\n",
      "0.5120181405895692\n",
      "0.5124716553287982\n",
      "0.5129251700680272\n",
      "0.5133786848072562\n",
      "0.5138321995464853\n",
      "0.5142857142857142\n",
      "0.5147392290249433\n",
      "0.5151927437641723\n",
      "0.5156462585034014\n",
      "0.5160997732426303\n",
      "0.5165532879818594\n",
      "0.5170068027210885\n",
      "0.5174603174603175\n",
      "0.5179138321995465\n",
      "0.5183673469387755\n",
      "0.5188208616780046\n",
      "0.5192743764172335\n",
      "0.5197278911564626\n",
      "0.5201814058956916\n",
      "0.5206349206349207\n",
      "0.5210884353741496\n",
      "0.5215419501133787\n",
      "0.5219954648526077\n",
      "0.5224489795918368\n",
      "0.5229024943310657\n",
      "0.5233560090702948\n",
      "0.5238095238095238\n",
      "0.5242630385487528\n",
      "0.5247165532879818\n",
      "0.5251700680272109\n",
      "0.52562358276644\n",
      "0.5260770975056689\n",
      "0.5265306122448979\n",
      "0.526984126984127\n",
      "0.527437641723356\n",
      "0.527891156462585\n",
      "0.528344671201814\n",
      "0.5287981859410431\n",
      "0.5292517006802722\n",
      "0.5297052154195011\n",
      "0.5301587301587302\n",
      "0.5306122448979592\n",
      "0.5310657596371882\n",
      "0.5315192743764172\n",
      "0.5319727891156463\n",
      "0.5324263038548753\n",
      "0.5328798185941043\n",
      "0.5333333333333333\n",
      "0.5337868480725624\n",
      "0.5342403628117914\n",
      "0.5346938775510204\n",
      "0.5351473922902494\n",
      "0.5356009070294785\n",
      "0.5360544217687074\n",
      "0.5365079365079365\n",
      "0.5369614512471655\n",
      "0.5374149659863946\n",
      "0.5378684807256235\n",
      "0.5383219954648526\n",
      "0.5387755102040817\n",
      "0.5392290249433107\n",
      "0.5396825396825397\n",
      "0.5401360544217687\n",
      "0.5405895691609978\n",
      "0.5410430839002267\n",
      "0.5414965986394558\n",
      "0.5419501133786848\n",
      "0.5424036281179139\n",
      "0.5428571428571428\n",
      "0.5433106575963719\n",
      "0.5437641723356009\n",
      "0.54421768707483\n",
      "0.5446712018140589\n",
      "0.545124716553288\n",
      "0.545578231292517\n",
      "0.546031746031746\n",
      "0.546485260770975\n",
      "0.5469387755102041\n",
      "0.5473922902494331\n",
      "0.5478458049886621\n",
      "0.5482993197278911\n",
      "0.5487528344671202\n",
      "0.5492063492063493\n",
      "0.5496598639455782\n",
      "0.5501133786848073\n",
      "0.5505668934240363\n",
      "0.5510204081632653\n",
      "0.5514739229024943\n",
      "0.5519274376417234\n",
      "0.5523809523809524\n",
      "0.5528344671201814\n",
      "0.5532879818594104\n",
      "0.5537414965986395\n",
      "0.5541950113378685\n",
      "0.5546485260770975\n",
      "0.5551020408163265\n",
      "0.5555555555555556\n",
      "0.5560090702947846\n",
      "0.5564625850340136\n",
      "0.5569160997732426\n",
      "0.5573696145124717\n",
      "0.5578231292517006\n",
      "0.5582766439909297\n",
      "0.5587301587301587\n",
      "0.5591836734693878\n",
      "0.5596371882086167\n",
      "0.5600907029478458\n",
      "0.5605442176870749\n",
      "0.5609977324263039\n",
      "0.5614512471655329\n",
      "0.5619047619047619\n",
      "0.562358276643991\n",
      "0.5628117913832199\n",
      "0.563265306122449\n",
      "0.563718820861678\n",
      "0.5641723356009071\n",
      "0.564625850340136\n",
      "0.5650793650793651\n",
      "0.5655328798185941\n",
      "0.5659863945578232\n",
      "0.5664399092970521\n",
      "0.5668934240362812\n",
      "0.5673469387755102\n",
      "0.5678004535147392\n",
      "0.5682539682539682\n",
      "0.5687074829931973\n",
      "0.5691609977324263\n",
      "0.5696145124716553\n",
      "0.5700680272108843\n",
      "0.5705215419501134\n",
      "0.5709750566893425\n",
      "0.5714285714285714\n",
      "0.5718820861678005\n",
      "0.5723356009070295\n",
      "0.5727891156462585\n",
      "0.5732426303854875\n",
      "0.5736961451247166\n",
      "0.5741496598639456\n",
      "0.5746031746031746\n",
      "0.5750566893424036\n",
      "0.5755102040816327\n",
      "0.5759637188208617\n",
      "0.5764172335600907\n",
      "0.5768707482993197\n",
      "0.5773242630385488\n",
      "0.5777777777777777\n",
      "0.5782312925170068\n",
      "0.5786848072562358\n",
      "0.5791383219954649\n",
      "0.5795918367346938\n",
      "0.5800453514739229\n",
      "0.5804988662131519\n",
      "0.580952380952381\n",
      "0.5814058956916099\n",
      "0.581859410430839\n",
      "0.582312925170068\n",
      "0.5827664399092971\n",
      "0.583219954648526\n",
      "0.5836734693877551\n",
      "0.5841269841269842\n",
      "0.5845804988662131\n",
      "0.5850340136054422\n",
      "0.5854875283446712\n",
      "0.5859410430839003\n",
      "0.5863945578231292\n",
      "0.5868480725623583\n",
      "0.5873015873015873\n",
      "0.5877551020408164\n",
      "0.5882086167800453\n",
      "0.5886621315192744\n",
      "0.5891156462585034\n",
      "0.5895691609977324\n",
      "0.5900226757369614\n",
      "0.5904761904761905\n",
      "0.5909297052154195\n",
      "0.5913832199546485\n",
      "0.5918367346938775\n",
      "0.5922902494331066\n",
      "0.5927437641723357\n",
      "0.5931972789115646\n",
      "0.5936507936507937\n",
      "0.5941043083900227\n",
      "0.5945578231292517\n",
      "0.5950113378684807\n",
      "0.5954648526077098\n",
      "0.5959183673469388\n",
      "0.5963718820861678\n",
      "0.5968253968253968\n",
      "0.5972789115646259\n",
      "0.5977324263038549\n",
      "0.5981859410430839\n",
      "0.5986394557823129\n",
      "0.599092970521542\n",
      "0.5995464852607709\n",
      "0.6\n",
      "0.600453514739229\n",
      "0.6009070294784581\n",
      "0.601360544217687\n",
      "0.6018140589569161\n",
      "0.6022675736961451\n",
      "0.6027210884353742\n",
      "0.6031746031746031\n",
      "0.6036281179138322\n",
      "0.6040816326530613\n",
      "0.6045351473922902\n",
      "0.6049886621315193\n",
      "0.6054421768707483\n",
      "0.6058956916099774\n",
      "0.6063492063492063\n",
      "0.6068027210884354\n",
      "0.6072562358276644\n",
      "0.6077097505668935\n",
      "0.6081632653061224\n",
      "0.6086167800453515\n",
      "0.6090702947845805\n",
      "0.6095238095238096\n",
      "0.6099773242630385\n",
      "0.6104308390022676\n",
      "0.6108843537414966\n",
      "0.6113378684807256\n",
      "0.6117913832199546\n",
      "0.6122448979591837\n",
      "0.6126984126984127\n",
      "0.6131519274376417\n",
      "0.6136054421768707\n",
      "0.6140589569160998\n",
      "0.6145124716553289\n",
      "0.6149659863945578\n",
      "0.6154195011337869\n",
      "0.6158730158730159\n",
      "0.6163265306122448\n",
      "0.6167800453514739\n",
      "0.617233560090703\n",
      "0.617687074829932\n",
      "0.618140589569161\n",
      "0.61859410430839\n",
      "0.6190476190476191\n",
      "0.6195011337868481\n",
      "0.6199546485260771\n",
      "0.6204081632653061\n",
      "0.6208616780045352\n",
      "0.6213151927437641\n",
      "0.6217687074829932\n",
      "0.6222222222222222\n",
      "0.6226757369614513\n",
      "0.6231292517006802\n",
      "0.6235827664399093\n",
      "0.6240362811791383\n",
      "0.6244897959183674\n",
      "0.6249433106575963\n",
      "0.6253968253968254\n",
      "0.6258503401360545\n",
      "0.6263038548752834\n",
      "0.6267573696145124\n",
      "0.6272108843537415\n",
      "0.6276643990929706\n",
      "0.6281179138321995\n",
      "0.6285714285714286\n",
      "0.6290249433106576\n",
      "0.6294784580498867\n",
      "0.6299319727891156\n",
      "0.6303854875283447\n",
      "0.6308390022675737\n",
      "0.6312925170068027\n",
      "0.6317460317460317\n",
      "0.6321995464852608\n",
      "0.6326530612244898\n",
      "0.6331065759637188\n",
      "0.6335600907029478\n",
      "0.6340136054421769\n",
      "0.6344671201814059\n",
      "0.6349206349206349\n",
      "0.6353741496598639\n",
      "0.635827664399093\n",
      "0.636281179138322\n",
      "0.636734693877551\n",
      "0.63718820861678\n",
      "0.6376417233560091\n",
      "0.638095238095238\n",
      "0.6385487528344671\n",
      "0.6390022675736962\n",
      "0.6394557823129252\n",
      "0.6399092970521542\n",
      "0.6403628117913832\n",
      "0.6408163265306123\n",
      "0.6412698412698413\n",
      "0.6417233560090703\n",
      "0.6421768707482993\n",
      "0.6426303854875284\n",
      "0.6430839002267573\n",
      "0.6435374149659864\n",
      "0.6439909297052154\n",
      "0.6444444444444445\n",
      "0.6448979591836734\n",
      "0.6453514739229025\n",
      "0.6458049886621315\n",
      "0.6462585034013606\n",
      "0.6467120181405895\n",
      "0.6471655328798186\n",
      "0.6476190476190476\n",
      "0.6480725623582766\n",
      "0.6485260770975056\n",
      "0.6489795918367347\n",
      "0.6494331065759638\n",
      "0.6498866213151927\n",
      "0.6503401360544218\n",
      "0.6507936507936508\n",
      "0.6512471655328799\n",
      "0.6517006802721088\n",
      "0.6521541950113379\n",
      "0.6526077097505669\n",
      "0.6530612244897959\n",
      "0.6535147392290249\n",
      "0.653968253968254\n",
      "0.654421768707483\n",
      "0.654875283446712\n",
      "0.655328798185941\n",
      "0.6557823129251701\n",
      "0.6562358276643991\n",
      "0.6566893424036281\n",
      "0.6571428571428571\n",
      "0.6575963718820862\n",
      "0.6580498866213151\n",
      "0.6585034013605442\n",
      "0.6589569160997732\n",
      "0.6594104308390023\n",
      "0.6598639455782312\n",
      "0.6603174603174603\n",
      "0.6607709750566894\n",
      "0.6612244897959184\n",
      "0.6616780045351474\n",
      "0.6621315192743764\n",
      "0.6625850340136055\n",
      "0.6630385487528345\n",
      "0.6634920634920635\n",
      "0.6639455782312925\n",
      "0.6643990929705216\n",
      "0.6648526077097505\n",
      "0.6653061224489796\n",
      "0.6657596371882086\n",
      "0.6662131519274377\n",
      "0.6666666666666666\n",
      "0.6671201814058957\n",
      "0.6675736961451247\n",
      "0.6680272108843538\n",
      "0.6684807256235827\n",
      "0.6689342403628118\n",
      "0.6693877551020408\n",
      "0.6698412698412698\n",
      "0.6702947845804988\n",
      "0.6707482993197279\n",
      "0.671201814058957\n",
      "0.6716553287981859\n",
      "0.672108843537415\n",
      "0.672562358276644\n",
      "0.6730158730158731\n",
      "0.673469387755102\n",
      "0.6739229024943311\n",
      "0.6743764172335601\n",
      "0.6748299319727891\n",
      "0.6752834467120181\n",
      "0.6757369614512472\n",
      "0.6761904761904762\n",
      "0.6766439909297052\n",
      "0.6770975056689342\n",
      "0.6775510204081633\n",
      "0.6780045351473923\n",
      "0.6784580498866213\n",
      "0.6789115646258503\n",
      "0.6793650793650794\n",
      "0.6798185941043083\n",
      "0.6802721088435374\n",
      "0.6807256235827664\n",
      "0.6811791383219955\n",
      "0.6816326530612244\n",
      "0.6820861678004535\n",
      "0.6825396825396826\n",
      "0.6829931972789116\n",
      "0.6834467120181406\n",
      "0.6839002267573696\n",
      "0.6843537414965987\n",
      "0.6848072562358276\n",
      "0.6852607709750567\n",
      "0.6857142857142857\n",
      "0.6861678004535148\n",
      "0.6866213151927437\n",
      "0.6870748299319728\n",
      "0.6875283446712018\n",
      "0.6879818594104309\n",
      "0.6884353741496598\n",
      "0.6888888888888889\n",
      "0.6893424036281179\n",
      "0.689795918367347\n",
      "0.6902494331065759\n",
      "0.690702947845805\n",
      "0.691156462585034\n",
      "0.691609977324263\n",
      "0.692063492063492\n",
      "0.6925170068027211\n",
      "0.6929705215419502\n",
      "0.6934240362811791\n",
      "0.6938775510204082\n",
      "0.6943310657596372\n",
      "0.6947845804988663\n",
      "0.6952380952380952\n",
      "0.6956916099773243\n",
      "0.6961451247165533\n",
      "0.6965986394557823\n",
      "0.6970521541950113\n",
      "0.6975056689342404\n",
      "0.6979591836734694\n",
      "0.6984126984126984\n",
      "0.6988662131519274\n",
      "0.6993197278911565\n",
      "0.6997732426303855\n",
      "0.7002267573696145\n",
      "0.7006802721088435\n",
      "0.7011337868480726\n",
      "0.7015873015873015\n",
      "0.7020408163265306\n",
      "0.7024943310657596\n",
      "0.7029478458049887\n",
      "0.7034013605442176\n",
      "0.7038548752834467\n",
      "0.7043083900226758\n",
      "0.7047619047619048\n",
      "0.7052154195011338\n",
      "0.7056689342403628\n",
      "0.7061224489795919\n",
      "0.7065759637188208\n",
      "0.7070294784580499\n",
      "0.7074829931972789\n",
      "0.707936507936508\n",
      "0.7083900226757369\n",
      "0.708843537414966\n",
      "0.709297052154195\n",
      "0.7097505668934241\n",
      "0.710204081632653\n",
      "0.7106575963718821\n",
      "0.7111111111111111\n",
      "0.7115646258503401\n",
      "0.7120181405895691\n",
      "0.7124716553287982\n",
      "0.7129251700680272\n",
      "0.7133786848072562\n",
      "0.7138321995464852\n",
      "0.7142857142857143\n",
      "0.7147392290249434\n",
      "0.7151927437641723\n",
      "0.7156462585034014\n",
      "0.7160997732426304\n",
      "0.7165532879818595\n",
      "0.7170068027210884\n",
      "0.7174603174603175\n",
      "0.7179138321995465\n",
      "0.7183673469387755\n",
      "0.7188208616780045\n",
      "0.7192743764172336\n",
      "0.7197278911564626\n",
      "0.7201814058956916\n",
      "0.7206349206349206\n",
      "0.7210884353741497\n",
      "0.7215419501133787\n",
      "0.7219954648526077\n",
      "0.7224489795918367\n",
      "0.7229024943310658\n",
      "0.7233560090702947\n",
      "0.7238095238095238\n",
      "0.7242630385487528\n",
      "0.7247165532879819\n",
      "0.7251700680272108\n",
      "0.7256235827664399\n",
      "0.726077097505669\n",
      "0.726530612244898\n",
      "0.726984126984127\n",
      "0.727437641723356\n",
      "0.7278911564625851\n",
      "0.728344671201814\n",
      "0.7287981859410431\n",
      "0.7292517006802721\n",
      "0.7297052154195012\n",
      "0.7301587301587301\n",
      "0.7306122448979592\n",
      "0.7310657596371882\n",
      "0.7315192743764173\n",
      "0.7319727891156462\n",
      "0.7324263038548753\n",
      "0.7328798185941043\n",
      "0.7333333333333333\n",
      "0.7337868480725623\n",
      "0.7342403628117914\n",
      "0.7346938775510204\n",
      "0.7351473922902494\n",
      "0.7356009070294784\n",
      "0.7360544217687075\n",
      "0.7365079365079366\n",
      "0.7369614512471655\n",
      "0.7374149659863946\n",
      "0.7378684807256236\n",
      "0.7383219954648526\n",
      "0.7387755102040816\n",
      "0.7392290249433107\n",
      "0.7396825396825397\n",
      "0.7401360544217687\n",
      "0.7405895691609977\n",
      "0.7410430839002268\n",
      "0.7414965986394558\n",
      "0.7419501133786848\n",
      "0.7424036281179138\n",
      "0.7428571428571429\n",
      "0.7433106575963719\n",
      "0.7437641723356009\n",
      "0.7442176870748299\n",
      "0.744671201814059\n",
      "0.7451247165532879\n",
      "0.745578231292517\n",
      "0.746031746031746\n",
      "0.7464852607709751\n",
      "0.746938775510204\n",
      "0.7473922902494331\n",
      "0.7478458049886622\n",
      "0.7482993197278912\n",
      "0.7487528344671202\n",
      "0.7492063492063492\n",
      "0.7496598639455783\n",
      "0.7501133786848072\n",
      "0.7505668934240363\n",
      "0.7510204081632653\n",
      "0.7514739229024944\n",
      "0.7519274376417233\n",
      "0.7523809523809524\n",
      "0.7528344671201814\n",
      "0.7532879818594105\n",
      "0.7537414965986394\n",
      "0.7541950113378685\n",
      "0.7546485260770975\n",
      "0.7551020408163265\n",
      "0.7555555555555555\n",
      "0.7560090702947846\n",
      "0.7564625850340136\n",
      "0.7569160997732426\n",
      "0.7573696145124716\n",
      "0.7578231292517007\n",
      "0.7582766439909298\n",
      "0.7587301587301587\n",
      "0.7591836734693878\n",
      "0.7596371882086168\n",
      "0.7600907029478458\n",
      "0.7605442176870748\n",
      "0.7609977324263039\n",
      "0.7614512471655329\n",
      "0.7619047619047619\n",
      "0.7623582766439909\n",
      "0.76281179138322\n",
      "0.763265306122449\n",
      "0.763718820861678\n",
      "0.764172335600907\n",
      "0.7646258503401361\n",
      "0.765079365079365\n",
      "0.7655328798185941\n",
      "0.7659863945578231\n",
      "0.7664399092970522\n",
      "0.7668934240362811\n",
      "0.7673469387755102\n",
      "0.7678004535147392\n",
      "0.7682539682539683\n",
      "0.7687074829931972\n",
      "0.7691609977324263\n",
      "0.7696145124716554\n",
      "0.7700680272108843\n",
      "0.7705215419501134\n",
      "0.7709750566893424\n",
      "0.7714285714285715\n",
      "0.7718820861678004\n",
      "0.7723356009070295\n",
      "0.7727891156462585\n",
      "0.7732426303854876\n",
      "0.7736961451247165\n",
      "0.7741496598639456\n",
      "0.7746031746031746\n",
      "0.7750566893424037\n",
      "0.7755102040816326\n",
      "0.7759637188208617\n",
      "0.7764172335600907\n",
      "0.7768707482993197\n",
      "0.7773242630385487\n",
      "0.7777777777777778\n",
      "0.7782312925170068\n",
      "0.7786848072562358\n",
      "0.7791383219954648\n",
      "0.7795918367346939\n",
      "0.780045351473923\n",
      "0.7804988662131519\n",
      "0.780952380952381\n",
      "0.78140589569161\n",
      "0.781859410430839\n",
      "0.782312925170068\n",
      "0.7827664399092971\n",
      "0.7832199546485261\n",
      "0.7836734693877551\n",
      "0.7841269841269841\n",
      "0.7845804988662132\n",
      "0.7850340136054422\n",
      "0.7854875283446712\n",
      "0.7859410430839002\n",
      "0.7863945578231293\n",
      "0.7868480725623582\n",
      "0.7873015873015873\n",
      "0.7877551020408163\n",
      "0.7882086167800454\n",
      "0.7886621315192743\n",
      "0.7891156462585034\n",
      "0.7895691609977324\n",
      "0.7900226757369615\n",
      "0.7904761904761904\n",
      "0.7909297052154195\n",
      "0.7913832199546486\n",
      "0.7918367346938775\n",
      "0.7922902494331066\n",
      "0.7927437641723356\n",
      "0.7931972789115647\n",
      "0.7936507936507936\n",
      "0.7941043083900227\n",
      "0.7945578231292517\n",
      "0.7950113378684808\n",
      "0.7954648526077097\n",
      "0.7959183673469388\n",
      "0.7963718820861678\n",
      "0.7968253968253968\n",
      "0.7972789115646258\n",
      "0.7977324263038549\n",
      "0.7981859410430839\n",
      "0.7986394557823129\n",
      "0.7990929705215419\n",
      "0.799546485260771\n",
      "0.8\n",
      "0.800453514739229\n",
      "0.800907029478458\n",
      "0.8013605442176871\n",
      "0.8018140589569162\n",
      "0.8022675736961451\n",
      "0.8027210884353742\n",
      "0.8031746031746032\n",
      "0.8036281179138322\n",
      "0.8040816326530612\n",
      "0.8045351473922903\n",
      "0.8049886621315193\n",
      "0.8054421768707483\n",
      "0.8058956916099773\n",
      "0.8063492063492064\n",
      "0.8068027210884354\n",
      "0.8072562358276644\n",
      "0.8077097505668934\n",
      "0.8081632653061225\n",
      "0.8086167800453514\n",
      "0.8090702947845805\n",
      "0.8095238095238095\n",
      "0.8099773242630386\n",
      "0.8104308390022675\n",
      "0.8108843537414966\n",
      "0.8113378684807256\n",
      "0.8117913832199547\n",
      "0.8122448979591836\n",
      "0.8126984126984127\n",
      "0.8131519274376418\n",
      "0.8136054421768707\n",
      "0.8140589569160998\n",
      "0.8145124716553288\n",
      "0.8149659863945579\n",
      "0.8154195011337868\n",
      "0.8158730158730159\n",
      "0.8163265306122449\n",
      "0.816780045351474\n",
      "0.8172335600907029\n",
      "0.817687074829932\n",
      "0.818140589569161\n",
      "0.81859410430839\n",
      "0.819047619047619\n",
      "0.8195011337868481\n",
      "0.8199546485260771\n",
      "0.8204081632653061\n",
      "0.8208616780045351\n",
      "0.8213151927437642\n",
      "0.8217687074829932\n",
      "0.8222222222222222\n",
      "0.8226757369614512\n",
      "0.8231292517006803\n",
      "0.8235827664399092\n",
      "0.8240362811791383\n",
      "0.8244897959183674\n",
      "0.8249433106575964\n",
      "0.8253968253968254\n",
      "0.8258503401360544\n",
      "0.8263038548752835\n",
      "0.8267573696145125\n",
      "0.8272108843537415\n",
      "0.8276643990929705\n",
      "0.8281179138321996\n",
      "0.8285714285714286\n",
      "0.8290249433106576\n",
      "0.8294784580498866\n",
      "0.8299319727891157\n",
      "0.8303854875283446\n",
      "0.8308390022675737\n",
      "0.8312925170068027\n",
      "0.8317460317460318\n",
      "0.8321995464852607\n",
      "0.8326530612244898\n",
      "0.8331065759637188\n",
      "0.8335600907029479\n",
      "0.8340136054421768\n",
      "0.8344671201814059\n",
      "0.834920634920635\n",
      "0.8353741496598639\n",
      "0.835827664399093\n",
      "0.836281179138322\n",
      "0.8367346938775511\n",
      "0.83718820861678\n",
      "0.8376417233560091\n",
      "0.8380952380952381\n",
      "0.8385487528344672\n",
      "0.8390022675736961\n",
      "0.8394557823129252\n",
      "0.8399092970521542\n",
      "0.8403628117913832\n",
      "0.8408163265306122\n",
      "0.8412698412698413\n",
      "0.8417233560090703\n",
      "0.8421768707482993\n",
      "0.8426303854875283\n",
      "0.8430839002267574\n",
      "0.8435374149659864\n",
      "0.8439909297052154\n",
      "0.8444444444444444\n",
      "0.8448979591836735\n",
      "0.8453514739229024\n",
      "0.8458049886621315\n",
      "0.8462585034013606\n",
      "0.8467120181405896\n",
      "0.8471655328798186\n",
      "0.8476190476190476\n",
      "0.8480725623582767\n",
      "0.8485260770975057\n",
      "0.8489795918367347\n",
      "0.8494331065759637\n",
      "0.8498866213151928\n",
      "0.8503401360544217\n",
      "0.8507936507936508\n",
      "0.8512471655328798\n",
      "0.8517006802721089\n",
      "0.8521541950113378\n",
      "0.8526077097505669\n",
      "0.8530612244897959\n",
      "0.853514739229025\n",
      "0.8539682539682539\n",
      "0.854421768707483\n",
      "0.854875283446712\n",
      "0.8553287981859411\n",
      "0.85578231292517\n",
      "0.8562358276643991\n",
      "0.8566893424036282\n",
      "0.8571428571428571\n",
      "0.8575963718820862\n",
      "0.8580498866213152\n",
      "0.8585034013605443\n",
      "0.8589569160997732\n",
      "0.8594104308390023\n",
      "0.8598639455782313\n",
      "0.8603174603174604\n",
      "0.8607709750566893\n",
      "0.8612244897959184\n",
      "0.8616780045351474\n",
      "0.8621315192743764\n",
      "0.8625850340136054\n",
      "0.8630385487528345\n",
      "0.8634920634920635\n",
      "0.8639455782312925\n",
      "0.8643990929705215\n",
      "0.8648526077097506\n",
      "0.8653061224489796\n",
      "0.8657596371882086\n",
      "0.8662131519274376\n",
      "0.8666666666666667\n",
      "0.8671201814058956\n",
      "0.8675736961451247\n",
      "0.8680272108843538\n",
      "0.8684807256235828\n",
      "0.8689342403628117\n",
      "0.8693877551020408\n",
      "0.8698412698412699\n",
      "0.8702947845804989\n",
      "0.8707482993197279\n",
      "0.8712018140589569\n",
      "0.871655328798186\n",
      "0.8721088435374149\n",
      "0.872562358276644\n",
      "0.873015873015873\n",
      "0.8734693877551021\n",
      "0.873922902494331\n",
      "0.8743764172335601\n",
      "0.8748299319727891\n",
      "0.8752834467120182\n",
      "0.8757369614512471\n",
      "0.8761904761904762\n",
      "0.8766439909297052\n",
      "0.8770975056689342\n",
      "0.8775510204081632\n",
      "0.8780045351473923\n",
      "0.8784580498866214\n",
      "0.8789115646258503\n",
      "0.8793650793650793\n",
      "0.8798185941043084\n",
      "0.8802721088435375\n",
      "0.8807256235827664\n",
      "0.8811791383219955\n",
      "0.8816326530612245\n",
      "0.8820861678004536\n",
      "0.8825396825396825\n",
      "0.8829931972789116\n",
      "0.8834467120181406\n",
      "0.8839002267573696\n",
      "0.8843537414965986\n",
      "0.8848072562358277\n",
      "0.8852607709750567\n",
      "0.8857142857142857\n",
      "0.8861678004535147\n",
      "0.8866213151927438\n",
      "0.8870748299319728\n",
      "0.8875283446712018\n",
      "0.8879818594104308\n",
      "0.8884353741496599\n",
      "0.8888888888888888\n",
      "0.8893424036281179\n",
      "0.889795918367347\n",
      "0.890249433106576\n",
      "0.890702947845805\n",
      "0.891156462585034\n",
      "0.8916099773242631\n",
      "0.8920634920634921\n",
      "0.8925170068027211\n",
      "0.8929705215419501\n",
      "0.8934240362811792\n",
      "0.8938775510204081\n",
      "0.8943310657596372\n",
      "0.8947845804988662\n",
      "0.8952380952380953\n",
      "0.8956916099773242\n",
      "0.8961451247165533\n",
      "0.8965986394557823\n",
      "0.8970521541950114\n",
      "0.8975056689342403\n",
      "0.8979591836734694\n",
      "0.8984126984126984\n",
      "0.8988662131519274\n",
      "0.8993197278911564\n",
      "0.8997732426303855\n",
      "0.9002267573696145\n",
      "0.9006802721088435\n",
      "0.9011337868480725\n",
      "0.9015873015873016\n",
      "0.9020408163265307\n",
      "0.9024943310657596\n",
      "0.9029478458049887\n",
      "0.9034013605442177\n",
      "0.9038548752834467\n",
      "0.9043083900226757\n",
      "0.9047619047619048\n",
      "0.9052154195011338\n",
      "0.9056689342403628\n",
      "0.9061224489795918\n",
      "0.9065759637188209\n",
      "0.9070294784580499\n",
      "0.9074829931972789\n",
      "0.9079365079365079\n",
      "0.908390022675737\n",
      "0.908843537414966\n",
      "0.909297052154195\n",
      "0.909750566893424\n",
      "0.9102040816326531\n",
      "0.910657596371882\n",
      "0.9111111111111111\n",
      "0.9115646258503401\n",
      "0.9120181405895692\n",
      "0.9124716553287981\n",
      "0.9129251700680272\n",
      "0.9133786848072563\n",
      "0.9138321995464853\n",
      "0.9142857142857143\n",
      "0.9147392290249433\n",
      "0.9151927437641724\n",
      "0.9156462585034013\n",
      "0.9160997732426304\n",
      "0.9165532879818594\n",
      "0.9170068027210885\n",
      "0.9174603174603174\n",
      "0.9179138321995465\n",
      "0.9183673469387755\n",
      "0.9188208616780046\n",
      "0.9192743764172335\n",
      "0.9197278911564626\n",
      "0.9201814058956916\n",
      "0.9206349206349206\n",
      "0.9210884353741496\n",
      "0.9215419501133787\n",
      "0.9219954648526077\n",
      "0.9224489795918367\n",
      "0.9229024943310657\n",
      "0.9233560090702948\n",
      "0.9238095238095239\n",
      "0.9242630385487528\n",
      "0.9247165532879819\n",
      "0.9251700680272109\n",
      "0.9256235827664399\n",
      "0.9260770975056689\n",
      "0.926530612244898\n",
      "0.926984126984127\n",
      "0.927437641723356\n",
      "0.927891156462585\n",
      "0.9283446712018141\n",
      "0.9287981859410431\n",
      "0.9292517006802721\n",
      "0.9297052154195011\n",
      "0.9301587301587302\n",
      "0.9306122448979591\n",
      "0.9310657596371882\n",
      "0.9315192743764172\n",
      "0.9319727891156463\n",
      "0.9324263038548752\n",
      "0.9328798185941043\n",
      "0.9333333333333333\n",
      "0.9337868480725624\n",
      "0.9342403628117913\n",
      "0.9346938775510204\n",
      "0.9351473922902495\n",
      "0.9356009070294785\n",
      "0.9360544217687075\n",
      "0.9365079365079365\n",
      "0.9369614512471656\n",
      "0.9374149659863945\n",
      "0.9378684807256236\n",
      "0.9383219954648526\n",
      "0.9387755102040817\n",
      "0.9392290249433106\n",
      "0.9396825396825397\n",
      "0.9401360544217687\n",
      "0.9405895691609978\n",
      "0.9410430839002267\n",
      "0.9414965986394558\n",
      "0.9419501133786848\n",
      "0.9424036281179138\n",
      "0.9428571428571428\n",
      "0.9433106575963719\n",
      "0.943764172335601\n",
      "0.9442176870748299\n",
      "0.944671201814059\n",
      "0.945124716553288\n",
      "0.9455782312925171\n",
      "0.946031746031746\n",
      "0.9464852607709751\n",
      "0.9469387755102041\n",
      "0.9473922902494331\n",
      "0.9478458049886621\n",
      "0.9482993197278912\n",
      "0.9487528344671202\n",
      "0.9492063492063492\n",
      "0.9496598639455782\n",
      "0.9501133786848073\n",
      "0.9505668934240363\n",
      "0.9510204081632653\n",
      "0.9514739229024943\n",
      "0.9519274376417234\n",
      "0.9523809523809523\n",
      "0.9528344671201814\n",
      "0.9532879818594104\n",
      "0.9537414965986395\n",
      "0.9541950113378684\n",
      "0.9546485260770975\n",
      "0.9551020408163265\n",
      "0.9555555555555556\n",
      "0.9560090702947845\n",
      "0.9564625850340136\n",
      "0.9569160997732427\n",
      "0.9573696145124716\n",
      "0.9578231292517007\n",
      "0.9582766439909297\n",
      "0.9587301587301588\n",
      "0.9591836734693877\n",
      "0.9596371882086168\n",
      "0.9600907029478458\n",
      "0.9605442176870749\n",
      "0.9609977324263038\n",
      "0.9614512471655329\n",
      "0.9619047619047619\n",
      "0.962358276643991\n",
      "0.9628117913832199\n",
      "0.963265306122449\n",
      "0.963718820861678\n",
      "0.964172335600907\n",
      "0.964625850340136\n",
      "0.9650793650793651\n",
      "0.9655328798185941\n",
      "0.9659863945578231\n",
      "0.9664399092970521\n",
      "0.9668934240362812\n",
      "0.9673469387755103\n",
      "0.9678004535147392\n",
      "0.9682539682539683\n",
      "0.9687074829931973\n",
      "0.9691609977324263\n",
      "0.9696145124716553\n",
      "0.9700680272108844\n",
      "0.9705215419501134\n",
      "0.9709750566893424\n",
      "0.9714285714285714\n",
      "0.9718820861678005\n",
      "0.9723356009070295\n",
      "0.9727891156462585\n",
      "0.9732426303854875\n",
      "0.9736961451247166\n",
      "0.9741496598639455\n",
      "0.9746031746031746\n",
      "0.9750566893424036\n",
      "0.9755102040816327\n",
      "0.9759637188208616\n",
      "0.9764172335600907\n",
      "0.9768707482993197\n",
      "0.9773242630385488\n",
      "0.9777777777777777\n",
      "0.9782312925170068\n",
      "0.9786848072562359\n",
      "0.9791383219954648\n",
      "0.9795918367346939\n",
      "0.9800453514739229\n",
      "0.980498866213152\n",
      "0.9809523809523809\n",
      "0.98140589569161\n",
      "0.981859410430839\n",
      "0.9823129251700681\n",
      "0.982766439909297\n",
      "0.9832199546485261\n",
      "0.9836734693877551\n",
      "0.9841269841269841\n",
      "0.9845804988662131\n",
      "0.9850340136054422\n",
      "0.9854875283446712\n",
      "0.9859410430839002\n",
      "0.9863945578231292\n",
      "0.9868480725623583\n",
      "0.9873015873015873\n",
      "0.9877551020408163\n",
      "0.9882086167800453\n",
      "0.9886621315192744\n",
      "0.9891156462585035\n",
      "0.9895691609977324\n",
      "0.9900226757369615\n",
      "0.9904761904761905\n",
      "0.9909297052154195\n",
      "0.9913832199546485\n",
      "0.9918367346938776\n",
      "0.9922902494331066\n",
      "0.9927437641723356\n",
      "0.9931972789115646\n",
      "0.9936507936507937\n",
      "0.9941043083900227\n",
      "0.9945578231292517\n",
      "0.9950113378684807\n",
      "0.9954648526077098\n",
      "0.9959183673469387\n",
      "0.9963718820861678\n",
      "0.9968253968253968\n",
      "0.9972789115646259\n",
      "0.9977324263038548\n",
      "0.9981859410430839\n",
      "0.998639455782313\n",
      "0.999092970521542\n",
      "0.999546485260771\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = '../data/хоккей_матч.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_interval = int(video_fps / 1)\n",
    "\n",
    "current_frame = 0\n",
    "extracted_frames = 0\n",
    "\n",
    "frames = []\n",
    "labels = []\n",
    "cur_pos = -1\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Если текущий кадр кратен интервалу, сохраняем его\n",
    "    if current_frame % frame_interval == 0:\n",
    "        frame_num = current_frame / frame_interval\n",
    "\n",
    "        if frame_num > max_value:\n",
    "            break\n",
    "        else:\n",
    "\n",
    "            if cur_pos == -1 and frame_num not in s:\n",
    "                current_frame += 1\n",
    "                continue\n",
    "            \n",
    "            if frame_num in s:\n",
    "                cur_pos = s[frame_num]\n",
    "\n",
    "\n",
    "            labels.append(cur_pos) \n",
    "            frames.append(frame)\n",
    "\n",
    "        extracted_frames += 1\n",
    "\n",
    "        print(frame_num / max_value)\n",
    "    \n",
    "    current_frame += 1\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "DEVICE = torch.device('mps')\n",
    "\n",
    "# Custom dataset class for loading video frames\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, frames, labels, video_len=5, transform=None):\n",
    "        self.frames = frames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.video_len = video_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames) - self.video_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video = [self.frames[idx + i] for i in range(self.video_len)]\n",
    "        label = self.labels[idx + self.video_len - 1]\n",
    "        if self.transform:\n",
    "            # print(self.transform, video[0])\n",
    "            video = [self.transform(image=frame)['image'] for frame in video]\n",
    "        video = torch.stack(video)\n",
    "        return video, torch.tensor(label)\n",
    "\n",
    "transform = albu.Compose([\n",
    "    albu.Resize(368, 368),\n",
    "    albu.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frames = [frames[i] for i in range(len(frames)) if i % 1 == 0]\n",
    "new_labels = [labels[i] for i in range(len(frames)) if i % 1 == 0]\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "\n",
    "train_frames = new_frames[:int(len(new_frames) * (1 - test_size))]\n",
    "train_labels = new_labels[:int(len(new_labels) * (1 - test_size))]\n",
    "val_frames = new_frames[int(len(new_frames) * (1 - test_size)):]\n",
    "val_labels = new_labels[int(len(new_labels) * (1 - test_size)):]\n",
    "\n",
    "train_ds = VideoDataset(train_frames, train_labels, transform=transform)\n",
    "valid_ds = VideoDataset(train_frames, train_labels, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=8)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN-LSTM model\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, cnn_model, hidden_dim, lstm_layers, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.cnn = cnn_model\n",
    "        self.lstm = nn.LSTM(input_size=cnn_model.classifier[0].out_features, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=lstm_layers, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, lstm_input=None):\n",
    "        batch_size, seq_len, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * seq_len, C, H, W)  # Flatten to [batch_size*seq_len, C, H, W]\n",
    "        c_out = self.cnn(c_in)  # Pass through the CNN\n",
    "        c_out = c_out.view(batch_size, seq_len, -1)  # Reshape to [batch_size, seq_len, feature_dim]\n",
    "\n",
    "        if lstm_input is None:\n",
    "            lstm_out, hidden_lstm = self.lstm(c_out)  # LSTM output\n",
    "        else:\n",
    "            lstm_out, hidden_lstm = self.lstm(c_out, (lstm_input[0][:,-1:,:], lstm_input[1][:,-1:,:]))\n",
    "\n",
    "        # lstm_out, _ = self.lstm(c_out)  # LSTM output\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the last output of the LSTM\n",
    "        out = self.fc(lstm_out)  # Fully connected layer\n",
    "        return out, hidden_lstm\n",
    "\n",
    "\n",
    "# Load the pretrained MobileNetV3 and modify it\n",
    "mobilenet_v3 = models.mobilenet_v3_small(pretrained=True)\n",
    "# Remove the last classifier layer\n",
    "mobilenet_v3.classifier = nn.Sequential(*list(mobilenet_v3.classifier.children())[:-1])\n",
    "\n",
    "# Model hyperparameters\n",
    "hidden_dim = 128\n",
    "lstm_layers = 1\n",
    "num_classes = 2\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN_LSTM(mobilenet_v3, hidden_dim, lstm_layers, num_classes)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 154/1227 [00:36<04:16,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.6297362709278845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 154/1227 [00:32<03:45,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.4809111713510394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 154/1227 [00:33<03:51,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.5562541012216795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 154/1227 [00:32<03:48,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/3, Loss: 0.5757207312173658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 154/1227 [00:32<03:47,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/3, Loss: 0.44281669198112056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_dataloader, total=len(train_ds)):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs.cpu(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{3}, Loss: {running_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mobilenet_v3.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:13<00:00, 11.30it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "val_labels = []\n",
    "for inputs, labels in tqdm(valid_dataloader, total=len(valid_dataloader)):\n",
    "    optimizer.zero_grad()\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs, _ = model(inputs)\n",
    "        outputs = outputs.cpu().numpy()[:, 1]\n",
    "    val_labels.append(labels)\n",
    "    preds.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905142405063291"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.roc_auc_score(np.concatenate(val_labels), np.concatenate(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frames_transforms = torch.stack([transform(image=x)['image'] for x in val_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2413,  0.5902, -0.1082,  ...,  0.2751, -0.2755,  0.0563],\n",
       "        [ 1.3169,  0.4147,  0.3289,  ...,  0.1845, -0.2745,  0.1564],\n",
       "        [ 2.2707,  0.1501,  0.4816,  ...,  0.2332, -0.3149,  0.6129],\n",
       "        [ 1.1871, -0.0776,  0.5309,  ...,  0.6983,  0.0854,  0.4708],\n",
       "        [ 0.1075,  0.0744,  0.1393,  ...,  0.9069,  0.5010,  0.2018]],\n",
       "       device='mps:0', grad_fn=<HardswishBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_v3(val_frames_transforms[:5].to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 368, 368])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_frames_transforms[:5].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden_state = model(val_frames_transforms[:5].unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.12 GB, other allocations: 9.86 MB, max allowed: 18.13 GB). Tried to allocate 793.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_frames_transforms)):\n\u001b[0;32m----> 2\u001b[0m     output, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_frames_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mCNN_LSTM.forward\u001b[0;34m(self, x, lstm_input)\u001b[0m\n\u001b[1;32m     13\u001b[0m batch_size, seq_len, C, H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m     14\u001b[0m c_in \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m seq_len, C, H, W)  \u001b[38;5;66;03m# Flatten to [batch_size*seq_len, C, H, W]\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m c_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass through the CNN\u001b[39;00m\n\u001b[1;32m     16\u001b[0m c_out \u001b[38;5;241m=\u001b[39m c_out\u001b[38;5;241m.\u001b[39mview(batch_size, seq_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to [batch_size, seq_len, feature_dim]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lstm_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torchvision/models/mobilenetv3.py:220\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torchvision/models/mobilenetv3.py:210\u001b[0m, in \u001b[0;36mMobileNetV3._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    213\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torchvision/models/mobilenetv3.py:111\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 111\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    113\u001b[0m         result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/venv_mvp_matching/lib/python3.11/site-packages/torch/nn/functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 18.12 GB, other allocations: 9.86 MB, max allowed: 18.13 GB). Tried to allocate 793.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "for i in range(len(val_frames_transforms)):\n",
    "    output, hidden_state = model(val_frames_transforms[5+i:6+i].unsqueeze(0).to(DEVICE), hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
