{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebefb95d-abf4-4ce4-8e1b-9e1cdb9d1a83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:02.879652Z",
     "iopub.status.busy": "2024-09-15T19:55:02.879139Z",
     "iopub.status.idle": "2024-09-15T19:55:06.361110Z",
     "shell.execute_reply": "2024-09-15T19:55:06.360622Z",
     "shell.execute_reply.started": "2024-09-15T19:55:02.879632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from src import CustomLLamaForMultipleChoice\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import get_cosine_schedule_with_warmup,get_linear_schedule_with_warmup, AutoModel, AutoTokenizer, AutoModelForMultipleChoice, AutoConfig\n",
    "import wandb\n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fb9898-59e6-41f6-b6bc-27f3341fa0e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.363410Z",
     "iopub.status.busy": "2024-09-15T19:55:06.363255Z",
     "iopub.status.idle": "2024-09-15T19:55:06.376670Z",
     "shell.execute_reply": "2024-09-15T19:55:06.376168Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.363394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e9f408305c446a8551ef3a60624a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for gemma 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\n",
    "# for llama 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\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8056812-3164-4f48-a202-1bac5554241a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.377581Z",
     "iopub.status.busy": "2024-09-15T19:55:06.377430Z",
     "iopub.status.idle": "2024-09-15T19:55:06.379882Z",
     "shell.execute_reply": "2024-09-15T19:55:06.379382Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.377566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013db4df-de87-486a-b20c-296bf0e4603a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.381157Z",
     "iopub.status.busy": "2024-09-15T19:55:06.380940Z",
     "iopub.status.idle": "2024-09-15T19:55:06.386732Z",
     "shell.execute_reply": "2024-09-15T19:55:06.386195Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.381141Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    class data:\n",
    "        train_path = 'train.statement.jsonl'\n",
    "        val_path = 'dev.statement.jsonl'\n",
    "        test_path = 'test.statement.jsonl'\n",
    "        tokenizer = 'IlyaGusev/gemma-2-9b-it-abliterated'\n",
    "        num_workers = 8\n",
    "        nfolds = 5\n",
    "        batch_size = 4\n",
    "        use_prefix = False\n",
    "        max_length = 80 \n",
    "        seed = 56\n",
    "    class model:\n",
    "        model = 'IlyaGusev/gemma-2-9b-it-abliterated'\n",
    "        optim = torch.optim.AdamW\n",
    "        grad_acum_steps = 2\n",
    "        num_labels = 5\n",
    "        torch_dtype = torch.bfloat16\n",
    "        scheduler= 'cosine'\n",
    "        warnap_steps = 0.0 #0.25\n",
    "        label_smoothing = 0.0\n",
    "        pool = 'attention'\n",
    "        max_epoches = 5\n",
    "        cls_drop_type = None\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        cls_drop = 0.0\n",
    "        lr_fn = 1e-5\n",
    "        lr = 1e-5\n",
    "        turn_off_drop = True\n",
    "        num_cycles = 0.5\n",
    "        eps = 1e-7\n",
    "        weight_decay = 0.0\n",
    "        weight_decay_fn = 0.0\n",
    "        betas = (0.9, 0.999)\n",
    "        use_lora = True\n",
    "        class lora:\n",
    "            r = 64\n",
    "            lora_alpha = 128\n",
    "            lora_dropout = 0.05\n",
    "            bias = 'none'\n",
    "            use_dora = False\n",
    "            target_modules = ['down_proj','o_proj','k_proj','q_proj','gate_proj','up_proj','v_proj']\n",
    "    seed = 56\n",
    "    fold_number = 0\n",
    "\n",
    "def set_wandb_cfg():\n",
    "    config = {}\n",
    "    for k,v in CFG.model.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    for k,v in CFG.data.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    for k,v in CFG.model.lora.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    config['fold_number'] = CFG.fold_number\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4136339-00fb-4336-83f8-a55f97627902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.387540Z",
     "iopub.status.busy": "2024-09-15T19:55:06.387400Z",
     "iopub.status.idle": "2024-09-15T19:55:06.391749Z",
     "shell.execute_reply": "2024-09-15T19:55:06.391270Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.387527Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(path,is_test=False):\n",
    "    data = pd.read_json(path,lines=True)\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['question'] = data['question'].apply(lambda x: x['stem'])\n",
    "    df['choice_A'] = data['question'].apply(lambda x: x['choices'][0]['text'])\n",
    "    df['choice_B'] = data['question'].apply(lambda x: x['choices'][1]['text'])\n",
    "    df['choice_C'] = data['question'].apply(lambda x: x['choices'][2]['text'])\n",
    "    df['choice_D'] = data['question'].apply(lambda x: x['choices'][3]['text'])\n",
    "    df['choice_E'] = data['question'].apply(lambda x: x['choices'][4]['text'])\n",
    "    \n",
    "    if not is_test:\n",
    "        df['label'] = data['answerKey'].map({'A':0,'B':1,'C':2,'D':3,'E':4})\n",
    "    else:\n",
    "        df['label'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0adda29e-e64a-4a04-b726-d905f048d2eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.392518Z",
     "iopub.status.busy": "2024-09-15T19:55:06.392345Z",
     "iopub.status.idle": "2024-09-15T19:55:06.397673Z",
     "shell.execute_reply": "2024-09-15T19:55:06.397253Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.392502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        if self.cfg.use_prefix:\n",
    "            prompts = [[f\"Question: {row['question']}\",f\"Answer: {i}\"] for i in [row['choice_A'],row['choice_B'],row['choice_C'],row['choice_D'],row['choice_E']]]\n",
    "        else:\n",
    "            prompts = [[row['question'],i] for i in [row['choice_A'],row['choice_B'],row['choice_C'],row['choice_D'],row['choice_E']]]\n",
    "        \n",
    "        \n",
    "        encodes = [\n",
    "            self.tokenizer.encode_plus(question,answer,\n",
    "                                       max_length=self.cfg.max_length,\n",
    "                                       truncation=False,\n",
    "                                       padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "            for question,answer in prompts\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            'input_ids':torch.stack([x.input_ids.squeeze(0) for x in encodes]),\n",
    "            'attention_mask':torch.stack([x.attention_mask.squeeze(0) for x in encodes]),\n",
    "            'labels': row['label']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22632749-1e96-470b-b926-1ff32048fb15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.398560Z",
     "iopub.status.busy": "2024-09-15T19:55:06.398398Z",
     "iopub.status.idle": "2024-09-15T19:55:06.403773Z",
     "shell.execute_reply": "2024-09-15T19:55:06.403267Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.398546Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.is_setup = False\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        self.train_df = make_df(self.cfg.train_path)\n",
    "        self.val_df = make_df(self.cfg.val_path)\n",
    "        self.test_df = make_df(self.cfg.test_path,is_test=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg.tokenizer)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.tokenizer.padding_side = 'right'\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        #kf = StratifiedKFold(n_splits=self.cfg.nfolds, shuffle=True, random_state=self.cfg.seed)\n",
    "        #splits = [(x,y) for x,y in  kf.split(self.df,self.df['label'])][CFG.fold_number]\n",
    "        #self.train_df, self.val_df = self.df.iloc[splits[0]], self.df.iloc[splits[1]]\n",
    "        self.train_dataset = PLDataset(self.train_df,self.tokenizer)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.tokenizer)\n",
    "        self.predict_dataset = PLDataset(self.test_df,self.tokenizer)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                         batch_size=self.cfg.batch_size,\n",
    "                         num_workers=self.cfg.num_workers,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "887b699e-a0b9-480a-bb7f-22881ec3a336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.404813Z",
     "iopub.status.busy": "2024-09-15T19:55:06.404592Z",
     "iopub.status.idle": "2024-09-15T19:55:06.407757Z",
     "shell.execute_reply": "2024-09-15T19:55:06.407392Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.404798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.history = []\n",
    "    \n",
    "    def update(self,y_t,y_p):\n",
    "        self.labels += y_t\n",
    "        self.preds += y_p\n",
    "        \n",
    "    def clean(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        metrics = {}\n",
    "        metrics['accuracy'] = accuracy_score(self.labels, self.preds)\n",
    "        self.history.append(metrics)\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7473a4f8-97c5-4600-8cd0-229824be7a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:06.465183Z",
     "iopub.status.busy": "2024-09-15T19:55:06.464961Z",
     "iopub.status.idle": "2024-09-15T19:55:06.472604Z",
     "shell.execute_reply": "2024-09-15T19:55:06.472092Z",
     "shell.execute_reply.started": "2024-09-15T19:55:06.465166Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.model = CustomLLamaForMultipleChoice(self.cfg)\n",
    "        self.avg_meter = AverageMeter()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        output = self.model(**batch)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, i):\n",
    "        out = self(batch)\n",
    "        loss = out.loss\n",
    "        self.log('train_loss', loss.item())\n",
    "        return loss\n",
    "            \n",
    "    def validation_step(self, batch, i):\n",
    "        out = self(batch)\n",
    "        loss = out.loss\n",
    "        self.log('val_loss',loss.item())\n",
    "        preds = out.logits.argmax(dim=-1).tolist()\n",
    "        self.avg_meter.update(batch['labels'].tolist(),preds)\n",
    "    \n",
    "    def predict_step(self, batch, i):\n",
    "        out = self(batch)\n",
    "        logits = out.logits\n",
    "        return logits.argmax(dim=-1).tolist()\n",
    "                \n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.avg_meter.calc_metrics()\n",
    "        self.log_dict(metrics)\n",
    "        self.avg_meter.clean()\n",
    "            \n",
    "    def configure_optimizers(self):        \n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in self.model.model.named_parameters() if not any(nd in n for nd in self.cfg.no_decay)],\n",
    "             'lr': self.cfg.lr, 'weight_decay': self.cfg.weight_decay},\n",
    "            {'params': [p for n, p in self.model.model.named_parameters() if any(nd in n for nd in self.cfg.no_decay)],\n",
    "             'lr': self.cfg.lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if \"model\" not in n],\n",
    "             'lr': self.cfg.lr_fn, 'weight_decay': self.cfg.weight_decay_fn}\n",
    "        ]\n",
    "        \n",
    "        optim = self.cfg.optim(\n",
    "            optimizer_parameters,\n",
    "            lr=self.cfg.lr,\n",
    "            betas=self.cfg.betas,\n",
    "            weight_decay=self.cfg.weight_decay,\n",
    "            eps=self.cfg.eps\n",
    "        )\n",
    "        \n",
    "        if self.cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warnap_steps,\n",
    "                                                        num_cycles=self.cfg.num_cycles)\n",
    "        elif self.cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warnap_steps)\n",
    "        else:\n",
    "            return optim\n",
    "        \n",
    "        scheduler = {'scheduler': scheduler,'interval': 'step', 'frequency': 1}\n",
    "\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b045ec0-d4d4-465e-9271-ef70a400f650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:07.062333Z",
     "iopub.status.busy": "2024-09-15T19:55:07.062108Z",
     "iopub.status.idle": "2024-09-15T19:55:08.742753Z",
     "shell.execute_reply": "2024-09-15T19:55:08.742160Z",
     "shell.execute_reply.started": "2024-09-15T19:55:07.062317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc2904b81c04c1292d7823862226658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a3e5567c59455394845187c11636f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c1de8756734050bb2d2fca00b042c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957a63c8ecea41209269e6b66a7454f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b0b61f-9aed-403a-983a-9b28535cc524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:08.745089Z",
     "iopub.status.busy": "2024-09-15T19:55:08.744931Z",
     "iopub.status.idle": "2024-09-15T19:55:08.748050Z",
     "shell.execute_reply": "2024-09-15T19:55:08.747615Z",
     "shell.execute_reply.started": "2024-09-15T19:55:08.745075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG.model.num_training_steps = len(dm.train_dataloader()) * CFG.model.max_epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b1aa44-fa11-412d-8b58-5e978f71010b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:55:10.350118Z",
     "iopub.status.busy": "2024-09-15T19:55:10.349829Z",
     "iopub.status.idle": "2024-09-15T19:56:38.979041Z",
     "shell.execute_reply": "2024-09-15T19:56:38.978467Z",
     "shell.execute_reply.started": "2024-09-15T19:55:10.350095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aee8c600d9428589d66e416416f803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/895 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a3722e9e3e479793806b30ed5353ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e7d37fd4c0462f960e544cac4114a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab4ed8cd471464188c940643da40141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8ca22f5574463897effff7593f1499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8000e529beed4ff293b69b31fcab76b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb6574ec5c14e1e8bcf6fb8a6d6e041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba1eca7b67f4ef79356d1ab22e3776a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PLModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ee0cccc-0947-4ca7-b7fc-e670d2a15478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:56:38.981710Z",
     "iopub.status.busy": "2024-09-15T19:56:38.981251Z",
     "iopub.status.idle": "2024-09-15T19:56:40.327444Z",
     "shell.execute_reply": "2024-09-15T19:56:40.326962Z",
     "shell.execute_reply.started": "2024-09-15T19:56:38.981693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewkhl\u001b[0m (\u001b[33mandlh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240915_195639-frs21k5c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/AIIJC_task1/runs/frs21k5c' target=\"_blank\">gemma_2-9b-it-abliterated_attn</a></strong> to <a href='https://wandb.ai/andlh/AIIJC_task1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/AIIJC_task1' target=\"_blank\">https://wandb.ai/andlh/AIIJC_task1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/AIIJC_task1/runs/frs21k5c' target=\"_blank\">https://wandb.ai/andlh/AIIJC_task1/runs/frs21k5c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andlh/AIIJC_task1/runs/frs21k5c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4c9bc9d890>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"31520b01739d418e5d77a11fd8a79a70b189b8bc\")\n",
    "os.environ['WANDB_API_KEY'] = \"31520b01739d418e5d77a11fd8a79a70b189b8bc\"\n",
    "wandb.init(project='AIIJC_task1',name='gemma_2-9b-it-abliterated_attn',config=set_wandb_cfg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccaaf5ef-b77a-438b-876b-acc030bff130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:56:40.330170Z",
     "iopub.status.busy": "2024-09-15T19:56:40.330034Z",
     "iopub.status.idle": "2024-09-15T19:56:40.350846Z",
     "shell.execute_reply": "2024-09-15T19:56:40.350304Z",
     "shell.execute_reply.started": "2024-09-15T19:56:40.330157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:571: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs/',\n",
    "    filename='model_{epoch:02d}-{accuracy:.4f}',\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision='bf16',\n",
    "    callbacks = [lr_monitor],#[lr_monitor,checkpoint_cb],\n",
    "    logger = pl.loggers.WandbLogger(save_code=True),\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=CFG.model.grad_acum_steps,\n",
    "    enable_checkpointing=False,\n",
    "    min_epochs=1,\n",
    "    devices=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=CFG.model.max_epoches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334db762-adbd-45d4-9793-2f567c8711f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:56:40.352976Z",
     "iopub.status.busy": "2024-09-15T19:56:40.352823Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                         | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | model | CustomLLamaForMultipleChoice | 9.5 B  | train\n",
      "---------------------------------------------------------------\n",
      "217 M     Trainable params\n",
      "9.2 B     Non-trainable params\n",
      "9.5 B     Total params\n",
      "37,838.471Total estimated model params size (MB)\n",
      "2951      Modules in train mode\n",
      "676       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10955ce6a4d84521900e99ec9457841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37147ff3af2491aa209d8bb5867fc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44e03ff703646c6af548e7a59cd6c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11b40650-b454-49ab-8477-fb607dd5c6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945d8a1222b64c39a8db7247554b2871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(model,dm.predict_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c6526a85-a903-4ac8-99de-405b92dafae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_json('test.statement.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d0ef00b1-3e21-4c36-95ae-d543f99d63f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = ['ABCDE'[x] for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "715a02ef-8ef1-4e88-a517-78f9daa4f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('subv56.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5e839788-fe09-45c0-a807-ec6c7c722298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('subv56v2.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccce25a-2175-4cd2-913d-e324af425120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
