{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4abb10-86df-469a-9455-da1627bc24ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedGroupKFold\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import cv2\n",
    "import h5py\n",
    "import io\n",
    "import pandas.api.types\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas.api.types\n",
    "import sklearn.metrics\n",
    "from math import sin,cos,pi\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from catboost import CatBoostClassifier,Pool,cv\n",
    "from copy import deepcopy\n",
    "import wandb\n",
    "import timm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99196f5-f7fd-48f2-8142-3c73abfd9ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    class data:\n",
    "        train_data= './isic-2024-challenge/train-metadata.csv'\n",
    "        train_hdf5='./isic-2024-challenge/train-image.hdf5'\n",
    "        output_prefix = 'effnet_res'\n",
    "        num_workers = 8\n",
    "        img_size = 384\n",
    "        nfolds = 5\n",
    "        positive_sampling = 5\n",
    "        negs_per_positive = 10\n",
    "        batch_size = 32\n",
    "        eval_batch_size = 128\n",
    "        seed = 56\n",
    "    class model:\n",
    "        model = 'tf_efficientnetv2_m.in21k'\n",
    "        pretrained = True\n",
    "        optim = torch.optim.AdamW\n",
    "        global_pool = 'avg' # 'avg', 'max', 'avgmax', 'catavg'\n",
    "        drop_path_rate = 0.3 \n",
    "        cls_drop = 0.2\n",
    "        num_chanels = 3\n",
    "        num_labels = 2\n",
    "        hidden_size = 1280 #1280 \n",
    "        scheduler = 'cosine'\n",
    "        max_epoches = 1\n",
    "        lr = 2e-4\n",
    "        num_cycles = 0.5\n",
    "        warmup_ratio = 0.0\n",
    "        lr_head = 2e-4\n",
    "        eps = 1e-12\n",
    "        weight_decay = 0.0\n",
    "        weight_decay_head = 0.0\n",
    "        betas = (0.9, 0.999)\n",
    "    seed = 56\n",
    "    fold_number = 4\n",
    "    \n",
    "class Transforms:\n",
    "    transforms_train = A.Compose([\n",
    "            A.Resize(CFG.data.img_size,CFG.data.img_size),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                rotate_limit=(-10, 10),\n",
    "                scale_limit=(-0.1,0.1),\n",
    "                shift_limit=(-0.05, 0.05),\n",
    "                p=0.25\n",
    "            ),\n",
    "            #A.Downscale(p=0.25,scale_range=(0.25, 0.5)),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.2, -0.2), contrast_limit=(-0.2, 0.2),p=0.5),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    transforms_val = A.Compose([\n",
    "            A.Resize(CFG.data.img_size,CFG.data.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    transforms_test = A.Compose([\n",
    "            A.Resize(CFG.data.img_size,CFG.data.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "def set_wandb_cfg():\n",
    "    config = {}\n",
    "    for k,v in CFG.model.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    for k,v in CFG.data.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    config['fold_number'] = CFG.fold_number\n",
    "    return config\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581fe1d8-6583-49ef-8e7b-c9bda35ee5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data[['isic_id','target','patient_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097788ef-e09e-4465-9677-1a69bd64ea01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(Dataset):\n",
    "    def __init__(self, df, transforms, reader):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.data = df\n",
    "        self.transforms = transforms\n",
    "        self.hdf5_filles = reader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image = np.array(Image.open(io.BytesIO(self.hdf5_filles[row['isic_id']][()])))\n",
    "        image = self.transforms(image=image)['image']\n",
    "            \n",
    "        return {\n",
    "            'image': image.squeeze(0),\n",
    "            'labels': row['target']\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43297269-3f96-405a-81fa-b17b87b722de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.is_setup = False\n",
    "        self.is_prepared = False\n",
    "    \n",
    "    def resample(self,df):\n",
    "        df_0 = df[df['target'] == 0].copy()\n",
    "        df_1 = df[df['target'] == 1].copy()\n",
    "        return pd.concat([df_1] * self.cfg.positive_sampling + [df_0.sample(len(df_1) * self.cfg.positive_sampling * self.cfg.negs_per_positive,random_state=self.cfg.seed)],ignore_index=True,axis=0)\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        if self.is_prepared: return None\n",
    "        self.df = make_df(self.cfg.train_data)\n",
    "        self.transforms = Transforms\n",
    "        self.reader = h5py.File(self.cfg.train_hdf5,'r')\n",
    "        self.is_prepared = True\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup: return None\n",
    "        kf = StratifiedGroupKFold(n_splits=self.cfg.nfolds, shuffle=True, random_state=self.cfg.seed)\n",
    "        splits = [(x,y) for x,y in  kf.split(self.df,self.df['target'],self.df['patient_id'])][CFG.fold_number]\n",
    "        self.train_df, self.val_df = self.df.iloc[splits[0]], self.df.iloc[splits[1]]\n",
    "        self.re_train_df = self.resample(self.train_df)\n",
    "        self.train_dataset = PLDataset(self.re_train_df,self.transforms.transforms_train,self.reader)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.transforms.transforms_val,self.reader)\n",
    "        #self.predict_dataset = PLDataset(self.test_df,self.transforms.transforms_test,self.reader)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                         batch_size=self.cfg.batch_size,\n",
    "                         num_workers=self.cfg.num_workers,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.cfg.eval_batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.cfg.eval_batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75318071-da55-48d5-a203-a8a775f82024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def p_auc_tpr(v_gt, v_pred, min_tpr=0.80, sample_weight=None):\n",
    "    \"\"\"Computes the area under the AUC above a minumum TPR.\n",
    "\n",
    "    Args:\n",
    "        v_gt: ground truth vector (1s and 0s)\n",
    "        v_p: predictions vector of scores ranging [0, 1]\n",
    "        min_tpr: minimum true positive threshold (sensitivity)\n",
    "\n",
    "    Returns:\n",
    "        Float value range [0, 1]\n",
    "    \"\"\"\n",
    "    if len(np.unique(v_gt)) != 2:\n",
    "        raise ValueError(\n",
    "            \"Only one class present in y_true. ROC AUC score \"\n",
    "            \"is not defined in that case.\"\n",
    "        )\n",
    "    \n",
    "    # redefine the target. set 0s to 1s and 1s to 0s\n",
    "    v_gt = abs(np.asarray(v_gt)-1)\n",
    "    v_pred = abs(np.asarray(v_pred)-1)\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    \n",
    "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
    "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=sample_weight)\n",
    "    if max_fpr is None or max_fpr == 1:\n",
    "        return auc(fpr, tpr)\n",
    "    if max_fpr <= 0 or max_fpr > 1:\n",
    "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
    "\n",
    "    # Add a single point at max_fpr by linear interpolation\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    partial_auc = auc(fpr, tpr)\n",
    "    return(partial_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65fadda-6b8d-4abe-9638-c3bee5eb0146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.preds_round = []\n",
    "        self.history = []\n",
    "    \n",
    "    def update(self,y_t,y_p,y_pr):\n",
    "        self.labels += y_t\n",
    "        self.preds_round += y_pr\n",
    "        self.preds += y_p\n",
    "        \n",
    "    def clean(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.preds_round = []\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        metrics = {}\n",
    "        try:\n",
    "            metrics['prauc'] = p_auc_tpr(self.labels,np.stack(self.preds)[:,1])\n",
    "        except:\n",
    "            metrics['prauc'] = -100\n",
    "        self.history.append(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe0af40-5c49-4e68-b644-40becaa6f987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.encoder = timm.create_model(\n",
    "                self.cfg.model,\n",
    "                pretrained=self.cfg.pretrained,\n",
    "                in_chans=self.cfg.num_chanels,\n",
    "                num_classes=-1,\n",
    "                drop_path_rate=self.cfg.drop_path_rate,\n",
    "                global_pool=self.cfg.global_pool\n",
    "        )\n",
    "        self.cls_drop = nn.Dropout(self.cfg.cls_drop)\n",
    "        self.fc = nn.Linear(self.cfg.hidden_size, self.cfg.num_labels)\n",
    "        self._init_weights(self.fc)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, image, return_features=False):\n",
    "        features = self.encoder(image)\n",
    "        if return_features:\n",
    "            return features\n",
    "        logits = self.fc(self.cls_drop(features))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4397afd-4e28-4bc6-a99e-89e4f2933f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.model = Model()\n",
    "        self.avg_meter = AverageMeter()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        output = self.model(batch['image'])\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, i):\n",
    "        logits = self(batch)\n",
    "        loss = self.criterion(logits,batch['labels'])\n",
    "        self.log('train_loss', loss.item())\n",
    "        return loss\n",
    "            \n",
    "    def validation_step(self, batch, i):\n",
    "        logits = self(batch)\n",
    "        loss = self.criterion(logits,batch['labels'])\n",
    "        self.log('val_loss',loss.item())\n",
    "        preds = logits.argmax(dim=-1).tolist()\n",
    "        self.avg_meter.update(batch['labels'].tolist(),logits.tolist(),preds)\n",
    "    \n",
    "    def predict_step(self, batch, i):\n",
    "        logits = self(batch)\n",
    "        return logits.softmax(dim=-1).tolist()\n",
    "                \n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.avg_meter.calc_metrics()\n",
    "        self.log_dict(metrics)\n",
    "        self.avg_meter.clean()\n",
    "            \n",
    "    def configure_optimizers(self):        \n",
    "        optimizer_parameters = [\n",
    "            {'params': self.model.encoder.parameters(),\n",
    "             'lr': self.cfg.lr, 'weight_decay': self.cfg.weight_decay},\n",
    "            {'params': self.model.fc.parameters(),\n",
    "             'lr': self.cfg.lr_head, 'weight_decay': self.cfg.weight_decay_head}\n",
    "        ]\n",
    "        \n",
    "        optim = self.cfg.optim(\n",
    "            optimizer_parameters,\n",
    "            lr=self.cfg.lr,\n",
    "            betas=self.cfg.betas,\n",
    "            weight_decay=self.cfg.weight_decay,\n",
    "            eps=self.cfg.eps\n",
    "        )\n",
    "        \n",
    "        if self.cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warmup_ratio,\n",
    "                                                        num_cycles=self.cfg.num_cycles)\n",
    "        elif self.cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warmup_ratio)\n",
    "        else:\n",
    "            return optim\n",
    "        \n",
    "        scheduler = {'scheduler': scheduler,'interval': 'step', 'frequency': 1}\n",
    "\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c3d5614-868e-4bd7-ae3f-f0b3a90c64b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fold(fold_n=0):\n",
    "    pl.seed_everything(56)\n",
    "    CFG.fold_number = fold_n\n",
    "    \n",
    "    dm = PLDataModule()\n",
    "    dm.prepare_data()\n",
    "    dm.setup(0)\n",
    "    \n",
    "    CFG.model.num_training_steps = len(dm.train_dataloader()) * CFG.model.max_epoches\n",
    "    model = PLModule()\n",
    "    \n",
    "    wandb.login(key=\"31520b01739d418e5d77a11fd8a79a70b189b8bc\")\n",
    "    os.environ['WANDB_API_KEY'] = \"31520b01739d418e5d77a11fd8a79a70b189b8bc\"\n",
    "    wandb.init(project='Kaggle_ISIC',name='effnet_medium',config=set_wandb_cfg())\n",
    "    \n",
    "    model = PLModule()\n",
    "    \n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "    checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=f'./{CFG.data.output_prefix}_outputs_{fold_n}/',\n",
    "        filename='model_{epoch:02d}-{prauc:.4f}',\n",
    "        monitor='prauc',\n",
    "        mode='max',\n",
    "        save_last=True\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        precision=32,\n",
    "        callbacks = [lr_monitor,checkpoint_cb],\n",
    "        logger = pl.loggers.WandbLogger(save_code=True),\n",
    "        log_every_n_steps=1,\n",
    "        min_epochs=1,\n",
    "        devices=1,\n",
    "        check_val_every_n_epoch=1,\n",
    "        max_epochs=CFG.model.max_epoches\n",
    "    )\n",
    "    trainer.fit(model,datamodule=dm)\n",
    "    hist = model.avg_meter.history[-1]['prauc']\n",
    "    model = model.cpu()\n",
    "    del model, trainer, dm, checkpoint_cb, lr_monitor\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27096032-91ae-478e-8f7a-cb4c5076a275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n",
      "/tmp/ipykernel_649/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839039f4d23d4dbbb4273ea5a5b8fb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/325M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewkhl\u001b[0m (\u001b[33mandlh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240828_193909-z749dajw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/z749dajw' target=\"_blank\">effnet_medium</a></strong> to <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/z749dajw' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/z749dajw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /notebooks/effnet_res_outputs_0 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Model            | 52.9 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "52.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.9 M    Total params\n",
      "211.444   Total estimated model params size (MB)\n",
      "989       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad10680b785408798964300712c9c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "score_0 = train_fold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a325ee02-6c35-4aee-899c-3966f459fdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n",
      "/tmp/ipykernel_649/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:z749dajw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.012 MB of 0.022 MB uploaded (0.006 MB deduped)\\r'), FloatProgress(value=0.557043…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 26.2%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg1</td><td>███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>prauc</td><td>▁</td></tr><tr><td>train_loss</td><td>▅▆▆▆▄█▃▄▇▃▄▅▃▃▆▄▂▃▅▄▂▂▃▂▁▂▃▃▃▃▅▂▂▄▂▅▄▁▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>prauc</td><td>0.15677</td></tr><tr><td>train_loss</td><td>0.01616</td></tr><tr><td>trainer/global_step</td><td>531</td></tr><tr><td>val_loss</td><td>0.05649</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effnet_medium</strong> at: <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/z749dajw' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/z749dajw</a><br/> View project at: <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240828_193909-z749dajw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:z749dajw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33208ec4d47440598cec5a4b06e1a2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112980554915136, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240828_194713-57kd0g8z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/57kd0g8z' target=\"_blank\">effnet_medium</a></strong> to <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/57kd0g8z' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/57kd0g8z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /notebooks/effnet_res_outputs_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Model            | 52.9 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "52.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.9 M    Total params\n",
      "211.444   Total estimated model params size (MB)\n",
      "989       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1856a6a720fc4c00bbb7ca1e39ff8803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "score_1 = train_fold(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c2edae-de93-41d9-9491-8eb21fcfc184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n",
      "/tmp/ipykernel_649/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:57kd0g8z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg1</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>prauc</td><td>▁</td></tr><tr><td>train_loss</td><td>▆▃▅▃█▇▂▃▂▅▃▃▂▃▄▂▂▃▃▂▂▂▃▃▄▁▂▂▁▃▃▂▁▄▃▁▆▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>prauc</td><td>0.15274</td></tr><tr><td>train_loss</td><td>0.01004</td></tr><tr><td>trainer/global_step</td><td>562</td></tr><tr><td>val_loss</td><td>0.05584</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effnet_medium</strong> at: <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/57kd0g8z' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/57kd0g8z</a><br/> View project at: <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240828_194713-57kd0g8z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:57kd0g8z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f18be36f58d4737a9260f4c66c14124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111252597765997, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240828_195518-8z0ghw1o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/8z0ghw1o' target=\"_blank\">effnet_medium</a></strong> to <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/8z0ghw1o' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/8z0ghw1o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /notebooks/effnet_res_outputs_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Model            | 52.9 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "52.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.9 M    Total params\n",
      "211.444   Total estimated model params size (MB)\n",
      "989       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2f6b415ad24e45a8a2f7827ef8ec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "score_2 = train_fold(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e136b30-a504-4f0a-a3ed-a7ebcf587661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n",
      "/tmp/ipykernel_649/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8z0ghw1o) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg1</td><td>███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>prauc</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▆▅▅▄█▂▃▆▄▄▂▂▃▅▂▂▄▃▆▅▃█▂▂▁▃▅▃▂▁▂▂▆▄▂▁▆▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>prauc</td><td>0.16483</td></tr><tr><td>train_loss</td><td>0.03274</td></tr><tr><td>trainer/global_step</td><td>522</td></tr><tr><td>val_loss</td><td>0.08221</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effnet_medium</strong> at: <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/8z0ghw1o' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/8z0ghw1o</a><br/> View project at: <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240828_195518-8z0ghw1o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8z0ghw1o). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759dcdd1ac2c486b8c1bb0457045891a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112439254712727, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240828_200341-6pmib8qs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/6pmib8qs' target=\"_blank\">effnet_medium</a></strong> to <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/6pmib8qs' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/6pmib8qs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /notebooks/effnet_res_outputs_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Model            | 52.9 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "52.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.9 M    Total params\n",
      "211.444   Total estimated model params size (MB)\n",
      "989       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e841799f5c54756bf31e0f6fd397ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "score_3 = train_fold(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e38eb1a6-caf8-48ca-bef3-73bb728bfe4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n",
      "/tmp/ipykernel_649/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6pmib8qs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg1</td><td>███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>prauc</td><td>▁</td></tr><tr><td>train_loss</td><td>▄█▆▄▄█▃▄▃▁▅▅▂▂▃▄▃▂▂▄▂▂▂▂▁▃▂▃▂▁▄▄▁▄▁▄▄▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>prauc</td><td>0.14818</td></tr><tr><td>train_loss</td><td>0.20401</td></tr><tr><td>trainer/global_step</td><td>531</td></tr><tr><td>val_loss</td><td>0.04625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effnet_medium</strong> at: <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/6pmib8qs' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/6pmib8qs</a><br/> View project at: <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240828_200341-6pmib8qs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6pmib8qs). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431af90492a943d2a1271d4e2b38446e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111267985543236, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240828_201217-mdi91hjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/mdi91hjp' target=\"_blank\">effnet_medium</a></strong> to <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/mdi91hjp' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/mdi91hjp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /notebooks/effnet_res_outputs_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Model            | 52.9 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "52.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.9 M    Total params\n",
      "211.444   Total estimated model params size (MB)\n",
      "989       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d7df87f5914ac6a9104896cef4707c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "score_4 = train_fold(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0f5228-5253-4276-8874-57fdf206569b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15677033670538,\n",
       " 0.15274188612788592,\n",
       " 0.1648346106892314,\n",
       " 0.14818190074388418,\n",
       " 0.1396130989560096)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_0,score_1,score_2,score_3,score_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c35f2ea8-10d9-4061-a1ca-18710a280550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1524283666444782"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([score_0,score_1,score_2,score_3,score_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af01f6b-ba11-4fe3-a508-0a6fdbc0003b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# effnet\n",
    "# 0.12041390962773615 - 5;5;384\n",
    "# 0.11888069868220903 - 5;5;256\n",
    "# 0.12183054207543556 - 5;5;512\n",
    "# 0.117.............. - 5;5;384 - turn of read drop\n",
    "# 0.10615598570669585 - off drop_path_rate\n",
    "# 0.12581443502801903 - off drop_path_rate=0.3\n",
    "# WITH AUGS 0.147222530452279"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
