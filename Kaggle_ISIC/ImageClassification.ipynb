{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4abb10-86df-469a-9455-da1627bc24ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedGroupKFold\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import cv2\n",
    "import h5py\n",
    "import io\n",
    "import pandas.api.types\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas.api.types\n",
    "import sklearn.metrics\n",
    "from math import sin,cos,pi\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from catboost import CatBoostClassifier,Pool,cv\n",
    "from copy import deepcopy\n",
    "import wandb\n",
    "import timm \n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99196f5-f7fd-48f2-8142-3c73abfd9ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    class data:\n",
    "        train_data= './isic-2024-challenge/train-metadata.csv'\n",
    "        train_hdf5='./isic-2024-challenge/train-image.hdf5'\n",
    "        num_workers = 8\n",
    "        img_size = 384\n",
    "        nfolds = 5\n",
    "        batch_size = 32\n",
    "        seed = 56\n",
    "    class model:\n",
    "        model = 'efficientnetv2_rw_m.agc_in1k'\n",
    "        pretrained = True\n",
    "        optim = torch.optim.AdamW\n",
    "        global_pool = 'avg' # 'avg', 'max', 'avgmax', 'catavg'\n",
    "        drop_path_rate = 0.2\n",
    "        cls_drop = 0.2\n",
    "        num_chanels = 3\n",
    "        num_labels = 2\n",
    "        hidden_size = 2152\n",
    "        scheduler = 'cosine'\n",
    "        head_drop = 0.05\n",
    "        max_epoches = 10\n",
    "        lr = 1e-4\n",
    "        num_cycles = 0.5\n",
    "        warmup_ratio = 0.0\n",
    "        lr_head = 1e-4\n",
    "        eps = 1e-12\n",
    "        weight_decay = 0.0\n",
    "        weight_decay_head = 0.0\n",
    "        betas = (0.9, 0.999)\n",
    "    seed = 56\n",
    "    fold_number = 4\n",
    "    \n",
    "class Transforms:\n",
    "    transforms_train = A.Compose([\n",
    "            A.Resize(CFG.data.img_size,CFG.data.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    transforms_val = A.Compose([\n",
    "            A.Resize(CFG.data.img_size,CFG.data.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    transforms_test = A.Compose([\n",
    "            A.Resize(CFG.data.img_size,CFG.data.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "def set_wandb_cfg():\n",
    "    config = {}\n",
    "    for k,v in CFG.model.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    for k,v in CFG.data.__dict__.items():\n",
    "        if '__' not in k:\n",
    "            config[k] = v\n",
    "    config['fold_number'] = CFG.fold_number\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581fe1d8-6583-49ef-8e7b-c9bda35ee5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data[['isic_id','target','patient_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097788ef-e09e-4465-9677-1a69bd64ea01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(Dataset):\n",
    "    def __init__(self, df, transforms, reader):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.data = df\n",
    "        self.transforms = transforms\n",
    "        self.hdf5_filles = reader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image = np.array(Image.open(io.BytesIO(self.hdf5_filles[row['isic_id']][()])))\n",
    "        image = self.transforms(image=image)['image']\n",
    "            \n",
    "        return {\n",
    "            'image': image.squeeze(0),\n",
    "            'labels': row['target']\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43297269-3f96-405a-81fa-b17b87b722de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.is_setup = False\n",
    "        self.is_prepared = False\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        if self.is_prepared: return None\n",
    "        self.df = make_df(self.cfg.train_data)\n",
    "        self.transforms = Transforms\n",
    "        self.reader = h5py.File(self.cfg.train_hdf5,'r')\n",
    "        self.is_prepared = True\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup: return None\n",
    "        kf = StratifiedGroupKFold(n_splits=self.cfg.nfolds, shuffle=True, random_state=self.cfg.seed)\n",
    "        splits = [(x,y) for x,y in  kf.split(self.df,self.df['target'],self.df['patient_id'])][CFG.fold_number]\n",
    "        self.train_df, self.val_df = self.df.iloc[splits[0]], self.df.iloc[splits[1]]\n",
    "        self.train_dataset = PLDataset(self.train_df,self.transforms.transforms_train,self.reader)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.transforms.transforms_val,self.reader)\n",
    "        #self.predict_dataset = PLDataset(self.test_df,self.transforms.transforms_test,self.reader)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                         batch_size=self.cfg.batch_size,\n",
    "                         num_workers=self.cfg.num_workers,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.cfg.batch_size,\n",
    "                          num_workers=self.cfg.num_workers,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75318071-da55-48d5-a203-a8a775f82024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def p_auc_tpr(v_gt, v_pred, min_tpr=0.80, sample_weight=None):\n",
    "    \"\"\"Computes the area under the AUC above a minumum TPR.\n",
    "\n",
    "    Args:\n",
    "        v_gt: ground truth vector (1s and 0s)\n",
    "        v_p: predictions vector of scores ranging [0, 1]\n",
    "        min_tpr: minimum true positive threshold (sensitivity)\n",
    "\n",
    "    Returns:\n",
    "        Float value range [0, 1]\n",
    "    \"\"\"\n",
    "    if len(np.unique(v_gt)) != 2:\n",
    "        raise ValueError(\n",
    "            \"Only one class present in y_true. ROC AUC score \"\n",
    "            \"is not defined in that case.\"\n",
    "        )\n",
    "    \n",
    "    # redefine the target. set 0s to 1s and 1s to 0s\n",
    "    v_gt = abs(np.asarray(v_gt)-1)\n",
    "    v_pred = abs(np.asarray(v_pred)-1)\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    \n",
    "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
    "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=sample_weight)\n",
    "    if max_fpr is None or max_fpr == 1:\n",
    "        return auc(fpr, tpr)\n",
    "    if max_fpr <= 0 or max_fpr > 1:\n",
    "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
    "\n",
    "    # Add a single point at max_fpr by linear interpolation\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    partial_auc = auc(fpr, tpr)\n",
    "    return(partial_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65fadda-6b8d-4abe-9638-c3bee5eb0146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.preds_round = []\n",
    "        self.history = []\n",
    "    \n",
    "    def update(self,y_t,y_p,y_pr):\n",
    "        self.labels += y_t\n",
    "        self.preds_round += y_pr\n",
    "        self.preds += y_p\n",
    "        \n",
    "    def clean(self):\n",
    "        self.preds = []\n",
    "        self.labels = []\n",
    "        self.preds_round = []\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        metrics = {}\n",
    "        try:\n",
    "            metrics['prauc'] = p_auc_tpr(self.labels,np.stack(self.preds)[:,1])\n",
    "        except:\n",
    "            metrics['prauc'] = -100\n",
    "        self.history.append(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe0af40-5c49-4e68-b644-40becaa6f987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.encoder = timm.create_model(\n",
    "                self.cfg.model,\n",
    "                pretrained=self.cfg.pretrained,\n",
    "                in_chans=self.cfg.num_chanels,\n",
    "                num_classes=-1,\n",
    "                drop_path_rate=self.cfg.drop_path_rate,\n",
    "                global_pool=self.cfg.global_pool\n",
    "        )\n",
    "        self.cls_drop = nn.Dropout(self.cfg.cls_drop)\n",
    "        self.fc = nn.Linear(self.cfg.hidden_size, self.cfg.num_labels)\n",
    "        self._init_weights(self.fc)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, image, return_features=False):\n",
    "        features = self.encoder(image)\n",
    "        if return_features:\n",
    "            return features\n",
    "        logits = self.fc(self.cls_drop(features))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4397afd-4e28-4bc6-a99e-89e4f2933f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.model = Model()\n",
    "        self.avg_meter = AverageMeter()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        output = self.model(batch['image'])\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, i):\n",
    "        logits = self(batch)\n",
    "        loss = self.criterion(logits,batch['labels'])\n",
    "        self.log('train_loss', loss.item())\n",
    "        return loss\n",
    "            \n",
    "    def validation_step(self, batch, i):\n",
    "        logits = self(batch)\n",
    "        loss = self.criterion(logits,batch['labels'])\n",
    "        self.log('val_loss',loss.item())\n",
    "        preds = logits.argmax(dim=-1).tolist()\n",
    "        self.avg_meter.update(batch['labels'].tolist(),logits.tolist(),preds)\n",
    "    \n",
    "    def predict_step(self, batch, i):\n",
    "        logits = self(batch)\n",
    "        return logits.softmax(dim=-1).tolist()\n",
    "                \n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.avg_meter.calc_metrics()\n",
    "        self.log_dict(metrics)\n",
    "        self.avg_meter.clean()\n",
    "            \n",
    "    def configure_optimizers(self):        \n",
    "        optimizer_parameters = [\n",
    "            {'params': self.model.encoder.parameters(),\n",
    "             'lr': self.cfg.lr, 'weight_decay': self.cfg.weight_decay},\n",
    "            {'params': self.model.fc.parameters(),\n",
    "             'lr': self.cfg.lr_head, 'weight_decay': self.cfg.weight_decay_head}\n",
    "        ]\n",
    "        \n",
    "        optim = self.cfg.optim(\n",
    "            optimizer_parameters,\n",
    "            lr=self.cfg.lr,\n",
    "            betas=self.cfg.betas,\n",
    "            weight_decay=self.cfg.weight_decay,\n",
    "            eps=self.cfg.eps\n",
    "        )\n",
    "        \n",
    "        if self.cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warmup_ratio,\n",
    "                                                        num_cycles=self.cfg.num_cycles)\n",
    "        elif self.cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                                        num_training_steps=self.cfg.num_training_steps,\n",
    "                                                        num_warmup_steps=self.cfg.num_training_steps * self.cfg.warmup_ratio)\n",
    "        else:\n",
    "            return optim\n",
    "        \n",
    "        scheduler = {'scheduler': scheduler,'interval': 'step', 'frequency': 1}\n",
    "\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c40cb-2ab0-4d48-9f91-d992fa03d35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf86a72-3d72-4150-bcb5-4d26d66a9b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG.model.num_training_steps = len(dm.train_dataloader()) * CFG.model.max_epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7533e04-6a44-45f6-a98d-4474570b8666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnetv2_rw_m.agc_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnetv2_rw_m.agc_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    }
   ],
   "source": [
    "model = PLModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db78a4ac-e54b-4ea6-a15e-c1a2a88e11c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewkhl\u001b[0m (\u001b[33mandlh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240814_193851-065pfy2l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/065pfy2l' target=\"_blank\">effnet_medium</a></strong> to <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andlh/Kaggle_ISIC' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andlh/Kaggle_ISIC/runs/065pfy2l' target=\"_blank\">https://wandb.ai/andlh/Kaggle_ISIC/runs/065pfy2l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andlh/Kaggle_ISIC/runs/065pfy2l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6e31120410>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"31520b01739d418e5d77a11fd8a79a70b189b8bc\")\n",
    "os.environ['WANDB_API_KEY'] = \"31520b01739d418e5d77a11fd8a79a70b189b8bc\"\n",
    "wandb.init(project='Kaggle_ISIC',name='effnet_medium',config=set_wandb_cfg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56728f3a-0ab6-457e-b3fc-70a7f601b601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs/',\n",
    "    filename='model_{epoch:02d}-{prauc:.4f}',\n",
    "    monitor='prauc',\n",
    "    mode='max',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=32,\n",
    "    callbacks = [lr_monitor,checkpoint_cb],\n",
    "    logger = pl.loggers.WandbLogger(save_code=True),\n",
    "    log_every_n_steps=1,\n",
    "    min_epochs=1,\n",
    "    devices=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=CFG.model.max_epoches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d5d95fb-ae35-4adf-926d-691af7756b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "CFG.fold_number = 0\n",
    "\n",
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8616f69-87d8-43db-8f80-ec9b91d2740c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "Restoring states from the checkpoint path at outputs_0/model_epoch=01-prauc=0.1420.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at outputs_0/model_epoch=01-prauc=0.1420.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede8b744a84c44a4ab4e6f6e7d5b8882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_fold_0 = trainer.predict(model,dm.val_dataloader(),ckpt_path=\"outputs_0/model_epoch=01-prauc=0.1420.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39251198-ae14-4ea9-b82c-f15575e51a87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "CFG.fold_number = 1\n",
    "\n",
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d4eb6af-9ced-474a-a485-593f3b719fec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at outputs_1/model_epoch=00-prauc=0.1286.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at outputs_1/model_epoch=00-prauc=0.1286.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceecd5231a014fd9a418e5a6af439642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_fold_1 = trainer.predict(model,dm.val_dataloader(),ckpt_path=\"outputs_1/model_epoch=00-prauc=0.1286.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a9d091c-b765-44b0-9394-18e8d1f0af1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "CFG.fold_number = 2\n",
    "\n",
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f0f6bf2-2c52-40c5-b2d7-ed458ac674ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at outputs_2/model_epoch=00-prauc=0.1182.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at outputs_2/model_epoch=00-prauc=0.1182.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c56f606183a465f80df446cc09af639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_fold_2 = trainer.predict(model,dm.val_dataloader(),ckpt_path=\"outputs_2/model_epoch=00-prauc=0.1182.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2adfa0a-d07b-4935-8dec-4f37c4249769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "CFG.fold_number = 3\n",
    "\n",
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14e89d0e-2aee-45f7-b121-cd0549579a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at outputs/model_epoch=01-prauc=0.1401.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at outputs/model_epoch=01-prauc=0.1401.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142e1570fd3648b5bddfd57d9870ef75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_fold_3 = trainer.predict(model,dm.val_dataloader(),ckpt_path=\"outputs/model_epoch=01-prauc=0.1401.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f22b55a4-6134-4381-b26d-6fb38c1cf507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/2786575331.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "CFG.fold_number = 4\n",
    "\n",
    "dm = PLDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf480f3d-ab6d-4223-a95e-1f4bbd749950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at outputs/model_epoch=01-prauc=0.1257.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at outputs/model_epoch=01-prauc=0.1257.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572d9c32e01f4d92b68bd9b7ca3f5543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_fold_4 = trainer.predict(model,dm.val_dataloader(),ckpt_path=\"outputs/model_epoch=01-prauc=0.1257.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "723bd8cd-e90f-41f1-a759-bfd4b77624c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = dm.df.copy()\n",
    "\n",
    "kf = StratifiedGroupKFold(n_splits=dm.cfg.nfolds, shuffle=True, random_state=dm.cfg.seed)\n",
    "splits = [(x,y) for x,y in  kf.split(df,df['target'],df['patient_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a1f5c31-a449-476b-ac60-a5a13a046dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['fold'] = -1\n",
    "df.loc[splits[0][1],'fold'] = 0\n",
    "df.loc[splits[1][1],'fold'] = 1\n",
    "df.loc[splits[2][1],'fold'] = 2\n",
    "df.loc[splits[3][1],'fold'] = 3\n",
    "df.loc[splits[4][1],'fold'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40e47c6e-b912-4c2d-8390-519971f81d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.31417289e-05, 1.26163577e-04, 2.19719863e-04, ...,\n",
       "       6.85076157e-05, 1.01727387e-03, 3.48700996e-04])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(preds_fold_4)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c366841b-6557-4379-a8de-081f3765e0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/1382868842.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[8.61431588e-04 1.04059407e-04 1.90227700e-04 ... 4.27426246e-04\n",
      " 7.16760987e-05 7.33906927e-05]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[splits[0][1],'predict'] = np.concatenate(preds_fold_0)[:,1]\n"
     ]
    }
   ],
   "source": [
    "df['predict'] = -1\n",
    "df.loc[splits[0][1],'predict'] = np.concatenate(preds_fold_0)[:,1]\n",
    "df.loc[splits[1][1],'predict'] = np.concatenate(preds_fold_1)[:,1]\n",
    "df.loc[splits[2][1],'predict'] = np.concatenate(preds_fold_2)[:,1]\n",
    "df.loc[splits[3][1],'predict'] = np.concatenate(preds_fold_3)[:,1]\n",
    "df.loc[splits[4][1],'predict'] = np.concatenate(preds_fold_4)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8fa9cd2b-6230-48a9-b02e-93dc311a2841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f538e971-5ccf-40d7-8cbe-128db16af17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def p_auc_tpr(v_gt, v_pred, min_tpr=0.80, sample_weight=None):\n",
    "    \"\"\"Computes the area under the AUC above a minumum TPR.\n",
    "\n",
    "    Args:\n",
    "        v_gt: ground truth vector (1s and 0s)\n",
    "        v_p: predictions vector of scores ranging [0, 1]\n",
    "        min_tpr: minimum true positive threshold (sensitivity)\n",
    "\n",
    "    Returns:\n",
    "        Float value range [0, 1]\n",
    "    \"\"\"\n",
    "    if len(np.unique(v_gt)) != 2:\n",
    "        raise ValueError(\n",
    "            \"Only one class present in y_true. ROC AUC score \"\n",
    "            \"is not defined in that case.\"\n",
    "        )\n",
    "    \n",
    "    # redefine the target. set 0s to 1s and 1s to 0s\n",
    "    v_gt = abs(np.asarray(v_gt)-1)\n",
    "    v_pred = abs(np.asarray(v_pred)-1)\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    \n",
    "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
    "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=sample_weight)\n",
    "    if max_fpr is None or max_fpr == 1:\n",
    "        return auc(fpr, tpr)\n",
    "    if max_fpr <= 0 or max_fpr > 1:\n",
    "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
    "\n",
    "    # Add a single point at max_fpr by linear interpolation\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    partial_auc = auc(fpr, tpr)\n",
    "    return(partial_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ab723a8-0beb-47fa-8fdc-5792a35ca31c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1230816492067425"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_auc_tpr(df['target'],df['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05a961df-175c-433a-913d-a14362457bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401054</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401057</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401058</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401059 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target   predict\n",
       "0            0  0.000740\n",
       "1            0  0.003848\n",
       "2            0  0.000113\n",
       "3            0  0.000126\n",
       "4            0  0.000861\n",
       "...        ...       ...\n",
       "401054       0  0.000210\n",
       "401055       0  0.000138\n",
       "401056       0  0.000072\n",
       "401057       0  0.000073\n",
       "401058       0  0.000349\n",
       "\n",
       "[401059 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['target','predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3f729f8-d687-47f0-8307-a56572511c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('simple_effnet_preds.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
