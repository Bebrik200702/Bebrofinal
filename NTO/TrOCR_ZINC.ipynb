{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4108bae3-82e0-4e67-86ee-ebbaa1b56f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.py\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DefaultDataCollator\n",
    "from PIL import Image\n",
    "import requests\n",
    "from evaluate import load\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, load_from_disk, load_dataset\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import Draw\n",
    "from io import BytesIO\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')  \n",
    "\n",
    "wandb.login(key=\"673ae6e9b51cc896110db5327738b993795fffad\")\n",
    "os.environ['WANDB_API_KEY'] = \"673ae6e9b51cc896110db5327738b993795fffad\"\n",
    "wandb.init(project='DoHACK',name='TrOCR_Small')\n",
    "\n",
    "cer = load('cer')\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "set_seed()\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "molecula_130m = load_dataset(\"parquet\", data_files=\"train_90m_ZINK_uniq.parquet.gzip\")['train']\n",
    "#zinc20 = load_dataset('sagawa/ZINC-canonicalized')['train']\n",
    "#zinc20 = zinc20.filter(lambda x: Chem.MolFromSmiles(x['smiles']) is not None and len(x['smiles']) < 128, num_proc=2)\n",
    "ds = molecula_130m.train_test_split(0.0001, seed=42)\n",
    "dataset_train = ds['train']\n",
    "dataset_val = ds['test']\n",
    "tokenizer = AutoTokenizer.from_pretrained('sagawa/PubChem-10m-t5-v2')\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-small-printed')\n",
    "processor.tokenizer= tokenizer\n",
    "\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "from transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder import shift_tokens_right\n",
    "from transformers.models.trocr.modeling_trocr import TrOCRLearnedPositionalEmbedding\n",
    "class VisionEncoderDecoderSmooth(VisionEncoderDecoderModel):\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values = None,\n",
    "        decoder_input_ids = None,\n",
    "        decoder_attention_mask = None,\n",
    "        encoder_outputs = None,\n",
    "        past_key_values = None,\n",
    "        decoder_inputs_embeds = None,\n",
    "        labels=None,\n",
    "        use_cache = None,\n",
    "        output_attentions = None,\n",
    "        output_hidden_states = True,\n",
    "        return_dict = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        kwargs_encoder = {argument: value for argument, value in kwargs.items() if not argument.startswith(\"decoder_\")}\n",
    "\n",
    "        kwargs_decoder = {\n",
    "            argument[len(\"decoder_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"decoder_\")\n",
    "        }\n",
    "\n",
    "        if encoder_outputs is None:\n",
    "            if pixel_values is None:\n",
    "                raise ValueError(\"You have to specify pixel_values\")\n",
    "\n",
    "            encoder_outputs = self.encoder(\n",
    "                pixel_values,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "                **kwargs_encoder,\n",
    "            )\n",
    "        elif isinstance(encoder_outputs, tuple):\n",
    "            encoder_outputs = BaseModelOutput(*encoder_outputs)\n",
    "\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # optionally project encoder_hidden_states\n",
    "        if (\n",
    "            self.encoder.config.hidden_size != self.decoder.config.hidden_size\n",
    "            and self.decoder.config.cross_attention_hidden_size is None\n",
    "        ):\n",
    "            encoder_hidden_states = self.enc_to_dec_proj(encoder_hidden_states)\n",
    "\n",
    "        # else:\n",
    "        encoder_attention_mask = None\n",
    "\n",
    "        if (labels is not None) and (decoder_input_ids is None and decoder_inputs_embeds is None):\n",
    "            decoder_input_ids = shift_tokens_right(\n",
    "                labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "            )\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            use_cache=use_cache,\n",
    "            past_key_values=past_key_values,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs_decoder,\n",
    "        )\n",
    "\n",
    "        # Compute loss independent from decoder (as some shift the logits inside them)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            logits = decoder_outputs.logits if return_dict else decoder_outputs[0]\n",
    "            loss_fct = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "            loss = loss_fct(logits.reshape(-1, self.decoder.config.vocab_size), labels.reshape(-1))\n",
    "            \n",
    "            \n",
    "\n",
    "        if not return_dict:\n",
    "            if loss is not None:\n",
    "                return (loss,) + decoder_outputs + encoder_outputs\n",
    "            else:\n",
    "                return decoder_outputs + encoder_outputs\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=loss,\n",
    "            logits=decoder_outputs.logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "model = VisionEncoderDecoderSmooth.from_pretrained('microsoft/trocr-small-printed')\n",
    "model.decoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "processor.tokenizer.cls_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "model.config.eos_token_id = processor.tokenizer.eos_token_id\n",
    "model.config.max_length = 256\n",
    "\n",
    "\n",
    "def draw_smiles(smiles):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    d2d = Draw.MolDraw2DCairo(512,512)\n",
    "    dopts = d2d.drawOptions()\n",
    "    dopts.useBWAtomPalette()\n",
    "    d2d.DrawMolecule(m)\n",
    "    d2d.FinishDrawing()\n",
    "    bio = BytesIO(d2d.GetDrawingText())\n",
    "    return Image.open(bio).convert('RGB')\n",
    "\n",
    "MERGE_PROB = 0.2\n",
    "merge_i = 0\n",
    "ORGANIC_SET = ['B', 'C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I']\n",
    "ELEMENTS = [\n",
    "    \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\n",
    "    \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\",\n",
    "    \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\",\n",
    "    \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\",\n",
    "    \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\",\n",
    "    \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\",\n",
    "    \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\",\n",
    "    \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\",\n",
    "    \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\",\n",
    "    \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\",\n",
    "    \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\", \"Bh\", \"Hs\", \"Mt\", \"Ds\",\n",
    "    \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n",
    "]\n",
    "\n",
    "ATOMS = ORGANIC_SET + [f'[{e}]' for e in ELEMENTS]\n",
    "\n",
    "def aug_smiles(smiles):\n",
    "    global merge_i\n",
    "    \n",
    "    if random.random() < MERGE_PROB:\n",
    "        mode = random.choice(['long', 'short'])\n",
    "        if mode == 'long':\n",
    "            pass\n",
    "            #add_smiles_idx = merge_i % len_merge\n",
    "            #merge_i += 1\n",
    "            #smileses = [smiles, zinc20[add_smiles_idx]['smiles']]\n",
    "            #smileses.sort(key=len)\n",
    "            #smiles = '.'.join(smileses)\n",
    "        else:\n",
    "            count = random.randint(1, 3)\n",
    "            add_atoms = np.random.choice(ATOMS, count)\n",
    "            smileses = [smiles]\n",
    "            smileses.extend(list(add_atoms))\n",
    "            smileses.sort(key=len)\n",
    "            smiles = '.'.join(smileses)\n",
    "    #smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), kekuleSmiles=True)\n",
    "    return smiles\n",
    "\n",
    "def prepare_features(examples):\n",
    "    smileses = [aug_smiles(s) for s in examples['smiles']]\n",
    "    images = [draw_smiles(s) for s in smileses]\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    target_encoding = processor.tokenizer(\n",
    "        [f'{i}' for i in smileses],\n",
    "        padding=\"longest\",\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    tokenized_examples = {'pixel_values': pixel_values}\n",
    "    labels = target_encoding.input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    tokenized_examples['labels'] = labels\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_dataset_train = dataset_train.with_transform(\n",
    "    prepare_features)\n",
    "tokenized_dataset_val = dataset_val.with_transform(\n",
    "    prepare_features)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    'models',\n",
    "    remove_unused_columns=False,\n",
    "    save_safetensors = False,\n",
    "    evaluation_strategy = 'steps',\n",
    "    per_device_train_batch_size = 64,\n",
    "    per_device_eval_batch_size = 64,\n",
    "    learning_rate = 4e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps = 5,\n",
    "    save_strategy = 'steps',\n",
    "    eval_steps = 2_000,\n",
    "    save_steps=500,\n",
    "    report_to = 'wandb',\n",
    "    gradient_accumulation_steps=4,\n",
    "    dataloader_num_workers=12,\n",
    "    lr_scheduler_type = 'cosine',\n",
    "    predict_with_generate = True,\n",
    "    save_total_limit = 10,\n",
    "    optim='adamw_torch',\n",
    "    adam_beta2 = 0.98,\n",
    ")\n",
    "\n",
    "def compute_metrics(preds):\n",
    "    labels, predictions = preds.label_ids, preds.predictions\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    print(labels[-1], predictions[-1])\n",
    "    y_true = [x.strip() for x in labels]\n",
    "    y_pred = [x.strip() for x in predictions]\n",
    "    return {f'cer': cer.compute(predictions=y_pred, references=y_true)}\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset = tokenized_dataset_train,\n",
    "    eval_dataset = tokenized_dataset_val,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    data_collator=DefaultDataCollator()\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a3ffe4-1087-4282-ad74-23afd383a058",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrey20007\u001b[0m (\u001b[33mandrey2007\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to \u001b[34m\u001b[4mhttps://wandb.me/wandb-init\u001b[0m.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/notebooks/wandb/run-20240205_143851-19qqchd1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTrOCR_Small\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/andrey2007/DoHACK\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/andrey2007/DoHACK/runs/19qqchd1\u001b[0m\n",
      "Random seed set as 42\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "/usr/local/lib/python3.9/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of VisionEncoderDecoderSmooth were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "{'loss': 7.2253, 'learning_rate': 0.000399999999967986, 'epoch': 0.0}           \n",
      "{'loss': 4.2375, 'learning_rate': 0.00039999999960782864, 'epoch': 0.0}         \n",
      "{'loss': 3.4648, 'learning_rate': 0.0003999999988474965, 'epoch': 0.0}          \n",
      "{'loss': 3.3397, 'learning_rate': 0.0003999999976869895, 'epoch': 0.0}          \n",
      "{'loss': 3.3115, 'learning_rate': 0.00039999999612630764, 'epoch': 0.0}         \n",
      "{'loss': 3.2688, 'learning_rate': 0.000399999994165451, 'epoch': 0.0}           \n",
      "{'loss': 3.2138, 'learning_rate': 0.00039999999180441947, 'epoch': 0.0}         \n",
      "{'loss': 3.0489, 'learning_rate': 0.0003999999890432131, 'epoch': 0.0}          \n",
      "{'loss': 2.8367, 'learning_rate': 0.00039999998588183196, 'epoch': 0.0}         \n",
      "{'loss': 2.6166, 'learning_rate': 0.000399999982320276, 'epoch': 0.0}           \n",
      "{'loss': 2.4521, 'learning_rate': 0.0003999999783585453, 'epoch': 0.0}          \n",
      "{'loss': 2.34, 'learning_rate': 0.00039999997399663975, 'epoch': 0.0}           \n",
      "{'loss': 2.2655, 'learning_rate': 0.0003999999692345594, 'epoch': 0.0}          \n",
      "{'loss': 2.2638, 'learning_rate': 0.00039999996407230436, 'epoch': 0.0}         \n",
      "{'loss': 2.1579, 'learning_rate': 0.0003999999585098745, 'epoch': 0.0}          \n",
      "{'loss': 2.0838, 'learning_rate': 0.0003999999525472699, 'epoch': 0.0}          \n",
      "{'loss': 2.0385, 'learning_rate': 0.00039999994618449057, 'epoch': 0.0}         \n",
      "{'loss': 1.9974, 'learning_rate': 0.00039999993942153644, 'epoch': 0.0}         \n",
      "{'loss': 1.9541, 'learning_rate': 0.0003999999322584077, 'epoch': 0.0}          \n",
      "{'loss': 1.9242, 'learning_rate': 0.0003999999246951042, 'epoch': 0.0}          \n",
      "{'loss': 1.8978, 'learning_rate': 0.00039999991673162605, 'epoch': 0.0}         \n",
      "{'loss': 1.8619, 'learning_rate': 0.0003999999083679732, 'epoch': 0.0}          \n",
      "{'loss': 1.8331, 'learning_rate': 0.0003999998996041457, 'epoch': 0.0}          \n",
      "{'loss': 1.8109, 'learning_rate': 0.00039999989044014355, 'epoch': 0.0}         \n",
      "{'loss': 1.7824, 'learning_rate': 0.0003999998808759668, 'epoch': 0.0}          \n",
      "{'loss': 1.7861, 'learning_rate': 0.00039999987091161545, 'epoch': 0.0}         \n",
      "{'loss': 1.7572, 'learning_rate': 0.00039999986054708954, 'epoch': 0.0}         \n",
      "{'loss': 1.7422, 'learning_rate': 0.00039999984978238905, 'epoch': 0.0}         \n",
      "{'loss': 1.7357, 'learning_rate': 0.0003999998386175141, 'epoch': 0.0}          \n",
      "{'loss': 1.717, 'learning_rate': 0.00039999982705246455, 'epoch': 0.0}          \n",
      "{'loss': 1.6977, 'learning_rate': 0.0003999998150872405, 'epoch': 0.0}          \n",
      "{'loss': 1.7151, 'learning_rate': 0.000399999802721842, 'epoch': 0.0}           \n",
      "{'loss': 1.6949, 'learning_rate': 0.0003999997899562691, 'epoch': 0.0}          \n",
      "{'loss': 1.6893, 'learning_rate': 0.0003999997767905217, 'epoch': 0.0}          \n",
      "{'loss': 1.6762, 'learning_rate': 0.0003999997632246, 'epoch': 0.0}             \n",
      "{'loss': 1.6643, 'learning_rate': 0.000399999749258504, 'epoch': 0.0}           \n",
      "{'loss': 1.6645, 'learning_rate': 0.00039999973489223355, 'epoch': 0.0}         \n",
      "{'loss': 1.6732, 'learning_rate': 0.0003999997201257888, 'epoch': 0.0}          \n",
      "{'loss': 1.6535, 'learning_rate': 0.0003999997049591698, 'epoch': 0.0}          \n",
      "{'loss': 1.6527, 'learning_rate': 0.0003999996893923766, 'epoch': 0.0}          \n",
      "{'loss': 1.6463, 'learning_rate': 0.0003999996734254091, 'epoch': 0.0}          \n",
      "{'loss': 1.652, 'learning_rate': 0.00039999965705826744, 'epoch': 0.0}          \n",
      "{'loss': 1.635, 'learning_rate': 0.0003999996402909517, 'epoch': 0.0}           \n",
      "{'loss': 1.6152, 'learning_rate': 0.0003999996231234618, 'epoch': 0.0}          \n",
      "{'loss': 1.6182, 'learning_rate': 0.0003999996055557978, 'epoch': 0.0}          \n",
      "{'loss': 1.6197, 'learning_rate': 0.0003999995875879598, 'epoch': 0.0}          \n",
      "{'loss': 1.6157, 'learning_rate': 0.00039999956921994766, 'epoch': 0.0}         \n",
      "{'loss': 1.6176, 'learning_rate': 0.00039999955045176165, 'epoch': 0.0}         \n",
      "{'loss': 1.6066, 'learning_rate': 0.0003999995312834017, 'epoch': 0.0}          \n",
      "{'loss': 1.6049, 'learning_rate': 0.00039999951171486786, 'epoch': 0.0}         \n",
      "{'loss': 1.6015, 'learning_rate': 0.0003999994917461602, 'epoch': 0.0}          \n",
      "{'loss': 1.5995, 'learning_rate': 0.0003999994713772786, 'epoch': 0.0}          \n",
      "{'loss': 1.5951, 'learning_rate': 0.0003999994506082233, 'epoch': 0.0}          \n",
      "{'loss': 1.6031, 'learning_rate': 0.0003999994294389943, 'epoch': 0.0}          \n",
      "{'loss': 1.5873, 'learning_rate': 0.0003999994078695915, 'epoch': 0.0}          \n",
      "{'loss': 1.5772, 'learning_rate': 0.0003999993859000152, 'epoch': 0.0}          \n",
      "{'loss': 1.5785, 'learning_rate': 0.00039999936353026514, 'epoch': 0.0}         \n",
      "{'loss': 1.5764, 'learning_rate': 0.0003999993407603416, 'epoch': 0.0}          \n",
      "{'loss': 1.5568, 'learning_rate': 0.0003999993175902446, 'epoch': 0.0}          \n",
      "{'loss': 1.5606, 'learning_rate': 0.000399999294019974, 'epoch': 0.0}           \n",
      "{'loss': 1.5571, 'learning_rate': 0.00039999927004953, 'epoch': 0.0}            \n",
      "{'loss': 1.5514, 'learning_rate': 0.0003999992456789127, 'epoch': 0.0}          \n",
      "{'loss': 1.567, 'learning_rate': 0.000399999220908122, 'epoch': 0.0}            \n",
      "{'loss': 1.5537, 'learning_rate': 0.0003999991957371581, 'epoch': 0.0}          \n",
      "{'loss': 1.5564, 'learning_rate': 0.00039999917016602087, 'epoch': 0.0}         \n",
      "{'loss': 1.5434, 'learning_rate': 0.00039999914419471054, 'epoch': 0.0}         \n",
      "{'loss': 1.5364, 'learning_rate': 0.0003999991178232271, 'epoch': 0.0}          \n",
      "{'loss': 1.5351, 'learning_rate': 0.00039999909105157053, 'epoch': 0.0}         \n",
      "{'loss': 1.5406, 'learning_rate': 0.000399999063879741, 'epoch': 0.0}           \n",
      "{'loss': 1.5458, 'learning_rate': 0.00039999903630773845, 'epoch': 0.0}         \n",
      "{'loss': 1.5425, 'learning_rate': 0.00039999900833556304, 'epoch': 0.0}         \n",
      "{'loss': 1.5405, 'learning_rate': 0.0003999989799632148, 'epoch': 0.0}          \n",
      "{'loss': 1.536, 'learning_rate': 0.0003999989511906937, 'epoch': 0.0}           \n",
      "{'loss': 1.5387, 'learning_rate': 0.0003999989220179999, 'epoch': 0.0}          \n",
      "{'loss': 1.535, 'learning_rate': 0.00039999889244513346, 'epoch': 0.0}          \n",
      "{'loss': 1.535, 'learning_rate': 0.0003999988624720943, 'epoch': 0.0}           \n",
      "{'loss': 1.5187, 'learning_rate': 0.0003999988320988826, 'epoch': 0.0}          \n",
      "{'loss': 1.5133, 'learning_rate': 0.0003999988013254985, 'epoch': 0.0}          \n",
      "{'loss': 1.521, 'learning_rate': 0.0003999987701519419, 'epoch': 0.0}           \n",
      "{'loss': 1.5241, 'learning_rate': 0.0003999987385782129, 'epoch': 0.0}          \n",
      "{'loss': 1.5244, 'learning_rate': 0.0003999987066043116, 'epoch': 0.0}          \n",
      "{'loss': 1.527, 'learning_rate': 0.0003999986742302381, 'epoch': 0.0}           \n",
      "{'loss': 1.5253, 'learning_rate': 0.00039999864145599237, 'epoch': 0.0}         \n",
      "{'loss': 1.5155, 'learning_rate': 0.0003999986082815745, 'epoch': 0.0}          \n",
      "{'loss': 1.5019, 'learning_rate': 0.0003999985747069847, 'epoch': 0.0}          \n",
      "{'loss': 1.5089, 'learning_rate': 0.00039999854073222277, 'epoch': 0.0}         \n",
      "{'loss': 1.4966, 'learning_rate': 0.000399998506357289, 'epoch': 0.0}           \n",
      "{'loss': 1.4995, 'learning_rate': 0.00039999847158218334, 'epoch': 0.0}         \n",
      "{'loss': 1.4929, 'learning_rate': 0.00039999843640690593, 'epoch': 0.0}         \n",
      "{'loss': 1.5008, 'learning_rate': 0.0003999984008314568, 'epoch': 0.0}          \n",
      "{'loss': 1.5072, 'learning_rate': 0.00039999836485583607, 'epoch': 0.0}         \n",
      "{'loss': 1.4939, 'learning_rate': 0.00039999832848004377, 'epoch': 0.0}         \n",
      "{'loss': 1.5048, 'learning_rate': 0.00039999829170408, 'epoch': 0.0}            \n",
      "{'loss': 1.4992, 'learning_rate': 0.00039999825452794477, 'epoch': 0.0}         \n",
      "{'loss': 1.4965, 'learning_rate': 0.0003999982169516382, 'epoch': 0.0}          \n",
      "{'loss': 1.4903, 'learning_rate': 0.00039999817897516036, 'epoch': 0.0}         \n",
      "{'loss': 1.474, 'learning_rate': 0.00039999814059851134, 'epoch': 0.0}          \n",
      "{'loss': 1.4831, 'learning_rate': 0.00039999810182169115, 'epoch': 0.0}         \n",
      "{'loss': 1.5049, 'learning_rate': 0.0003999980626447, 'epoch': 0.0}             \n",
      "{'loss': 1.481, 'learning_rate': 0.00039999802306753783, 'epoch': 0.0}          \n",
      "  0%|                                   | 500/351164 [07:24<84:05:10,  1.16it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "{'loss': 1.4777, 'learning_rate': 0.00039999798309020486, 'epoch': 0.0}         \n",
      "{'loss': 1.4847, 'learning_rate': 0.000399997942712701, 'epoch': 0.0}           \n",
      "{'loss': 1.4735, 'learning_rate': 0.0003999979019350265, 'epoch': 0.0}          \n",
      "{'loss': 1.474, 'learning_rate': 0.0003999978607571813, 'epoch': 0.0}           \n",
      "{'loss': 1.4678, 'learning_rate': 0.0003999978191791656, 'epoch': 0.0}          \n",
      "{'loss': 1.4668, 'learning_rate': 0.0003999977772009793, 'epoch': 0.0}          \n",
      "{'loss': 1.4687, 'learning_rate': 0.0003999977348226228, 'epoch': 0.0}          \n",
      "{'loss': 1.464, 'learning_rate': 0.0003999976920440959, 'epoch': 0.0}           \n",
      "{'loss': 1.465, 'learning_rate': 0.0003999976488653988, 'epoch': 0.0}           \n",
      "{'loss': 1.4704, 'learning_rate': 0.00039999760528653153, 'epoch': 0.0}         \n",
      "{'loss': 1.4742, 'learning_rate': 0.00039999756130749427, 'epoch': 0.0}         \n",
      "{'loss': 1.4628, 'learning_rate': 0.00039999751692828704, 'epoch': 0.0}         \n",
      "{'loss': 1.4606, 'learning_rate': 0.0003999974721489099, 'epoch': 0.0}          \n",
      "{'loss': 1.4655, 'learning_rate': 0.000399997426969363, 'epoch': 0.0}           \n",
      "{'loss': 1.4621, 'learning_rate': 0.00039999738138964645, 'epoch': 0.0}         \n",
      "{'loss': 1.461, 'learning_rate': 0.00039999733540976027, 'epoch': 0.0}          \n",
      "{'loss': 1.4595, 'learning_rate': 0.0003999972890297046, 'epoch': 0.0}          \n",
      "{'loss': 1.46, 'learning_rate': 0.00039999724224947956, 'epoch': 0.0}           \n",
      "{'loss': 1.4448, 'learning_rate': 0.0003999971950690851, 'epoch': 0.0}          \n",
      "{'loss': 1.4482, 'learning_rate': 0.00039999714748852153, 'epoch': 0.0}         \n",
      "{'loss': 1.4469, 'learning_rate': 0.0003999970995077887, 'epoch': 0.0}          \n",
      "{'loss': 1.4446, 'learning_rate': 0.00039999705112688693, 'epoch': 0.0}         \n",
      "{'loss': 1.4377, 'learning_rate': 0.0003999970023458163, 'epoch': 0.0}          \n",
      "{'loss': 1.4478, 'learning_rate': 0.0003999969531645767, 'epoch': 0.0}          \n",
      "{'loss': 1.4485, 'learning_rate': 0.00039999690358316837, 'epoch': 0.0}         \n",
      "{'loss': 1.4448, 'learning_rate': 0.00039999685360159144, 'epoch': 0.0}         \n",
      "{'loss': 1.4432, 'learning_rate': 0.000399996803219846, 'epoch': 0.0}           \n",
      "{'loss': 1.4415, 'learning_rate': 0.00039999675243793207, 'epoch': 0.0}         \n",
      "{'loss': 1.4373, 'learning_rate': 0.00039999670125584984, 'epoch': 0.0}         \n",
      "{'loss': 1.4373, 'learning_rate': 0.0003999966496735993, 'epoch': 0.0}          \n",
      "{'loss': 1.4391, 'learning_rate': 0.00039999659769118074, 'epoch': 0.0}         \n",
      "{'loss': 1.4331, 'learning_rate': 0.000399996545308594, 'epoch': 0.0}           \n",
      "{'loss': 1.432, 'learning_rate': 0.00039999649252583946, 'epoch': 0.0}          \n",
      "{'loss': 1.4285, 'learning_rate': 0.00039999643934291704, 'epoch': 0.0}         \n",
      "{'loss': 1.4303, 'learning_rate': 0.00039999638575982703, 'epoch': 0.0}         \n",
      "{'loss': 1.4289, 'learning_rate': 0.00039999633177656934, 'epoch': 0.0}         \n",
      "{'loss': 1.4241, 'learning_rate': 0.0003999962773931441, 'epoch': 0.0}          \n",
      "{'loss': 1.4273, 'learning_rate': 0.0003999962226095515, 'epoch': 0.0}          \n",
      "{'loss': 1.4294, 'learning_rate': 0.0003999961674257916, 'epoch': 0.0}          \n",
      "{'loss': 1.4251, 'learning_rate': 0.0003999961118418646, 'epoch': 0.0}          \n",
      "{'loss': 1.4144, 'learning_rate': 0.0003999960558577705, 'epoch': 0.0}          \n",
      "{'loss': 1.4207, 'learning_rate': 0.0003999959994735095, 'epoch': 0.0}          \n",
      "{'loss': 1.4218, 'learning_rate': 0.00039999594268908163, 'epoch': 0.0}         \n",
      "{'loss': 1.4224, 'learning_rate': 0.00039999588550448706, 'epoch': 0.0}         \n",
      "{'loss': 1.4216, 'learning_rate': 0.0003999958279197259, 'epoch': 0.0}          \n",
      "{'loss': 1.4133, 'learning_rate': 0.0003999957699347982, 'epoch': 0.0}          \n",
      "{'loss': 1.4182, 'learning_rate': 0.0003999957115497042, 'epoch': 0.0}          \n",
      "{'loss': 1.4115, 'learning_rate': 0.00039999565276444384, 'epoch': 0.0}         \n",
      "{'loss': 1.4236, 'learning_rate': 0.0003999955935790174, 'epoch': 0.0}          \n",
      "{'loss': 1.4329, 'learning_rate': 0.000399995533993425, 'epoch': 0.0}           \n",
      "{'loss': 1.4159, 'learning_rate': 0.00039999547400766666, 'epoch': 0.0}         \n",
      "{'loss': 1.4089, 'learning_rate': 0.0003999954136217425, 'epoch': 0.0}          \n",
      "{'loss': 1.399, 'learning_rate': 0.0003999953528356527, 'epoch': 0.0}           \n",
      "{'loss': 1.4051, 'learning_rate': 0.0003999952916493974, 'epoch': 0.0}          \n",
      "{'loss': 1.4075, 'learning_rate': 0.00039999523006297664, 'epoch': 0.0}         \n",
      "{'loss': 1.4058, 'learning_rate': 0.00039999516807639064, 'epoch': 0.0}         \n",
      "{'loss': 1.4103, 'learning_rate': 0.00039999510568963944, 'epoch': 0.0}         \n",
      "{'loss': 1.4043, 'learning_rate': 0.0003999950429027232, 'epoch': 0.0}          \n",
      "{'loss': 1.4014, 'learning_rate': 0.00039999497971564203, 'epoch': 0.0}         \n",
      "{'loss': 1.4107, 'learning_rate': 0.00039999491612839605, 'epoch': 0.0}         \n",
      "{'loss': 1.3995, 'learning_rate': 0.00039999485214098547, 'epoch': 0.0}         \n",
      "{'loss': 1.3957, 'learning_rate': 0.0003999947877534103, 'epoch': 0.0}          \n",
      "{'loss': 1.3928, 'learning_rate': 0.00039999472296567076, 'epoch': 0.0}         \n",
      "{'loss': 1.392, 'learning_rate': 0.0003999946577777669, 'epoch': 0.0}           \n",
      "{'loss': 1.3913, 'learning_rate': 0.00039999459218969895, 'epoch': 0.0}         \n",
      "{'loss': 1.3872, 'learning_rate': 0.000399994526201467, 'epoch': 0.0}           \n",
      "{'loss': 1.3889, 'learning_rate': 0.00039999445981307106, 'epoch': 0.0}         \n",
      "{'loss': 1.3908, 'learning_rate': 0.00039999439302451146, 'epoch': 0.0}         \n",
      "{'loss': 1.3743, 'learning_rate': 0.0003999943258357882, 'epoch': 0.0}          \n",
      "{'loss': 1.3781, 'learning_rate': 0.0003999942582469015, 'epoch': 0.0}          \n",
      "{'loss': 1.3753, 'learning_rate': 0.0003999941902578514, 'epoch': 0.0}          \n",
      "{'loss': 1.3758, 'learning_rate': 0.0003999941218686381, 'epoch': 0.0}          \n",
      "{'loss': 1.3792, 'learning_rate': 0.0003999940530792618, 'epoch': 0.0}          \n",
      "{'loss': 1.3744, 'learning_rate': 0.0003999939838897225, 'epoch': 0.0}          \n",
      "{'loss': 1.3793, 'learning_rate': 0.00039999391430002037, 'epoch': 0.0}         \n",
      "{'loss': 1.3747, 'learning_rate': 0.0003999938443101556, 'epoch': 0.0}          \n",
      "{'loss': 1.3665, 'learning_rate': 0.00039999377392012836, 'epoch': 0.0}         \n",
      "{'loss': 1.3726, 'learning_rate': 0.00039999370312993873, 'epoch': 0.0}         \n",
      "{'loss': 1.3788, 'learning_rate': 0.00039999363193958683, 'epoch': 0.0}         \n",
      "{'loss': 1.3819, 'learning_rate': 0.0003999935603490728, 'epoch': 0.0}          \n",
      "{'loss': 1.3782, 'learning_rate': 0.0003999934883583969, 'epoch': 0.0}          \n",
      "{'loss': 1.3709, 'learning_rate': 0.0003999934159675592, 'epoch': 0.0}          \n",
      "{'loss': 1.367, 'learning_rate': 0.00039999334317655983, 'epoch': 0.0}          \n",
      "{'loss': 1.3623, 'learning_rate': 0.00039999326998539886, 'epoch': 0.0}         \n",
      "{'loss': 1.3659, 'learning_rate': 0.0003999931963940766, 'epoch': 0.0}          \n",
      "{'loss': 1.3673, 'learning_rate': 0.0003999931224025931, 'epoch': 0.0}          \n",
      "{'loss': 1.3695, 'learning_rate': 0.00039999304801094853, 'epoch': 0.0}         \n",
      "{'loss': 1.3612, 'learning_rate': 0.000399992973219143, 'epoch': 0.0}           \n",
      "{'loss': 1.372, 'learning_rate': 0.00039999289802717677, 'epoch': 0.0}          \n",
      "{'loss': 1.3582, 'learning_rate': 0.0003999928224350498, 'epoch': 0.0}          \n",
      "{'loss': 1.3613, 'learning_rate': 0.0003999927464427625, 'epoch': 0.0}          \n",
      "{'loss': 1.3532, 'learning_rate': 0.00039999267005031477, 'epoch': 0.0}         \n",
      "{'loss': 1.351, 'learning_rate': 0.0003999925932577069, 'epoch': 0.0}           \n",
      "{'loss': 1.3486, 'learning_rate': 0.000399992516064939, 'epoch': 0.0}           \n",
      "{'loss': 1.3484, 'learning_rate': 0.0003999924384720113, 'epoch': 0.0}          \n",
      "{'loss': 1.3539, 'learning_rate': 0.00039999236047892384, 'epoch': 0.0}         \n",
      "{'loss': 1.3493, 'learning_rate': 0.0003999922820856768, 'epoch': 0.0}          \n",
      "{'loss': 1.3472, 'learning_rate': 0.0003999922032922704, 'epoch': 0.0}          \n",
      "{'loss': 1.3478, 'learning_rate': 0.0003999921240987048, 'epoch': 0.0}          \n",
      "{'loss': 1.3599, 'learning_rate': 0.00039999204450498005, 'epoch': 0.0}         \n",
      "  0%|                                  | 1000/351164 [14:37<78:32:52,  1.24it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "{'loss': 1.3532, 'learning_rate': 0.0003999919645110964, 'epoch': 0.0}          \n",
      "{'loss': 1.3465, 'learning_rate': 0.0003999918841170541, 'epoch': 0.0}          \n",
      "{'loss': 1.3429, 'learning_rate': 0.0003999918033228531, 'epoch': 0.0}          \n",
      "{'loss': 1.3346, 'learning_rate': 0.00039999172212849365, 'epoch': 0.0}         \n",
      "{'loss': 1.3391, 'learning_rate': 0.000399991640533976, 'epoch': 0.0}           \n",
      "{'loss': 1.334, 'learning_rate': 0.0003999915585393002, 'epoch': 0.0}           \n",
      "{'loss': 1.3313, 'learning_rate': 0.00039999147614446645, 'epoch': 0.0}         \n",
      "{'loss': 1.3279, 'learning_rate': 0.00039999139334947494, 'epoch': 0.0}         \n",
      "{'loss': 1.3292, 'learning_rate': 0.00039999131015432576, 'epoch': 0.0}         \n",
      "{'loss': 1.3263, 'learning_rate': 0.0003999912265590192, 'epoch': 0.0}          \n",
      "{'loss': 1.3271, 'learning_rate': 0.00039999114256355535, 'epoch': 0.0}         \n",
      "{'loss': 1.3309, 'learning_rate': 0.0003999910581679344, 'epoch': 0.0}          \n",
      "{'loss': 1.3307, 'learning_rate': 0.00039999097337215645, 'epoch': 0.0}         \n",
      "{'loss': 1.332, 'learning_rate': 0.0003999908881762218, 'epoch': 0.0}           \n",
      "{'loss': 1.3331, 'learning_rate': 0.00039999080258013047, 'epoch': 0.0}         \n",
      "{'loss': 1.3308, 'learning_rate': 0.0003999907165838827, 'epoch': 0.0}          \n",
      "{'loss': 1.3313, 'learning_rate': 0.0003999906301874787, 'epoch': 0.0}          \n",
      "{'loss': 1.3251, 'learning_rate': 0.00039999054339091866, 'epoch': 0.0}         \n",
      "{'loss': 1.3234, 'learning_rate': 0.0003999904561942026, 'epoch': 0.0}          \n",
      "{'loss': 1.3233, 'learning_rate': 0.0003999903685973309, 'epoch': 0.0}          \n",
      "{'loss': 1.3165, 'learning_rate': 0.00039999028060030365, 'epoch': 0.0}         \n",
      "{'loss': 1.3332, 'learning_rate': 0.0003999901922031209, 'epoch': 0.0}          \n",
      "{'loss': 1.3388, 'learning_rate': 0.00039999010340578304, 'epoch': 0.0}         \n",
      "{'loss': 1.3238, 'learning_rate': 0.00039999001420829017, 'epoch': 0.0}         \n",
      "{'loss': 1.3165, 'learning_rate': 0.00039998992461064234, 'epoch': 0.0}         \n",
      "{'loss': 1.3142, 'learning_rate': 0.0003999898346128399, 'epoch': 0.0}          \n",
      "{'loss': 1.3105, 'learning_rate': 0.0003999897442148829, 'epoch': 0.0}          \n",
      "{'loss': 1.3143, 'learning_rate': 0.0003999896534167716, 'epoch': 0.0}          \n",
      "{'loss': 1.3091, 'learning_rate': 0.00039998956221850624, 'epoch': 0.0}         \n",
      "{'loss': 1.3072, 'learning_rate': 0.0003999894706200869, 'epoch': 0.0}          \n",
      "{'loss': 1.3069, 'learning_rate': 0.00039998937862151376, 'epoch': 0.0}         \n",
      "{'loss': 1.3096, 'learning_rate': 0.00039998928622278707, 'epoch': 0.0}         \n",
      "{'loss': 1.307, 'learning_rate': 0.00039998919342390695, 'epoch': 0.0}          \n",
      "{'loss': 1.3057, 'learning_rate': 0.00039998910022487366, 'epoch': 0.0}         \n",
      "{'loss': 1.3028, 'learning_rate': 0.00039998900662568726, 'epoch': 0.0}         \n",
      "{'loss': 1.3029, 'learning_rate': 0.0003999889126263481, 'epoch': 0.0}          \n",
      "{'loss': 1.3026, 'learning_rate': 0.00039998881822685627, 'epoch': 0.0}         \n",
      "{'loss': 1.3023, 'learning_rate': 0.00039998872342721195, 'epoch': 0.0}         \n",
      "{'loss': 1.296, 'learning_rate': 0.00039998862822741534, 'epoch': 0.0}          \n",
      "{'loss': 1.3024, 'learning_rate': 0.00039998853262746676, 'epoch': 0.0}         \n",
      "{'loss': 1.2994, 'learning_rate': 0.0003999884366273662, 'epoch': 0.0}          \n",
      "{'loss': 1.3354, 'learning_rate': 0.000399988340227114, 'epoch': 0.0}           \n",
      "{'loss': 1.3126, 'learning_rate': 0.0003999882434267102, 'epoch': 0.0}          \n",
      "{'loss': 1.2987, 'learning_rate': 0.00039998814622615515, 'epoch': 0.0}         \n",
      "{'loss': 1.2979, 'learning_rate': 0.00039998804862544893, 'epoch': 0.0}         \n",
      "{'loss': 1.2931, 'learning_rate': 0.0003999879506245919, 'epoch': 0.0}          \n",
      "{'loss': 1.2922, 'learning_rate': 0.00039998785222358405, 'epoch': 0.0}         \n",
      "{'loss': 1.2907, 'learning_rate': 0.00039998775342242566, 'epoch': 0.0}         \n",
      "{'loss': 1.2855, 'learning_rate': 0.000399987654221117, 'epoch': 0.0}           \n",
      "{'loss': 1.2847, 'learning_rate': 0.0003999875546196582, 'epoch': 0.0}          \n",
      "{'loss': 1.2803, 'learning_rate': 0.0003999874546180494, 'epoch': 0.0}          \n",
      "{'loss': 1.2738, 'learning_rate': 0.00039998735421629093, 'epoch': 0.0}         \n",
      "{'loss': 1.2754, 'learning_rate': 0.00039998725341438293, 'epoch': 0.0}         \n",
      "{'loss': 1.2758, 'learning_rate': 0.00039998715221232557, 'epoch': 0.0}         \n",
      "{'loss': 1.2796, 'learning_rate': 0.0003999870506101191, 'epoch': 0.0}          \n",
      "{'loss': 1.2857, 'learning_rate': 0.0003999869486077637, 'epoch': 0.0}          \n",
      "{'loss': 1.2825, 'learning_rate': 0.0003999868462052596, 'epoch': 0.0}          \n",
      "{'loss': 1.2718, 'learning_rate': 0.0003999867434026069, 'epoch': 0.0}          \n",
      "{'loss': 1.2776, 'learning_rate': 0.000399986640199806, 'epoch': 0.0}           \n",
      "{'loss': 1.2717, 'learning_rate': 0.0003999865365968569, 'epoch': 0.0}          \n",
      "{'loss': 1.2712, 'learning_rate': 0.00039998643259375993, 'epoch': 0.0}         \n",
      "{'loss': 1.2666, 'learning_rate': 0.0003999863281905153, 'epoch': 0.0}          \n",
      "{'loss': 1.261, 'learning_rate': 0.00039998622338712316, 'epoch': 0.0}          \n",
      "{'loss': 1.2602, 'learning_rate': 0.00039998611818358376, 'epoch': 0.0}         \n",
      "{'loss': 1.2504, 'learning_rate': 0.0003999860125798973, 'epoch': 0.0}          \n",
      "{'loss': 1.2506, 'learning_rate': 0.00039998590657606406, 'epoch': 0.0}         \n",
      "{'loss': 1.2575, 'learning_rate': 0.00039998580017208414, 'epoch': 0.0}         \n",
      "{'loss': 1.2559, 'learning_rate': 0.0003999856933679577, 'epoch': 0.0}          \n",
      "{'loss': 1.2493, 'learning_rate': 0.00039998558616368514, 'epoch': 0.0}         \n",
      "{'loss': 1.2406, 'learning_rate': 0.0003999854785592666, 'epoch': 0.0}          \n",
      "{'loss': 1.2563, 'learning_rate': 0.00039998537055470227, 'epoch': 0.0}         \n",
      "{'loss': 1.2524, 'learning_rate': 0.00039998526214999236, 'epoch': 0.0}         \n",
      "{'loss': 1.2298, 'learning_rate': 0.0003999851533451371, 'epoch': 0.0}          \n",
      "{'loss': 1.2347, 'learning_rate': 0.00039998504414013664, 'epoch': 0.0}         \n",
      "{'loss': 1.2319, 'learning_rate': 0.00039998493453499137, 'epoch': 0.0}         \n",
      "{'loss': 1.2246, 'learning_rate': 0.0003999848245297014, 'epoch': 0.0}          \n",
      "{'loss': 1.2224, 'learning_rate': 0.0003999847141242669, 'epoch': 0.0}          \n",
      "{'loss': 1.2293, 'learning_rate': 0.00039998460331868823, 'epoch': 0.0}         \n",
      "{'loss': 1.22, 'learning_rate': 0.0003999844921129655, 'epoch': 0.0}            \n",
      "{'loss': 1.2245, 'learning_rate': 0.000399984380507099, 'epoch': 0.0}           \n",
      "{'loss': 1.2167, 'learning_rate': 0.0003999842685010888, 'epoch': 0.0}          \n",
      "{'loss': 1.2205, 'learning_rate': 0.00039998415609493536, 'epoch': 0.0}         \n",
      "{'loss': 1.2104, 'learning_rate': 0.0003999840432886387, 'epoch': 0.0}          \n",
      "{'loss': 1.2032, 'learning_rate': 0.0003999839300821992, 'epoch': 0.0}          \n",
      "{'loss': 1.2052, 'learning_rate': 0.00039998381647561696, 'epoch': 0.0}         \n",
      "{'loss': 1.2044, 'learning_rate': 0.0003999837024688923, 'epoch': 0.0}          \n",
      "{'loss': 1.2026, 'learning_rate': 0.0003999835880620254, 'epoch': 0.0}          \n",
      "{'loss': 1.1962, 'learning_rate': 0.0003999834732550165, 'epoch': 0.0}          \n",
      "{'loss': 1.1939, 'learning_rate': 0.0003999833580478659, 'epoch': 0.0}          \n",
      "{'loss': 1.1941, 'learning_rate': 0.0003999832424405737, 'epoch': 0.0}          \n",
      "{'loss': 1.1917, 'learning_rate': 0.0003999831264331402, 'epoch': 0.0}          \n",
      "{'loss': 1.1908, 'learning_rate': 0.00039998301002556563, 'epoch': 0.0}         \n",
      "{'loss': 1.1794, 'learning_rate': 0.0003999828932178502, 'epoch': 0.0}          \n",
      "{'loss': 1.1775, 'learning_rate': 0.0003999827760099942, 'epoch': 0.0}          \n",
      "{'loss': 1.1669, 'learning_rate': 0.0003999826584019978, 'epoch': 0.0}          \n",
      "{'loss': 1.1697, 'learning_rate': 0.0003999825403938613, 'epoch': 0.0}          \n",
      "{'loss': 1.1673, 'learning_rate': 0.0003999824219855849, 'epoch': 0.0}          \n",
      "{'loss': 1.1612, 'learning_rate': 0.00039998230317716876, 'epoch': 0.0}         \n",
      "{'loss': 1.169, 'learning_rate': 0.00039998218396861324, 'epoch': 0.0}          \n",
      "{'loss': 1.1702, 'learning_rate': 0.00039998206435991855, 'epoch': 0.0}         \n",
      "  0%|▏                                 | 1500/351164 [21:51<83:19:03,  1.17it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "{'loss': 1.1739, 'learning_rate': 0.00039998194435108484, 'epoch': 0.0}         \n",
      "{'loss': 1.1655, 'learning_rate': 0.0003999818239421125, 'epoch': 0.0}          \n",
      "{'loss': 1.1548, 'learning_rate': 0.0003999817031330017, 'epoch': 0.0}          \n",
      "{'loss': 1.1498, 'learning_rate': 0.0003999815819237526, 'epoch': 0.0}          \n",
      "{'loss': 1.1514, 'learning_rate': 0.0003999814603143656, 'epoch': 0.0}          \n",
      "{'loss': 1.147, 'learning_rate': 0.0003999813383048408, 'epoch': 0.0}           \n",
      "{'loss': 1.1358, 'learning_rate': 0.0003999812158951785, 'epoch': 0.0}          \n",
      "{'loss': 1.14, 'learning_rate': 0.00039998109308537897, 'epoch': 0.0}           \n",
      "{'loss': 1.1431, 'learning_rate': 0.0003999809698754424, 'epoch': 0.0}          \n",
      "{'loss': 1.1345, 'learning_rate': 0.0003999808462653691, 'epoch': 0.0}          \n",
      "{'loss': 1.1355, 'learning_rate': 0.0003999807222551594, 'epoch': 0.0}          \n",
      "{'loss': 1.14, 'learning_rate': 0.0003999805978448133, 'epoch': 0.0}            \n",
      "{'loss': 1.1448, 'learning_rate': 0.00039998047303433124, 'epoch': 0.0}         \n",
      "{'loss': 1.1398, 'learning_rate': 0.0003999803478237134, 'epoch': 0.0}          \n",
      "{'loss': 1.1412, 'learning_rate': 0.00039998022221296003, 'epoch': 0.0}         \n",
      "{'loss': 1.1412, 'learning_rate': 0.0003999800962020714, 'epoch': 0.0}          \n",
      "{'loss': 1.1344, 'learning_rate': 0.0003999799697910478, 'epoch': 0.0}          \n",
      "{'loss': 1.1203, 'learning_rate': 0.00039997984297988936, 'epoch': 0.0}         \n",
      "{'loss': 1.1138, 'learning_rate': 0.0003999797157685965, 'epoch': 0.0}          \n",
      "{'loss': 1.1119, 'learning_rate': 0.00039997958815716936, 'epoch': 0.0}         \n",
      "{'loss': 1.1131, 'learning_rate': 0.0003999794601456082, 'epoch': 0.0}          \n",
      "{'loss': 1.1113, 'learning_rate': 0.00039997933173391336, 'epoch': 0.0}         \n",
      "{'loss': 1.1112, 'learning_rate': 0.00039997920292208497, 'epoch': 0.0}         \n",
      "{'loss': 1.1057, 'learning_rate': 0.0003999790737101234, 'epoch': 0.0}          \n",
      "{'loss': 1.1041, 'learning_rate': 0.00039997894409802886, 'epoch': 0.0}         \n",
      "{'loss': 1.1098, 'learning_rate': 0.0003999788140858016, 'epoch': 0.0}          \n",
      "{'loss': 1.1036, 'learning_rate': 0.0003999786836734419, 'epoch': 0.0}          \n",
      "{'loss': 1.0955, 'learning_rate': 0.00039997855286095005, 'epoch': 0.0}         \n",
      "{'loss': 1.0911, 'learning_rate': 0.0003999784216483263, 'epoch': 0.0}          \n",
      "{'loss': 1.0913, 'learning_rate': 0.00039997829003557075, 'epoch': 0.0}         \n",
      "{'loss': 1.0952, 'learning_rate': 0.0003999781580226839, 'epoch': 0.0}          \n",
      "{'loss': 1.082, 'learning_rate': 0.0003999780256096659, 'epoch': 0.0}           \n",
      "{'loss': 1.0797, 'learning_rate': 0.0003999778927965171, 'epoch': 0.0}          \n",
      "{'loss': 1.0935, 'learning_rate': 0.00039997775958323765, 'epoch': 0.0}         \n",
      "{'loss': 1.093, 'learning_rate': 0.0003999776259698278, 'epoch': 0.0}           \n",
      "{'loss': 1.0774, 'learning_rate': 0.00039997749195628797, 'epoch': 0.0}         \n",
      "{'loss': 1.0763, 'learning_rate': 0.00039997735754261827, 'epoch': 0.0}         \n",
      "{'loss': 1.07, 'learning_rate': 0.00039997722272881915, 'epoch': 0.0}           \n",
      "{'loss': 1.067, 'learning_rate': 0.0003999770875148906, 'epoch': 0.0}           \n",
      "{'loss': 1.063, 'learning_rate': 0.00039997695190083324, 'epoch': 0.0}          \n",
      "{'loss': 1.0838, 'learning_rate': 0.0003999768158866471, 'epoch': 0.0}          \n",
      "{'loss': 1.1006, 'learning_rate': 0.0003999766794723324, 'epoch': 0.0}          \n",
      "{'loss': 1.0883, 'learning_rate': 0.0003999765426578897, 'epoch': 0.0}          \n",
      "{'loss': 1.081, 'learning_rate': 0.00039997640544331897, 'epoch': 0.0}          \n",
      "{'loss': 1.0732, 'learning_rate': 0.00039997626782862063, 'epoch': 0.0}         \n",
      "{'loss': 1.0597, 'learning_rate': 0.000399976129813795, 'epoch': 0.0}           \n",
      "{'loss': 1.0625, 'learning_rate': 0.0003999759913988423, 'epoch': 0.0}          \n",
      "{'loss': 1.0617, 'learning_rate': 0.0003999758525837627, 'epoch': 0.0}          \n",
      "{'loss': 1.06, 'learning_rate': 0.0003999757133685567, 'epoch': 0.0}            \n",
      "{'loss': 1.0652, 'learning_rate': 0.0003999755737532244, 'epoch': 0.0}          \n",
      "{'loss': 1.052, 'learning_rate': 0.00039997543373776614, 'epoch': 0.0}          \n",
      "{'loss': 1.0541, 'learning_rate': 0.0003999752933221822, 'epoch': 0.01}         \n",
      "{'loss': 1.0428, 'learning_rate': 0.00039997515250647284, 'epoch': 0.01}        \n",
      "{'loss': 1.0477, 'learning_rate': 0.00039997501129063846, 'epoch': 0.01}        \n",
      "{'loss': 1.0439, 'learning_rate': 0.00039997486967467916, 'epoch': 0.01}        \n",
      "{'loss': 1.0392, 'learning_rate': 0.00039997472765859526, 'epoch': 0.01}        \n",
      "{'loss': 1.0413, 'learning_rate': 0.0003999745852423872, 'epoch': 0.01}         \n",
      "{'loss': 1.0451, 'learning_rate': 0.0003999744424260551, 'epoch': 0.01}         \n",
      "{'loss': 1.0476, 'learning_rate': 0.0003999742992095993, 'epoch': 0.01}         \n",
      "{'loss': 1.0417, 'learning_rate': 0.0003999741555930201, 'epoch': 0.01}         \n",
      "{'loss': 1.0363, 'learning_rate': 0.00039997401157631775, 'epoch': 0.01}        \n",
      "{'loss': 1.0346, 'learning_rate': 0.00039997386715949257, 'epoch': 0.01}        \n",
      "{'loss': 1.044, 'learning_rate': 0.00039997372234254486, 'epoch': 0.01}         \n",
      "{'loss': 1.0356, 'learning_rate': 0.00039997357712547493, 'epoch': 0.01}        \n",
      "{'loss': 1.0313, 'learning_rate': 0.00039997343150828296, 'epoch': 0.01}        \n",
      "{'loss': 1.0265, 'learning_rate': 0.0003999732854909694, 'epoch': 0.01}         \n",
      "{'loss': 1.0334, 'learning_rate': 0.00039997313907353435, 'epoch': 0.01}        \n",
      "{'loss': 1.022, 'learning_rate': 0.0003999729922559783, 'epoch': 0.01}          \n",
      "{'loss': 1.0216, 'learning_rate': 0.0003999728450383014, 'epoch': 0.01}         \n",
      "{'loss': 1.0167, 'learning_rate': 0.000399972697420504, 'epoch': 0.01}          \n",
      "{'loss': 1.0257, 'learning_rate': 0.0003999725494025865, 'epoch': 0.01}         \n",
      "{'loss': 1.0105, 'learning_rate': 0.00039997240098454896, 'epoch': 0.01}        \n",
      "{'loss': 1.0225, 'learning_rate': 0.00039997225216639184, 'epoch': 0.01}        \n",
      "{'loss': 1.0174, 'learning_rate': 0.0003999721029481154, 'epoch': 0.01}         \n",
      "{'loss': 1.0348, 'learning_rate': 0.0003999719533297199, 'epoch': 0.01}         \n",
      "{'loss': 1.0403, 'learning_rate': 0.0003999718033112058, 'epoch': 0.01}         \n",
      "{'loss': 1.0281, 'learning_rate': 0.0003999716528925732, 'epoch': 0.01}         \n",
      "{'loss': 1.0144, 'learning_rate': 0.0003999715020738225, 'epoch': 0.01}         \n",
      "{'loss': 1.0109, 'learning_rate': 0.000399971350854954, 'epoch': 0.01}          \n",
      "{'loss': 1.0149, 'learning_rate': 0.00039997119923596794, 'epoch': 0.01}        \n",
      "{'loss': 1.0073, 'learning_rate': 0.0003999710472168648, 'epoch': 0.01}         \n",
      "{'loss': 1.0056, 'learning_rate': 0.0003999708947976446, 'epoch': 0.01}         \n",
      "{'loss': 1.0064, 'learning_rate': 0.0003999707419783079, 'epoch': 0.01}         \n",
      "{'loss': 1.0081, 'learning_rate': 0.0003999705887588548, 'epoch': 0.01}         \n",
      "{'loss': 1.005, 'learning_rate': 0.00039997043513928586, 'epoch': 0.01}         \n",
      "{'loss': 1.001, 'learning_rate': 0.0003999702811196011, 'epoch': 0.01}          \n",
      "{'loss': 1.0034, 'learning_rate': 0.0003999701266998011, 'epoch': 0.01}         \n",
      "{'loss': 1.0007, 'learning_rate': 0.00039996997187988594, 'epoch': 0.01}        \n",
      "{'loss': 0.9965, 'learning_rate': 0.000399969816659856, 'epoch': 0.01}          \n",
      "{'loss': 0.9968, 'learning_rate': 0.0003999696610397117, 'epoch': 0.01}         \n",
      "{'loss': 0.9963, 'learning_rate': 0.00039996950501945325, 'epoch': 0.01}        \n",
      "{'loss': 0.9895, 'learning_rate': 0.00039996934859908104, 'epoch': 0.01}        \n",
      "{'loss': 0.9929, 'learning_rate': 0.0003999691917785952, 'epoch': 0.01}         \n",
      "{'loss': 0.9945, 'learning_rate': 0.00039996903455799624, 'epoch': 0.01}        \n",
      "{'loss': 0.9894, 'learning_rate': 0.0003999688769372844, 'epoch': 0.01}         \n",
      "{'loss': 1.0004, 'learning_rate': 0.00039996871891645995, 'epoch': 0.01}        \n",
      "{'loss': 0.9924, 'learning_rate': 0.0003999685604955233, 'epoch': 0.01}         \n",
      "{'loss': 0.997, 'learning_rate': 0.0003999684016744747, 'epoch': 0.01}          \n",
      "{'loss': 0.9952, 'learning_rate': 0.0003999682424533145, 'epoch': 0.01}         \n",
      "{'loss': 0.9929, 'learning_rate': 0.000399968082832043, 'epoch': 0.01}          \n",
      "  1%|▏                                 | 2000/351164 [29:05<78:59:29,  1.23it/s]/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1290: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<01:07,  2.07it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:28,  1.56it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:35,  1.44it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:48,  1.25it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:48,  1.24it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:05<01:54,  1.17it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:06<01:57,  1.13it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:07<02:01,  1.09it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:08<01:58,  1.10it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:09<01:56,  1.12it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:55,  1.12it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:10<01:58,  1.08it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:11<01:56,  1.09it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:12<01:56,  1.08it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:13<01:58,  1.06it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:14<01:54,  1.09it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:15<01:53,  1.08it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:16<01:53,  1.07it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:17<01:49,  1.10it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:18<01:51,  1.08it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:19<01:46,  1.12it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:20<01:43,  1.14it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:20<01:41,  1.15it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:21<01:38,  1.18it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:22<01:37,  1.18it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:23<01:39,  1.14it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:24<01:41,  1.12it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:25<01:37,  1.14it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:26<01:36,  1.15it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:26<01:32,  1.18it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:27<01:31,  1.19it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:28<01:32,  1.16it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:29<01:33,  1.15it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:30<01:33,  1.14it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:31<01:30,  1.16it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:32<01:31,  1.14it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:33<01:29,  1.15it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:33<01:30,  1.13it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:34<01:28,  1.14it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:35<01:28,  1.13it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:36<01:26,  1.15it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:37<01:25,  1.15it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:38<01:22,  1.17it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:39<01:21,  1.18it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:39<01:20,  1.18it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:40<01:19,  1.19it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:41<01:16,  1.22it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:42<01:15,  1.21it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:43<01:15,  1.20it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:43<01:13,  1.23it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:44<01:14,  1.20it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:45<01:13,  1.20it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:46<01:11,  1.22it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:47<01:11,  1.21it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:48<01:12,  1.16it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:49<01:12,  1.16it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:50<01:13,  1.14it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:50<01:10,  1.17it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:51<01:09,  1.17it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:52<01:07,  1.19it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:53<01:06,  1.18it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:54<01:08,  1.14it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:55<01:06,  1.15it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:56<01:06,  1.15it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:56<01:06,  1.13it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:57<01:06,  1.11it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:58<01:06,  1.09it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:59<01:11,  1.01it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [01:00<01:08,  1.04it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [01:01<01:07,  1.04it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:02<01:04,  1.07it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:03<01:01,  1.10it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:04<00:58,  1.15it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:05<00:57,  1.14it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:06<00:56,  1.16it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:06<00:55,  1.15it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:07<00:53,  1.18it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:08<00:55,  1.12it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:09<00:53,  1.14it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:10<00:52,  1.14it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:11<00:54,  1.08it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:12<00:51,  1.12it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:13<00:52,  1.09it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:14<00:50,  1.12it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:15<00:49,  1.11it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:15<00:48,  1.12it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:16<00:45,  1.15it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:17<00:44,  1.17it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:18<00:42,  1.19it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:19<00:41,  1.21it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:20<00:41,  1.19it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:20<00:40,  1.19it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:21<00:38,  1.22it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:22<00:39,  1.15it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:23<00:39,  1.15it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:24<00:37,  1.17it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:25<00:36,  1.19it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:25<00:35,  1.18it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:26<00:34,  1.19it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:27<00:33,  1.19it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:28<00:33,  1.18it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:29<00:31,  1.20it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:30<00:30,  1.21it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:30<00:29,  1.22it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:31<00:30,  1.16it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:32<00:29,  1.15it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:33<00:28,  1.15it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:34<00:27,  1.16it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:35<00:26,  1.18it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:36<00:25,  1.18it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:36<00:24,  1.19it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:37<00:23,  1.21it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:38<00:22,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:39<00:21,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:40<00:21,  1.17it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:41<00:20,  1.15it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:42<00:19,  1.16it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:42<00:19,  1.15it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:43<00:17,  1.17it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:44<00:16,  1.20it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:45<00:16,  1.16it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:46<00:15,  1.16it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:47<00:14,  1.19it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:48<00:13,  1.18it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:48<00:13,  1.14it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:49<00:12,  1.14it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:50<00:11,  1.11it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:51<00:10,  1.12it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:52<00:09,  1.14it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:53<00:08,  1.13it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:54<00:07,  1.15it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:55<00:06,  1.17it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:56<00:06,  1.09it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:57<00:05,  1.10it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:57<00:04,  1.13it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:58<00:03,  1.13it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:59<00:02,  1.10it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [02:00<00:01,  1.14it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [02:01<00:00,  1.17it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [02:02<00:00,  1.08s/it]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1cc2c(cccc2o1)C(=O)OCc3ccccc3)c4ccco4\n",
      "\n",
      "{'eval_loss': 0.9702655076980591, 'eval_cer': 0.19027805509574447, 'eval_runtime': 132.6338, 'eval_samples_per_second': 67.788, 'eval_steps_per_second': 1.063, 'epoch': 0.01}\n",
      "\n",
      "  1%|▏                                 | 2000/351164 [31:18<78:59:29,  1.23it/s]\u001b[A\n",
      "                                                                                \u001b[ACheckpoint destination directory models/checkpoint-2000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.9886, 'learning_rate': 0.00039996792281066056, 'epoch': 0.01}        \n",
      "{'loss': 0.984, 'learning_rate': 0.0003999677623891674, 'epoch': 0.01}          \n",
      "{'loss': 0.9806, 'learning_rate': 0.000399967601567564, 'epoch': 0.01}          \n",
      "{'loss': 0.9812, 'learning_rate': 0.00039996744034585054, 'epoch': 0.01}        \n",
      "{'loss': 0.9791, 'learning_rate': 0.00039996727872402735, 'epoch': 0.01}        \n",
      "{'loss': 0.9877, 'learning_rate': 0.00039996711670209486, 'epoch': 0.01}        \n",
      "{'loss': 0.9783, 'learning_rate': 0.00039996695428005333, 'epoch': 0.01}        \n",
      "{'loss': 0.9842, 'learning_rate': 0.000399966791457903, 'epoch': 0.01}          \n",
      "{'loss': 0.9806, 'learning_rate': 0.00039996662823564436, 'epoch': 0.01}        \n",
      "{'loss': 0.9747, 'learning_rate': 0.00039996646461327767, 'epoch': 0.01}        \n",
      "{'loss': 0.9797, 'learning_rate': 0.0003999663005908032, 'epoch': 0.01}         \n",
      "{'loss': 0.9904, 'learning_rate': 0.0003999661361682213, 'epoch': 0.01}         \n",
      "{'loss': 0.9867, 'learning_rate': 0.0003999659713455324, 'epoch': 0.01}         \n",
      "{'loss': 0.9826, 'learning_rate': 0.00039996580612273666, 'epoch': 0.01}        \n",
      "{'loss': 0.9794, 'learning_rate': 0.0003999656404998346, 'epoch': 0.01}         \n",
      "{'loss': 0.9717, 'learning_rate': 0.0003999654744768264, 'epoch': 0.01}         \n",
      "{'loss': 0.9715, 'learning_rate': 0.00039996530805371243, 'epoch': 0.01}        \n",
      "{'loss': 0.9737, 'learning_rate': 0.0003999651412304931, 'epoch': 0.01}         \n",
      "{'loss': 0.9691, 'learning_rate': 0.0003999649740071686, 'epoch': 0.01}         \n",
      "{'loss': 0.9697, 'learning_rate': 0.0003999648063837394, 'epoch': 0.01}         \n",
      "{'loss': 0.9692, 'learning_rate': 0.0003999646383602058, 'epoch': 0.01}         \n",
      "{'loss': 0.9724, 'learning_rate': 0.00039996446993656806, 'epoch': 0.01}        \n",
      "{'loss': 0.9729, 'learning_rate': 0.0003999643011128266, 'epoch': 0.01}         \n",
      "{'loss': 0.9748, 'learning_rate': 0.0003999641318889817, 'epoch': 0.01}         \n",
      "{'loss': 0.967, 'learning_rate': 0.0003999639622650338, 'epoch': 0.01}          \n",
      "{'loss': 0.9683, 'learning_rate': 0.0003999637922409832, 'epoch': 0.01}         \n",
      "{'loss': 0.9723, 'learning_rate': 0.0003999636218168301, 'epoch': 0.01}         \n",
      "{'loss': 0.9682, 'learning_rate': 0.000399963450992575, 'epoch': 0.01}          \n",
      "{'loss': 0.964, 'learning_rate': 0.00039996327976821823, 'epoch': 0.01}         \n",
      "{'loss': 0.958, 'learning_rate': 0.0003999631081437601, 'epoch': 0.01}          \n",
      "{'loss': 0.9582, 'learning_rate': 0.00039996293611920084, 'epoch': 0.01}        \n",
      "{'loss': 0.958, 'learning_rate': 0.000399962763694541, 'epoch': 0.01}           \n",
      "{'loss': 0.9578, 'learning_rate': 0.00039996259086978085, 'epoch': 0.01}        \n",
      "{'loss': 0.9703, 'learning_rate': 0.00039996241764492067, 'epoch': 0.01}        \n",
      "{'loss': 0.9648, 'learning_rate': 0.0003999622440199609, 'epoch': 0.01}         \n",
      "{'loss': 0.9572, 'learning_rate': 0.0003999620699949017, 'epoch': 0.01}         \n",
      "{'loss': 0.9591, 'learning_rate': 0.00039996189556974375, 'epoch': 0.01}        \n",
      "{'loss': 0.962, 'learning_rate': 0.0003999617207444871, 'epoch': 0.01}          \n",
      "{'loss': 0.9555, 'learning_rate': 0.0003999615455191322, 'epoch': 0.01}         \n",
      "{'loss': 0.9512, 'learning_rate': 0.00039996136989367944, 'epoch': 0.01}        \n",
      "{'loss': 0.9573, 'learning_rate': 0.0003999611938681291, 'epoch': 0.01}         \n",
      "{'loss': 0.9522, 'learning_rate': 0.0003999610174424816, 'epoch': 0.01}         \n",
      "{'loss': 0.9512, 'learning_rate': 0.0003999608406167373, 'epoch': 0.01}         \n",
      "{'loss': 0.9536, 'learning_rate': 0.00039996066339089646, 'epoch': 0.01}        \n",
      "{'loss': 0.9529, 'learning_rate': 0.00039996048576495955, 'epoch': 0.01}        \n",
      "{'loss': 0.9515, 'learning_rate': 0.00039996030773892683, 'epoch': 0.01}        \n",
      "{'loss': 0.952, 'learning_rate': 0.0003999601293127987, 'epoch': 0.01}          \n",
      "{'loss': 0.9463, 'learning_rate': 0.0003999599504865755, 'epoch': 0.01}         \n",
      "{'loss': 0.9498, 'learning_rate': 0.00039995977126025756, 'epoch': 0.01}        \n",
      "{'loss': 0.9449, 'learning_rate': 0.00039995959163384535, 'epoch': 0.01}        \n",
      "{'loss': 0.9455, 'learning_rate': 0.0003999594116073391, 'epoch': 0.01}         \n",
      "{'loss': 0.9455, 'learning_rate': 0.00039995923118073924, 'epoch': 0.01}        \n",
      "{'loss': 0.9446, 'learning_rate': 0.00039995905035404615, 'epoch': 0.01}        \n",
      "{'loss': 0.9461, 'learning_rate': 0.00039995886912726013, 'epoch': 0.01}        \n",
      "{'loss': 0.9435, 'learning_rate': 0.0003999586875003816, 'epoch': 0.01}         \n",
      "{'loss': 0.9514, 'learning_rate': 0.00039995850547341086, 'epoch': 0.01}        \n",
      "{'loss': 0.9426, 'learning_rate': 0.00039995832304634836, 'epoch': 0.01}        \n",
      "{'loss': 0.9492, 'learning_rate': 0.00039995814021919434, 'epoch': 0.01}        \n",
      "{'loss': 0.942, 'learning_rate': 0.0003999579569919493, 'epoch': 0.01}          \n",
      "{'loss': 0.942, 'learning_rate': 0.00039995777336461355, 'epoch': 0.01}         \n",
      "{'loss': 0.9489, 'learning_rate': 0.0003999575893371874, 'epoch': 0.01}         \n",
      "{'loss': 0.9452, 'learning_rate': 0.0003999574049096714, 'epoch': 0.01}         \n",
      "{'loss': 0.9444, 'learning_rate': 0.0003999572200820656, 'epoch': 0.01}         \n",
      "{'loss': 0.9416, 'learning_rate': 0.0003999570348543707, 'epoch': 0.01}         \n",
      "{'loss': 0.9457, 'learning_rate': 0.00039995684922658687, 'epoch': 0.01}        \n",
      "{'loss': 0.934, 'learning_rate': 0.0003999566631987146, 'epoch': 0.01}          \n",
      "{'loss': 0.9339, 'learning_rate': 0.00039995647677075415, 'epoch': 0.01}        \n",
      "{'loss': 0.9418, 'learning_rate': 0.000399956289942706, 'epoch': 0.01}          \n",
      "{'loss': 0.9421, 'learning_rate': 0.00039995610271457044, 'epoch': 0.01}        \n",
      "{'loss': 0.9387, 'learning_rate': 0.0003999559150863479, 'epoch': 0.01}         \n",
      "{'loss': 0.9355, 'learning_rate': 0.0003999557270580387, 'epoch': 0.01}         \n",
      "{'loss': 0.9349, 'learning_rate': 0.00039995553862964324, 'epoch': 0.01}        \n",
      "{'loss': 0.9422, 'learning_rate': 0.00039995534980116196, 'epoch': 0.01}        \n",
      "{'loss': 0.9401, 'learning_rate': 0.00039995516057259517, 'epoch': 0.01}        \n",
      "{'loss': 0.942, 'learning_rate': 0.0003999549709439432, 'epoch': 0.01}          \n",
      "{'loss': 0.9351, 'learning_rate': 0.0003999547809152065, 'epoch': 0.01}         \n",
      "{'loss': 0.934, 'learning_rate': 0.00039995459048638554, 'epoch': 0.01}         \n",
      "{'loss': 0.9323, 'learning_rate': 0.0003999543996574805, 'epoch': 0.01}         \n",
      "{'loss': 0.9317, 'learning_rate': 0.00039995420842849197, 'epoch': 0.01}        \n",
      "{'loss': 0.9312, 'learning_rate': 0.00039995401679942014, 'epoch': 0.01}        \n",
      "{'loss': 0.9322, 'learning_rate': 0.0003999538247702655, 'epoch': 0.01}         \n",
      "{'loss': 0.9379, 'learning_rate': 0.00039995363234102843, 'epoch': 0.01}        \n",
      "{'loss': 0.9403, 'learning_rate': 0.0003999534395117093, 'epoch': 0.01}         \n",
      "{'loss': 0.9389, 'learning_rate': 0.00039995324628230855, 'epoch': 0.01}        \n",
      "{'loss': 0.9431, 'learning_rate': 0.00039995305265282636, 'epoch': 0.01}        \n",
      "{'loss': 0.9382, 'learning_rate': 0.0003999528586232634, 'epoch': 0.01}         \n",
      "{'loss': 0.9438, 'learning_rate': 0.0003999526641936199, 'epoch': 0.01}         \n",
      "{'loss': 0.9339, 'learning_rate': 0.00039995246936389624, 'epoch': 0.01}        \n",
      "{'loss': 0.9321, 'learning_rate': 0.0003999522741340929, 'epoch': 0.01}         \n",
      "{'loss': 0.9282, 'learning_rate': 0.0003999520785042102, 'epoch': 0.01}         \n",
      "{'loss': 0.9317, 'learning_rate': 0.0003999518824742485, 'epoch': 0.01}         \n",
      "{'loss': 0.936, 'learning_rate': 0.0003999516860442083, 'epoch': 0.01}          \n",
      "{'loss': 0.9291, 'learning_rate': 0.00039995148921409, 'epoch': 0.01}           \n",
      "{'loss': 0.9262, 'learning_rate': 0.0003999512919838938, 'epoch': 0.01}         \n",
      "{'loss': 0.9267, 'learning_rate': 0.0003999510943536203, 'epoch': 0.01}         \n",
      "{'loss': 0.9358, 'learning_rate': 0.0003999508963232698, 'epoch': 0.01}         \n",
      "{'loss': 0.9298, 'learning_rate': 0.0003999506978928427, 'epoch': 0.01}         \n",
      "{'loss': 0.9221, 'learning_rate': 0.0003999504990623394, 'epoch': 0.01}         \n",
      "{'loss': 0.9224, 'learning_rate': 0.0003999502998317604, 'epoch': 0.01}         \n",
      "{'loss': 0.9263, 'learning_rate': 0.00039995010020110587, 'epoch': 0.01}        \n",
      "  1%|▏                                 | 2500/351164 [38:24<80:06:14,  1.21it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.9174, 'learning_rate': 0.0003999499001703764, 'epoch': 0.01}         \n",
      "{'loss': 0.9269, 'learning_rate': 0.00039994969973957236, 'epoch': 0.01}        \n",
      "{'loss': 0.9264, 'learning_rate': 0.0003999494989086941, 'epoch': 0.01}         \n",
      "{'loss': 0.9217, 'learning_rate': 0.0003999492976777421, 'epoch': 0.01}         \n",
      "{'loss': 0.9195, 'learning_rate': 0.0003999490960467167, 'epoch': 0.01}         \n",
      "{'loss': 0.9171, 'learning_rate': 0.0003999488940156183, 'epoch': 0.01}         \n",
      "{'loss': 0.9212, 'learning_rate': 0.0003999486915844473, 'epoch': 0.01}         \n",
      "{'loss': 0.9158, 'learning_rate': 0.00039994848875320415, 'epoch': 0.01}        \n",
      "{'loss': 0.9227, 'learning_rate': 0.00039994828552188924, 'epoch': 0.01}        \n",
      "{'loss': 0.926, 'learning_rate': 0.00039994808189050296, 'epoch': 0.01}         \n",
      "{'loss': 0.952, 'learning_rate': 0.0003999478778590457, 'epoch': 0.01}          \n",
      "{'loss': 0.9602, 'learning_rate': 0.00039994767342751796, 'epoch': 0.01}        \n",
      "{'loss': 0.9378, 'learning_rate': 0.00039994746859592, 'epoch': 0.01}           \n",
      "{'loss': 0.9304, 'learning_rate': 0.0003999472633642524, 'epoch': 0.01}         \n",
      "{'loss': 0.9271, 'learning_rate': 0.00039994705773251543, 'epoch': 0.01}        \n",
      "{'loss': 0.9216, 'learning_rate': 0.00039994685170070956, 'epoch': 0.01}        \n",
      "{'loss': 0.9244, 'learning_rate': 0.0003999466452688352, 'epoch': 0.01}         \n",
      "{'loss': 0.9237, 'learning_rate': 0.0003999464384368928, 'epoch': 0.01}         \n",
      "{'loss': 0.9268, 'learning_rate': 0.0003999462312048827, 'epoch': 0.01}         \n",
      "{'loss': 0.9224, 'learning_rate': 0.0003999460235728053, 'epoch': 0.01}         \n",
      "{'loss': 0.9207, 'learning_rate': 0.0003999458155406611, 'epoch': 0.01}         \n",
      "{'loss': 0.9169, 'learning_rate': 0.0003999456071084505, 'epoch': 0.01}         \n",
      "{'loss': 0.9139, 'learning_rate': 0.00039994539827617394, 'epoch': 0.01}        \n",
      "{'loss': 0.9178, 'learning_rate': 0.00039994518904383177, 'epoch': 0.01}        \n",
      "{'loss': 0.9144, 'learning_rate': 0.00039994497941142436, 'epoch': 0.01}        \n",
      "{'loss': 0.9139, 'learning_rate': 0.00039994476937895226, 'epoch': 0.01}        \n",
      "{'loss': 0.9129, 'learning_rate': 0.00039994455894641585, 'epoch': 0.01}        \n",
      "{'loss': 0.9107, 'learning_rate': 0.00039994434811381545, 'epoch': 0.01}        \n",
      "{'loss': 0.9113, 'learning_rate': 0.00039994413688115165, 'epoch': 0.01}        \n",
      "{'loss': 0.9075, 'learning_rate': 0.0003999439252484248, 'epoch': 0.01}         \n",
      "{'loss': 0.9111, 'learning_rate': 0.0003999437132156353, 'epoch': 0.01}         \n",
      "{'loss': 0.9082, 'learning_rate': 0.00039994350078278356, 'epoch': 0.01}        \n",
      "{'loss': 0.9108, 'learning_rate': 0.00039994328794987005, 'epoch': 0.01}        \n",
      "{'loss': 0.9162, 'learning_rate': 0.00039994307471689515, 'epoch': 0.01}        \n",
      "{'loss': 0.9124, 'learning_rate': 0.0003999428610838593, 'epoch': 0.01}         \n",
      "{'loss': 0.9103, 'learning_rate': 0.000399942647050763, 'epoch': 0.01}          \n",
      "{'loss': 0.9172, 'learning_rate': 0.00039994243261760664, 'epoch': 0.01}        \n",
      "{'loss': 0.9152, 'learning_rate': 0.0003999422177843906, 'epoch': 0.01}         \n",
      "{'loss': 0.9184, 'learning_rate': 0.0003999420025511153, 'epoch': 0.01}         \n",
      "{'loss': 0.9158, 'learning_rate': 0.0003999417869177813, 'epoch': 0.01}         \n",
      "{'loss': 0.9147, 'learning_rate': 0.0003999415708843889, 'epoch': 0.01}         \n",
      "{'loss': 0.9152, 'learning_rate': 0.0003999413544509385, 'epoch': 0.01}         \n",
      "{'loss': 0.912, 'learning_rate': 0.00039994113761743065, 'epoch': 0.01}         \n",
      "{'loss': 0.9072, 'learning_rate': 0.00039994092038386574, 'epoch': 0.01}        \n",
      "{'loss': 0.9102, 'learning_rate': 0.0003999407027502442, 'epoch': 0.01}         \n",
      "{'loss': 0.9081, 'learning_rate': 0.0003999404847165665, 'epoch': 0.01}         \n",
      "{'loss': 0.9128, 'learning_rate': 0.0003999402662828331, 'epoch': 0.01}         \n",
      "{'loss': 0.9143, 'learning_rate': 0.00039994004744904426, 'epoch': 0.01}        \n",
      "{'loss': 0.909, 'learning_rate': 0.0003999398282152006, 'epoch': 0.01}          \n",
      "{'loss': 0.911, 'learning_rate': 0.0003999396085813025, 'epoch': 0.01}          \n",
      "{'loss': 0.9071, 'learning_rate': 0.0003999393885473504, 'epoch': 0.01}         \n",
      "{'loss': 0.9058, 'learning_rate': 0.0003999391681133448, 'epoch': 0.01}         \n",
      "{'loss': 0.9104, 'learning_rate': 0.000399938947279286, 'epoch': 0.01}          \n",
      "{'loss': 0.908, 'learning_rate': 0.0003999387260451745, 'epoch': 0.01}          \n",
      "{'loss': 0.9069, 'learning_rate': 0.00039993850441101086, 'epoch': 0.01}        \n",
      "{'loss': 0.9043, 'learning_rate': 0.00039993828237679536, 'epoch': 0.01}        \n",
      "{'loss': 0.9084, 'learning_rate': 0.00039993805994252855, 'epoch': 0.01}        \n",
      "{'loss': 0.9089, 'learning_rate': 0.0003999378371082108, 'epoch': 0.01}         \n",
      "{'loss': 0.9123, 'learning_rate': 0.00039993761387384266, 'epoch': 0.01}        \n",
      "{'loss': 0.9147, 'learning_rate': 0.00039993739023942444, 'epoch': 0.01}        \n",
      "{'loss': 0.9135, 'learning_rate': 0.00039993716620495676, 'epoch': 0.01}        \n",
      "{'loss': 0.9094, 'learning_rate': 0.00039993694177043983, 'epoch': 0.01}        \n",
      "{'loss': 0.9123, 'learning_rate': 0.0003999367169358743, 'epoch': 0.01}         \n",
      "{'loss': 0.9072, 'learning_rate': 0.00039993649170126053, 'epoch': 0.01}        \n",
      "{'loss': 0.9024, 'learning_rate': 0.00039993626606659913, 'epoch': 0.01}        \n",
      "{'loss': 0.9028, 'learning_rate': 0.0003999360400318903, 'epoch': 0.01}         \n",
      "{'loss': 0.9015, 'learning_rate': 0.00039993581359713457, 'epoch': 0.01}        \n",
      "{'loss': 0.901, 'learning_rate': 0.0003999355867623325, 'epoch': 0.01}          \n",
      "{'loss': 0.904, 'learning_rate': 0.00039993535952748447, 'epoch': 0.01}         \n",
      "{'loss': 0.907, 'learning_rate': 0.00039993513189259095, 'epoch': 0.01}         \n",
      "{'loss': 0.9084, 'learning_rate': 0.00039993490385765236, 'epoch': 0.01}        \n",
      "{'loss': 0.911, 'learning_rate': 0.0003999346754226692, 'epoch': 0.01}          \n",
      "{'loss': 0.915, 'learning_rate': 0.00039993444658764193, 'epoch': 0.01}         \n",
      "{'loss': 0.9113, 'learning_rate': 0.00039993421735257096, 'epoch': 0.01}        \n",
      "{'loss': 0.9022, 'learning_rate': 0.00039993398771745675, 'epoch': 0.01}        \n",
      "{'loss': 0.9025, 'learning_rate': 0.0003999337576822998, 'epoch': 0.01}         \n",
      "{'loss': 0.9042, 'learning_rate': 0.00039993352724710063, 'epoch': 0.01}        \n",
      "{'loss': 0.9022, 'learning_rate': 0.00039993329641185957, 'epoch': 0.01}        \n",
      "{'loss': 0.9032, 'learning_rate': 0.0003999330651765772, 'epoch': 0.01}         \n",
      "{'loss': 0.9012, 'learning_rate': 0.0003999328335412538, 'epoch': 0.01}         \n",
      "{'loss': 0.9096, 'learning_rate': 0.00039993260150589005, 'epoch': 0.01}        \n",
      "{'loss': 0.9062, 'learning_rate': 0.0003999323690704863, 'epoch': 0.01}         \n",
      "{'loss': 0.8982, 'learning_rate': 0.000399932136235043, 'epoch': 0.01}          \n",
      "{'loss': 0.8984, 'learning_rate': 0.00039993190299956067, 'epoch': 0.01}        \n",
      "{'loss': 0.9007, 'learning_rate': 0.0003999316693640398, 'epoch': 0.01}         \n",
      "{'loss': 0.8989, 'learning_rate': 0.0003999314353284808, 'epoch': 0.01}         \n",
      "{'loss': 0.8988, 'learning_rate': 0.00039993120089288416, 'epoch': 0.01}        \n",
      "{'loss': 0.9029, 'learning_rate': 0.0003999309660572503, 'epoch': 0.01}         \n",
      "{'loss': 0.8971, 'learning_rate': 0.0003999307308215798, 'epoch': 0.01}         \n",
      "{'loss': 0.8956, 'learning_rate': 0.000399930495185873, 'epoch': 0.01}          \n",
      "{'loss': 0.8983, 'learning_rate': 0.00039993025915013045, 'epoch': 0.01}        \n",
      "{'loss': 0.9038, 'learning_rate': 0.00039993002271435264, 'epoch': 0.01}        \n",
      "{'loss': 0.9059, 'learning_rate': 0.0003999297858785399, 'epoch': 0.01}         \n",
      "{'loss': 0.9078, 'learning_rate': 0.0003999295486426929, 'epoch': 0.01}         \n",
      "{'loss': 0.9045, 'learning_rate': 0.0003999293110068121, 'epoch': 0.01}         \n",
      "{'loss': 0.902, 'learning_rate': 0.0003999290729708978, 'epoch': 0.01}          \n",
      "{'loss': 0.902, 'learning_rate': 0.0003999288345349506, 'epoch': 0.01}          \n",
      "{'loss': 0.8998, 'learning_rate': 0.00039992859569897097, 'epoch': 0.01}        \n",
      "{'loss': 0.9002, 'learning_rate': 0.0003999283564629594, 'epoch': 0.01}         \n",
      "{'loss': 0.9071, 'learning_rate': 0.00039992811682691633, 'epoch': 0.01}        \n",
      "  1%|▎                                 | 3000/351164 [45:29<81:57:55,  1.18it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.9079, 'learning_rate': 0.0003999278767908422, 'epoch': 0.01}         \n",
      "{'loss': 0.9086, 'learning_rate': 0.0003999276363547376, 'epoch': 0.01}         \n",
      "{'loss': 0.9022, 'learning_rate': 0.0003999273955186029, 'epoch': 0.01}         \n",
      "{'loss': 0.9006, 'learning_rate': 0.00039992715428243867, 'epoch': 0.01}        \n",
      "{'loss': 0.8998, 'learning_rate': 0.0003999269126462454, 'epoch': 0.01}         \n",
      "{'loss': 0.9005, 'learning_rate': 0.0003999266706100235, 'epoch': 0.01}         \n",
      "{'loss': 0.8948, 'learning_rate': 0.0003999264281737735, 'epoch': 0.01}         \n",
      "{'loss': 0.8932, 'learning_rate': 0.00039992618533749583, 'epoch': 0.01}        \n",
      "{'loss': 0.897, 'learning_rate': 0.0003999259421011911, 'epoch': 0.01}          \n",
      "{'loss': 0.9002, 'learning_rate': 0.00039992569846485966, 'epoch': 0.01}        \n",
      "{'loss': 0.8929, 'learning_rate': 0.000399925454428502, 'epoch': 0.01}          \n",
      "{'loss': 0.8952, 'learning_rate': 0.0003999252099921187, 'epoch': 0.01}         \n",
      "{'loss': 0.8954, 'learning_rate': 0.00039992496515571025, 'epoch': 0.01}        \n",
      "{'loss': 0.8964, 'learning_rate': 0.0003999247199192771, 'epoch': 0.01}         \n",
      "{'loss': 0.8954, 'learning_rate': 0.00039992447428281974, 'epoch': 0.01}        \n",
      "{'loss': 0.8943, 'learning_rate': 0.0003999242282463386, 'epoch': 0.01}         \n",
      "{'loss': 0.8969, 'learning_rate': 0.0003999239818098343, 'epoch': 0.01}         \n",
      "{'loss': 0.8978, 'learning_rate': 0.0003999237349733072, 'epoch': 0.01}         \n",
      "{'loss': 0.8966, 'learning_rate': 0.00039992348773675794, 'epoch': 0.01}        \n",
      "{'loss': 0.9074, 'learning_rate': 0.0003999232401001869, 'epoch': 0.01}         \n",
      "{'loss': 0.9054, 'learning_rate': 0.0003999229920635946, 'epoch': 0.01}         \n",
      "{'loss': 0.9005, 'learning_rate': 0.00039992274362698154, 'epoch': 0.01}        \n",
      "{'loss': 0.8973, 'learning_rate': 0.00039992249479034827, 'epoch': 0.01}        \n",
      "{'loss': 0.8984, 'learning_rate': 0.0003999222455536952, 'epoch': 0.01}         \n",
      "{'loss': 0.8972, 'learning_rate': 0.00039992199591702286, 'epoch': 0.01}        \n",
      "{'loss': 0.8953, 'learning_rate': 0.0003999217458803318, 'epoch': 0.01}         \n",
      "{'loss': 0.896, 'learning_rate': 0.00039992149544362246, 'epoch': 0.01}         \n",
      "{'loss': 0.8961, 'learning_rate': 0.0003999212446068954, 'epoch': 0.01}         \n",
      "{'loss': 0.8925, 'learning_rate': 0.00039992099337015106, 'epoch': 0.01}        \n",
      "{'loss': 0.8941, 'learning_rate': 0.00039992074173338994, 'epoch': 0.01}        \n",
      "{'loss': 0.8885, 'learning_rate': 0.00039992048969661264, 'epoch': 0.01}        \n",
      "{'loss': 0.8917, 'learning_rate': 0.0003999202372598195, 'epoch': 0.01}         \n",
      "{'loss': 0.896, 'learning_rate': 0.0003999199844230112, 'epoch': 0.01}          \n",
      "{'loss': 0.8928, 'learning_rate': 0.0003999197311861881, 'epoch': 0.01}         \n",
      "{'loss': 0.8869, 'learning_rate': 0.0003999194775493508, 'epoch': 0.01}         \n",
      "{'loss': 0.8886, 'learning_rate': 0.0003999192235124998, 'epoch': 0.01}         \n",
      "{'loss': 0.8916, 'learning_rate': 0.0003999189690756356, 'epoch': 0.01}         \n",
      "{'loss': 0.891, 'learning_rate': 0.00039991871423875866, 'epoch': 0.01}         \n",
      "{'loss': 0.8973, 'learning_rate': 0.00039991845900186953, 'epoch': 0.01}        \n",
      "{'loss': 0.8932, 'learning_rate': 0.0003999182033649687, 'epoch': 0.01}         \n",
      "{'loss': 0.9036, 'learning_rate': 0.0003999179473280567, 'epoch': 0.01}         \n",
      "{'loss': 0.9109, 'learning_rate': 0.0003999176908911341, 'epoch': 0.01}         \n",
      "{'loss': 0.9192, 'learning_rate': 0.0003999174340542013, 'epoch': 0.01}         \n",
      "{'loss': 0.9025, 'learning_rate': 0.0003999171768172589, 'epoch': 0.01}         \n",
      "{'loss': 0.8996, 'learning_rate': 0.00039991691918030733, 'epoch': 0.01}        \n",
      "{'loss': 0.8963, 'learning_rate': 0.0003999166611433472, 'epoch': 0.01}         \n",
      "{'loss': 0.8946, 'learning_rate': 0.000399916402706379, 'epoch': 0.01}          \n",
      "{'loss': 0.8936, 'learning_rate': 0.00039991614386940326, 'epoch': 0.01}        \n",
      "{'loss': 0.8932, 'learning_rate': 0.0003999158846324204, 'epoch': 0.01}         \n",
      "{'loss': 0.8899, 'learning_rate': 0.00039991562499543104, 'epoch': 0.01}        \n",
      "{'loss': 0.8889, 'learning_rate': 0.0003999153649584357, 'epoch': 0.01}         \n",
      "{'loss': 0.8855, 'learning_rate': 0.0003999151045214348, 'epoch': 0.01}         \n",
      "{'loss': 0.8865, 'learning_rate': 0.000399914843684429, 'epoch': 0.01}          \n",
      "{'loss': 0.8915, 'learning_rate': 0.00039991458244741866, 'epoch': 0.01}        \n",
      "{'loss': 0.8845, 'learning_rate': 0.00039991432081040447, 'epoch': 0.01}        \n",
      "{'loss': 0.8852, 'learning_rate': 0.00039991405877338684, 'epoch': 0.01}        \n",
      "{'loss': 0.8882, 'learning_rate': 0.0003999137963363664, 'epoch': 0.01}         \n",
      "{'loss': 0.8891, 'learning_rate': 0.0003999135334993435, 'epoch': 0.01}         \n",
      "{'loss': 0.8883, 'learning_rate': 0.0003999132702623189, 'epoch': 0.01}         \n",
      "{'loss': 0.8905, 'learning_rate': 0.0003999130066252929, 'epoch': 0.01}         \n",
      "{'loss': 0.8899, 'learning_rate': 0.00039991274258826615, 'epoch': 0.01}        \n",
      "{'loss': 0.8899, 'learning_rate': 0.00039991247815123913, 'epoch': 0.01}        \n",
      "{'loss': 0.8852, 'learning_rate': 0.0003999122133142125, 'epoch': 0.01}         \n",
      "{'loss': 0.8863, 'learning_rate': 0.00039991194807718656, 'epoch': 0.01}        \n",
      "{'loss': 0.8937, 'learning_rate': 0.00039991168244016197, 'epoch': 0.01}        \n",
      "{'loss': 0.8952, 'learning_rate': 0.0003999114164031394, 'epoch': 0.01}         \n",
      "{'loss': 0.8951, 'learning_rate': 0.0003999111499661191, 'epoch': 0.01}         \n",
      "{'loss': 0.8925, 'learning_rate': 0.00039991088312910176, 'epoch': 0.01}        \n",
      "{'loss': 0.892, 'learning_rate': 0.00039991061589208794, 'epoch': 0.01}         \n",
      "{'loss': 0.8923, 'learning_rate': 0.00039991034825507805, 'epoch': 0.01}        \n",
      "{'loss': 0.8966, 'learning_rate': 0.0003999100802180728, 'epoch': 0.01}         \n",
      "{'loss': 0.8941, 'learning_rate': 0.00039990981178107264, 'epoch': 0.01}        \n",
      "{'loss': 0.8844, 'learning_rate': 0.00039990954294407804, 'epoch': 0.01}        \n",
      "{'loss': 0.8863, 'learning_rate': 0.0003999092737070896, 'epoch': 0.01}         \n",
      "{'loss': 0.8879, 'learning_rate': 0.0003999090040701079, 'epoch': 0.01}         \n",
      "{'loss': 0.8851, 'learning_rate': 0.0003999087340331334, 'epoch': 0.01}         \n",
      "{'loss': 0.8877, 'learning_rate': 0.0003999084635961667, 'epoch': 0.01}         \n",
      "{'loss': 0.8872, 'learning_rate': 0.00039990819275920826, 'epoch': 0.01}        \n",
      "{'loss': 0.8863, 'learning_rate': 0.00039990792152225875, 'epoch': 0.01}        \n",
      "{'loss': 0.8847, 'learning_rate': 0.0003999076498853186, 'epoch': 0.01}         \n",
      "{'loss': 0.8943, 'learning_rate': 0.00039990737784838845, 'epoch': 0.01}        \n",
      "{'loss': 0.8958, 'learning_rate': 0.00039990710541146874, 'epoch': 0.01}        \n",
      "{'loss': 0.8888, 'learning_rate': 0.0003999068325745601, 'epoch': 0.01}         \n",
      "{'loss': 0.8879, 'learning_rate': 0.00039990655933766294, 'epoch': 0.01}        \n",
      "{'loss': 0.8877, 'learning_rate': 0.00039990628570077803, 'epoch': 0.01}        \n",
      "{'loss': 0.887, 'learning_rate': 0.0003999060116639058, 'epoch': 0.01}          \n",
      "{'loss': 0.8875, 'learning_rate': 0.00039990573722704665, 'epoch': 0.01}        \n",
      "{'loss': 0.8843, 'learning_rate': 0.00039990546239020136, 'epoch': 0.01}        \n",
      "{'loss': 0.8828, 'learning_rate': 0.0003999051871533705, 'epoch': 0.01}         \n",
      "{'loss': 0.8824, 'learning_rate': 0.0003999049115165543, 'epoch': 0.01}         \n",
      "{'loss': 0.8843, 'learning_rate': 0.0003999046354797537, 'epoch': 0.01}         \n",
      "{'loss': 0.8853, 'learning_rate': 0.000399904359042969, 'epoch': 0.01}          \n",
      "{'loss': 0.8827, 'learning_rate': 0.00039990408220620086, 'epoch': 0.01}        \n",
      "{'loss': 0.8864, 'learning_rate': 0.0003999038049694498, 'epoch': 0.01}         \n",
      "{'loss': 0.8833, 'learning_rate': 0.00039990352733271635, 'epoch': 0.01}        \n",
      "{'loss': 0.8863, 'learning_rate': 0.0003999032492960011, 'epoch': 0.01}         \n",
      "{'loss': 0.8946, 'learning_rate': 0.0003999029708593046, 'epoch': 0.01}         \n",
      "{'loss': 0.8891, 'learning_rate': 0.0003999026920226274, 'epoch': 0.01}         \n",
      "{'loss': 0.8839, 'learning_rate': 0.0003999024127859701, 'epoch': 0.01}         \n",
      "{'loss': 0.8905, 'learning_rate': 0.0003999021331493332, 'epoch': 0.01}         \n",
      "  1%|▎                                 | 3500/351164 [52:37<80:32:27,  1.20it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8874, 'learning_rate': 0.00039990185311271733, 'epoch': 0.01}        \n",
      "{'loss': 0.8821, 'learning_rate': 0.0003999015726761229, 'epoch': 0.01}         \n",
      "{'loss': 0.8814, 'learning_rate': 0.0003999012918395507, 'epoch': 0.01}         \n",
      "{'loss': 0.8882, 'learning_rate': 0.0003999010106030011, 'epoch': 0.01}         \n",
      "{'loss': 0.8842, 'learning_rate': 0.0003999007289664747, 'epoch': 0.01}         \n",
      "{'loss': 0.8803, 'learning_rate': 0.0003999004469299721, 'epoch': 0.01}         \n",
      "{'loss': 0.8837, 'learning_rate': 0.00039990016449349393, 'epoch': 0.01}        \n",
      "{'loss': 0.8793, 'learning_rate': 0.0003998998816570406, 'epoch': 0.01}         \n",
      "{'loss': 0.882, 'learning_rate': 0.0003998995984206128, 'epoch': 0.01}          \n",
      "{'loss': 0.8842, 'learning_rate': 0.00039989931478421107, 'epoch': 0.01}        \n",
      "{'loss': 0.8791, 'learning_rate': 0.000399899030747836, 'epoch': 0.01}          \n",
      "{'loss': 0.8788, 'learning_rate': 0.00039989874631148807, 'epoch': 0.01}        \n",
      "{'loss': 0.8791, 'learning_rate': 0.00039989846147516785, 'epoch': 0.01}        \n",
      "{'loss': 0.8821, 'learning_rate': 0.000399898176238876, 'epoch': 0.01}          \n",
      "{'loss': 0.8859, 'learning_rate': 0.0003998978906026131, 'epoch': 0.01}         \n",
      "{'loss': 0.8839, 'learning_rate': 0.0003998976045663796, 'epoch': 0.01}         \n",
      "{'loss': 0.8844, 'learning_rate': 0.0003998973181301762, 'epoch': 0.01}         \n",
      "{'loss': 0.8855, 'learning_rate': 0.0003998970312940034, 'epoch': 0.01}         \n",
      "{'loss': 0.8837, 'learning_rate': 0.00039989674405786177, 'epoch': 0.01}        \n",
      "{'loss': 0.8831, 'learning_rate': 0.00039989645642175196, 'epoch': 0.01}        \n",
      "{'loss': 0.8806, 'learning_rate': 0.00039989616838567444, 'epoch': 0.01}        \n",
      "{'loss': 0.8811, 'learning_rate': 0.00039989587994962986, 'epoch': 0.01}        \n",
      "{'loss': 0.8787, 'learning_rate': 0.00039989559111361877, 'epoch': 0.01}        \n",
      "{'loss': 0.8795, 'learning_rate': 0.00039989530187764175, 'epoch': 0.01}        \n",
      "{'loss': 0.88, 'learning_rate': 0.0003998950122416994, 'epoch': 0.01}           \n",
      "{'loss': 0.8792, 'learning_rate': 0.00039989472220579227, 'epoch': 0.01}        \n",
      "{'loss': 0.8839, 'learning_rate': 0.00039989443176992095, 'epoch': 0.01}        \n",
      "{'loss': 0.8777, 'learning_rate': 0.00039989414093408605, 'epoch': 0.01}        \n",
      "{'loss': 0.8798, 'learning_rate': 0.0003998938496982881, 'epoch': 0.01}         \n",
      "{'loss': 0.8795, 'learning_rate': 0.0003998935580625277, 'epoch': 0.01}         \n",
      "{'loss': 0.8852, 'learning_rate': 0.00039989326602680547, 'epoch': 0.01}        \n",
      "{'loss': 0.8838, 'learning_rate': 0.0003998929735911219, 'epoch': 0.01}         \n",
      "{'loss': 0.8831, 'learning_rate': 0.0003998926807554777, 'epoch': 0.01}         \n",
      "{'loss': 0.8826, 'learning_rate': 0.0003998923875198734, 'epoch': 0.01}         \n",
      "{'loss': 0.8839, 'learning_rate': 0.00039989209388430956, 'epoch': 0.01}        \n",
      "{'loss': 0.9074, 'learning_rate': 0.0003998917998487868, 'epoch': 0.01}         \n",
      "{'loss': 0.8945, 'learning_rate': 0.00039989150541330565, 'epoch': 0.01}        \n",
      "{'loss': 0.8848, 'learning_rate': 0.00039989121057786687, 'epoch': 0.01}        \n",
      "{'loss': 0.8841, 'learning_rate': 0.0003998909153424708, 'epoch': 0.01}         \n",
      "{'loss': 0.8784, 'learning_rate': 0.0003998906197071182, 'epoch': 0.01}         \n",
      "{'loss': 0.8797, 'learning_rate': 0.00039989032367180965, 'epoch': 0.01}        \n",
      "{'loss': 0.8771, 'learning_rate': 0.00039989002723654567, 'epoch': 0.01}        \n",
      "{'loss': 0.8794, 'learning_rate': 0.00039988973040132694, 'epoch': 0.01}        \n",
      "{'loss': 0.8748, 'learning_rate': 0.000399889433166154, 'epoch': 0.01}          \n",
      "{'loss': 0.8804, 'learning_rate': 0.00039988913553102743, 'epoch': 0.01}        \n",
      "{'loss': 0.8806, 'learning_rate': 0.00039988883749594785, 'epoch': 0.01}        \n",
      "{'loss': 0.8749, 'learning_rate': 0.0003998885390609159, 'epoch': 0.01}         \n",
      "{'loss': 0.8808, 'learning_rate': 0.00039988824022593213, 'epoch': 0.01}        \n",
      "{'loss': 0.8838, 'learning_rate': 0.0003998879409909971, 'epoch': 0.01}         \n",
      "{'loss': 0.8815, 'learning_rate': 0.0003998876413561115, 'epoch': 0.01}         \n",
      "{'loss': 0.8858, 'learning_rate': 0.0003998873413212758, 'epoch': 0.01}         \n",
      "{'loss': 0.884, 'learning_rate': 0.0003998870408864908, 'epoch': 0.01}          \n",
      "{'loss': 0.8926, 'learning_rate': 0.00039988674005175687, 'epoch': 0.01}        \n",
      "{'loss': 0.8922, 'learning_rate': 0.00039988643881707476, 'epoch': 0.01}        \n",
      "{'loss': 0.8889, 'learning_rate': 0.00039988613718244505, 'epoch': 0.01}        \n",
      "{'loss': 0.8825, 'learning_rate': 0.0003998858351478683, 'epoch': 0.01}         \n",
      "{'loss': 0.8823, 'learning_rate': 0.00039988553271334517, 'epoch': 0.01}        \n",
      "{'loss': 0.8823, 'learning_rate': 0.00039988522987887624, 'epoch': 0.01}        \n",
      "{'loss': 0.8781, 'learning_rate': 0.0003998849266444621, 'epoch': 0.01}         \n",
      "{'loss': 0.877, 'learning_rate': 0.0003998846230101034, 'epoch': 0.01}          \n",
      "{'loss': 0.8789, 'learning_rate': 0.0003998843189758007, 'epoch': 0.01}         \n",
      "{'loss': 0.8742, 'learning_rate': 0.00039988401454155463, 'epoch': 0.01}        \n",
      "{'loss': 0.8801, 'learning_rate': 0.0003998837097073658, 'epoch': 0.01}         \n",
      "{'loss': 0.8741, 'learning_rate': 0.0003998834044732348, 'epoch': 0.01}         \n",
      "{'loss': 0.8769, 'learning_rate': 0.0003998830988391623, 'epoch': 0.01}         \n",
      "{'loss': 0.8749, 'learning_rate': 0.00039988279280514885, 'epoch': 0.01}        \n",
      "{'loss': 0.879, 'learning_rate': 0.00039988248637119506, 'epoch': 0.01}         \n",
      "{'loss': 0.8781, 'learning_rate': 0.00039988217953730153, 'epoch': 0.01}        \n",
      "{'loss': 0.8804, 'learning_rate': 0.00039988187230346903, 'epoch': 0.01}        \n",
      "{'loss': 0.8838, 'learning_rate': 0.0003998815646696979, 'epoch': 0.01}         \n",
      "{'loss': 0.8833, 'learning_rate': 0.00039988125663598903, 'epoch': 0.01}        \n",
      "{'loss': 0.8829, 'learning_rate': 0.0003998809482023429, 'epoch': 0.01}         \n",
      "{'loss': 0.8829, 'learning_rate': 0.0003998806393687601, 'epoch': 0.01}         \n",
      "{'loss': 0.8896, 'learning_rate': 0.00039988033013524133, 'epoch': 0.01}        \n",
      "{'loss': 0.8827, 'learning_rate': 0.0003998800205017871, 'epoch': 0.01}         \n",
      "{'loss': 0.88, 'learning_rate': 0.00039987971046839815, 'epoch': 0.01}          \n",
      "{'loss': 0.8786, 'learning_rate': 0.000399879400035075, 'epoch': 0.01}          \n",
      "{'loss': 0.8773, 'learning_rate': 0.00039987908920181836, 'epoch': 0.01}        \n",
      "{'loss': 0.8767, 'learning_rate': 0.0003998787779686288, 'epoch': 0.01}         \n",
      "{'loss': 0.8754, 'learning_rate': 0.00039987846633550704, 'epoch': 0.01}        \n",
      "{'loss': 0.8775, 'learning_rate': 0.0003998781543024535, 'epoch': 0.01}         \n",
      "{'loss': 0.8806, 'learning_rate': 0.000399877841869469, 'epoch': 0.01}          \n",
      "{'loss': 0.8756, 'learning_rate': 0.000399877529036554, 'epoch': 0.01}          \n",
      "{'loss': 0.8759, 'learning_rate': 0.00039987721580370925, 'epoch': 0.01}        \n",
      "{'loss': 0.8751, 'learning_rate': 0.00039987690217093536, 'epoch': 0.01}        \n",
      "{'loss': 0.8776, 'learning_rate': 0.00039987658813823296, 'epoch': 0.01}        \n",
      "{'loss': 0.8749, 'learning_rate': 0.00039987627370560263, 'epoch': 0.01}        \n",
      "{'loss': 0.8743, 'learning_rate': 0.000399875958873045, 'epoch': 0.01}          \n",
      "{'loss': 0.8768, 'learning_rate': 0.00039987564364056083, 'epoch': 0.01}        \n",
      "{'loss': 0.8725, 'learning_rate': 0.00039987532800815054, 'epoch': 0.01}        \n",
      "{'loss': 0.8757, 'learning_rate': 0.0003998750119758149, 'epoch': 0.01}         \n",
      "{'loss': 0.8861, 'learning_rate': 0.0003998746955435545, 'epoch': 0.01}         \n",
      "{'loss': 0.876, 'learning_rate': 0.00039987437871137, 'epoch': 0.01}            \n",
      "{'loss': 0.8753, 'learning_rate': 0.000399874061479262, 'epoch': 0.01}          \n",
      "{'loss': 0.8756, 'learning_rate': 0.0003998737438472311, 'epoch': 0.01}         \n",
      "{'loss': 0.8719, 'learning_rate': 0.0003998734258152781, 'epoch': 0.01}         \n",
      "{'loss': 0.872, 'learning_rate': 0.00039987310738340346, 'epoch': 0.01}         \n",
      "{'loss': 0.8725, 'learning_rate': 0.0003998727885516079, 'epoch': 0.01}         \n",
      "{'loss': 0.8716, 'learning_rate': 0.000399872469319892, 'epoch': 0.01}          \n",
      "{'loss': 0.8702, 'learning_rate': 0.00039987214968825643, 'epoch': 0.01}        \n",
      "  1%|▍                                 | 4000/351164 [59:42<83:02:33,  1.16it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<01:00,  2.30it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:25,  1.61it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:31,  1.49it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:39,  1.36it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:43,  1.30it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:05<01:47,  1.25it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:05<01:45,  1.26it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:48,  1.22it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:49,  1.20it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:44,  1.24it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:44,  1.23it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:10<01:49,  1.17it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:11<01:54,  1.11it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:11<01:52,  1.12it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:48,  1.15it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:50,  1.12it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:47,  1.14it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:15<01:46,  1.14it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:16<01:47,  1.13it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:17<01:49,  1.10it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:18<01:47,  1.10it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:19<01:43,  1.14it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:19<01:38,  1.19it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:38,  1.18it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:38,  1.17it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:22<01:36,  1.18it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:23<01:33,  1.20it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:24<01:33,  1.20it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:24<01:32,  1.20it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:28,  1.24it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:26<01:28,  1.23it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:27<01:29,  1.20it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:28<01:34,  1.13it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:29<01:32,  1.15it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:29<01:28,  1.18it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:30<01:27,  1.19it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:31<01:26,  1.19it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:32<01:29,  1.14it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:33<01:27,  1.15it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:34<01:24,  1.18it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:35<01:24,  1.18it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:36<01:26,  1.13it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:36<01:24,  1.15it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:37<01:23,  1.15it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:38<01:22,  1.15it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:39<01:18,  1.19it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:40<01:17,  1.20it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:41<01:21,  1.13it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:42<01:22,  1.11it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:43<01:20,  1.12it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:43<01:21,  1.09it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:44<01:17,  1.13it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:45<01:15,  1.16it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:46<01:12,  1.18it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:47<01:11,  1.19it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:48<01:09,  1.22it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:48<01:09,  1.19it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:49<01:08,  1.20it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:50<01:07,  1.19it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:51<01:05,  1.22it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:52<01:05,  1.20it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:52<01:03,  1.22it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:53<01:04,  1.20it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:54<01:02,  1.21it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:55<01:05,  1.14it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:56<01:04,  1.14it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:57<01:02,  1.17it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:58<01:02,  1.15it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:59<01:04,  1.11it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [01:00<01:03,  1.10it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:00<01:01,  1.13it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:01<00:58,  1.15it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:02<00:56,  1.18it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:03<00:55,  1.18it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:04<00:53,  1.21it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:05<00:53,  1.19it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:05<00:52,  1.20it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:06<00:51,  1.20it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:07<00:50,  1.22it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:08<00:49,  1.21it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:09<00:51,  1.15it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:10<00:51,  1.13it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:11<00:51,  1.11it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:12<00:49,  1.14it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:12<00:49,  1.11it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:13<00:47,  1.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:14<00:45,  1.15it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:15<00:44,  1.18it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:16<00:42,  1.20it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:17<00:40,  1.22it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:17<00:40,  1.20it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:18<00:42,  1.14it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:19<00:41,  1.12it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:20<00:42,  1.09it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:21<00:40,  1.11it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:22<00:38,  1.14it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:23<00:36,  1.17it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:24<00:35,  1.18it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:24<00:34,  1.18it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:25<00:33,  1.18it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:26<00:33,  1.15it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:27<00:32,  1.17it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:28<00:31,  1.17it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:29<00:31,  1.15it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:30<00:30,  1.16it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:30<00:28,  1.19it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:31<00:27,  1.20it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:32<00:26,  1.19it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:33<00:26,  1.17it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:34<00:25,  1.18it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:35<00:24,  1.20it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:35<00:23,  1.22it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:36<00:22,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:37<00:21,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:38<00:21,  1.14it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:39<00:21,  1.10it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:40<00:20,  1.15it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:41<00:19,  1.14it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:42<00:18,  1.16it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:42<00:17,  1.15it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:43<00:16,  1.13it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:44<00:15,  1.15it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:45<00:14,  1.16it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:46<00:13,  1.16it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:47<00:12,  1.16it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:48<00:12,  1.16it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:48<00:11,  1.18it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:49<00:10,  1.20it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:50<00:09,  1.22it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:51<00:08,  1.22it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:52<00:07,  1.19it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:53<00:06,  1.20it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:53<00:05,  1.17it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:54<00:05,  1.15it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:55<00:04,  1.18it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:56<00:03,  1.16it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:57<00:02,  1.13it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:58<00:01,  1.15it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:59<00:00,  1.17it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [01:59<00:00,  1.18it/s]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8648104667663574, 'eval_cer': 0.04516999437147411, 'eval_runtime': 127.4261, 'eval_samples_per_second': 70.559, 'eval_steps_per_second': 1.107, 'epoch': 0.01}\n",
      "  1%|▎                               | 4000/351164 [1:01:49<83:02:33,  1.16it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [02:01<00:00,  1.18it/s]\u001b[A\n",
      "                                                                                \u001b[ACheckpoint destination directory models/checkpoint-4000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8708, 'learning_rate': 0.00039987182965670195, 'epoch': 0.01}        \n",
      "{'loss': 0.8742, 'learning_rate': 0.0003998715092252289, 'epoch': 0.01}         \n",
      "{'loss': 0.8777, 'learning_rate': 0.0003998711883938383, 'epoch': 0.01}         \n",
      "{'loss': 0.8766, 'learning_rate': 0.0003998708671625305, 'epoch': 0.01}         \n",
      "{'loss': 0.8823, 'learning_rate': 0.00039987054553130625, 'epoch': 0.01}        \n",
      "{'loss': 0.8824, 'learning_rate': 0.0003998702235001662, 'epoch': 0.01}         \n",
      "{'loss': 0.8809, 'learning_rate': 0.000399869901069111, 'epoch': 0.01}          \n",
      "{'loss': 0.8801, 'learning_rate': 0.00039986957823814125, 'epoch': 0.01}        \n",
      "{'loss': 0.8808, 'learning_rate': 0.0003998692550072576, 'epoch': 0.01}         \n",
      "{'loss': 0.8804, 'learning_rate': 0.00039986893137646077, 'epoch': 0.01}        \n",
      "{'loss': 0.8816, 'learning_rate': 0.00039986860734575133, 'epoch': 0.01}        \n",
      "{'loss': 0.8774, 'learning_rate': 0.00039986828291512996, 'epoch': 0.01}        \n",
      "{'loss': 0.8759, 'learning_rate': 0.00039986795808459727, 'epoch': 0.01}        \n",
      "{'loss': 0.8727, 'learning_rate': 0.00039986763285415394, 'epoch': 0.01}        \n",
      "{'loss': 0.8698, 'learning_rate': 0.0003998673072238007, 'epoch': 0.01}         \n",
      "{'loss': 0.8773, 'learning_rate': 0.0003998669811935381, 'epoch': 0.01}         \n",
      "{'loss': 0.8728, 'learning_rate': 0.00039986665476336676, 'epoch': 0.01}        \n",
      "{'loss': 0.8704, 'learning_rate': 0.0003998663279332875, 'epoch': 0.01}         \n",
      "{'loss': 0.8704, 'learning_rate': 0.0003998660007033007, 'epoch': 0.01}         \n",
      "{'loss': 0.8717, 'learning_rate': 0.00039986567307340735, 'epoch': 0.01}        \n",
      "{'loss': 0.8712, 'learning_rate': 0.00039986534504360784, 'epoch': 0.01}        \n",
      "{'loss': 0.8715, 'learning_rate': 0.00039986501661390297, 'epoch': 0.01}        \n",
      "{'loss': 0.8723, 'learning_rate': 0.0003998646877842933, 'epoch': 0.01}         \n",
      "{'loss': 0.8695, 'learning_rate': 0.00039986435855477955, 'epoch': 0.01}        \n",
      "{'loss': 0.8759, 'learning_rate': 0.00039986402892536237, 'epoch': 0.01}        \n",
      "{'loss': 0.8784, 'learning_rate': 0.00039986369889604247, 'epoch': 0.01}        \n",
      "{'loss': 0.8773, 'learning_rate': 0.0003998633684668204, 'epoch': 0.01}         \n",
      "{'loss': 0.8736, 'learning_rate': 0.0003998630376376969, 'epoch': 0.01}         \n",
      "{'loss': 0.8686, 'learning_rate': 0.00039986270640867257, 'epoch': 0.01}        \n",
      "{'loss': 0.8665, 'learning_rate': 0.0003998623747797481, 'epoch': 0.01}         \n",
      "{'loss': 0.8757, 'learning_rate': 0.0003998620427509243, 'epoch': 0.01}         \n",
      "{'loss': 0.8724, 'learning_rate': 0.00039986171032220156, 'epoch': 0.01}        \n",
      "{'loss': 0.8704, 'learning_rate': 0.00039986137749358077, 'epoch': 0.01}        \n",
      "{'loss': 0.876, 'learning_rate': 0.0003998610442650624, 'epoch': 0.01}          \n",
      "{'loss': 0.8769, 'learning_rate': 0.00039986071063664733, 'epoch': 0.01}        \n",
      "{'loss': 0.8734, 'learning_rate': 0.0003998603766083361, 'epoch': 0.01}         \n",
      "{'loss': 0.8722, 'learning_rate': 0.00039986004218012944, 'epoch': 0.01}        \n",
      "{'loss': 0.8721, 'learning_rate': 0.00039985970735202794, 'epoch': 0.01}        \n",
      "{'loss': 0.8695, 'learning_rate': 0.00039985937212403224, 'epoch': 0.01}        \n",
      "{'loss': 0.8688, 'learning_rate': 0.0003998590364961432, 'epoch': 0.01}         \n",
      "{'loss': 0.8707, 'learning_rate': 0.00039985870046836127, 'epoch': 0.01}        \n",
      "{'loss': 0.8698, 'learning_rate': 0.0003998583640406873, 'epoch': 0.01}         \n",
      "{'loss': 0.8717, 'learning_rate': 0.00039985802721312184, 'epoch': 0.01}        \n",
      "{'loss': 0.8715, 'learning_rate': 0.0003998576899856657, 'epoch': 0.01}         \n",
      "{'loss': 0.8703, 'learning_rate': 0.00039985735235831943, 'epoch': 0.01}        \n",
      "{'loss': 0.8731, 'learning_rate': 0.00039985701433108373, 'epoch': 0.01}        \n",
      "{'loss': 0.8709, 'learning_rate': 0.00039985667590395924, 'epoch': 0.01}        \n",
      "{'loss': 0.8708, 'learning_rate': 0.0003998563370769468, 'epoch': 0.01}         \n",
      "{'loss': 0.8721, 'learning_rate': 0.0003998559978500469, 'epoch': 0.01}         \n",
      "{'loss': 0.8746, 'learning_rate': 0.00039985565822326036, 'epoch': 0.01}        \n",
      "{'loss': 0.8738, 'learning_rate': 0.0003998553181965877, 'epoch': 0.01}         \n",
      "{'loss': 0.8697, 'learning_rate': 0.00039985497777002976, 'epoch': 0.01}        \n",
      "{'loss': 0.8711, 'learning_rate': 0.0003998546369435871, 'epoch': 0.01}         \n",
      "{'loss': 0.8742, 'learning_rate': 0.0003998542957172605, 'epoch': 0.01}         \n",
      "{'loss': 0.8707, 'learning_rate': 0.0003998539540910506, 'epoch': 0.01}         \n",
      "{'loss': 0.8709, 'learning_rate': 0.0003998536120649581, 'epoch': 0.01}         \n",
      "{'loss': 0.8717, 'learning_rate': 0.00039985326963898365, 'epoch': 0.01}        \n",
      "{'loss': 0.8745, 'learning_rate': 0.00039985292681312795, 'epoch': 0.01}        \n",
      "{'loss': 0.8734, 'learning_rate': 0.0003998525835873917, 'epoch': 0.01}         \n",
      "{'loss': 0.8735, 'learning_rate': 0.00039985223996177557, 'epoch': 0.01}        \n",
      "{'loss': 0.8728, 'learning_rate': 0.00039985189593628025, 'epoch': 0.01}        \n",
      "{'loss': 0.8732, 'learning_rate': 0.00039985155151090645, 'epoch': 0.01}        \n",
      "{'loss': 0.8684, 'learning_rate': 0.0003998512066856548, 'epoch': 0.01}         \n",
      "{'loss': 0.8712, 'learning_rate': 0.00039985086146052606, 'epoch': 0.01}        \n",
      "{'loss': 0.8701, 'learning_rate': 0.0003998505158355209, 'epoch': 0.01}         \n",
      "{'loss': 0.8728, 'learning_rate': 0.00039985016981064, 'epoch': 0.01}           \n",
      "{'loss': 0.8731, 'learning_rate': 0.000399849823385884, 'epoch': 0.01}          \n",
      "{'loss': 0.8864, 'learning_rate': 0.0003998494765612537, 'epoch': 0.01}         \n",
      "{'loss': 0.8772, 'learning_rate': 0.0003998491293367497, 'epoch': 0.01}         \n",
      "{'loss': 0.8687, 'learning_rate': 0.0003998487817123728, 'epoch': 0.01}         \n",
      "{'loss': 0.8696, 'learning_rate': 0.0003998484336881236, 'epoch': 0.01}         \n",
      "{'loss': 0.8694, 'learning_rate': 0.0003998480852640029, 'epoch': 0.01}         \n",
      "{'loss': 0.8692, 'learning_rate': 0.00039984773644001124, 'epoch': 0.01}        \n",
      "{'loss': 0.869, 'learning_rate': 0.0003998473872161494, 'epoch': 0.01}          \n",
      "{'loss': 0.868, 'learning_rate': 0.00039984703759241816, 'epoch': 0.01}         \n",
      "{'loss': 0.8677, 'learning_rate': 0.00039984668756881805, 'epoch': 0.01}        \n",
      "{'loss': 0.8666, 'learning_rate': 0.0003998463371453499, 'epoch': 0.01}         \n",
      "{'loss': 0.8672, 'learning_rate': 0.0003998459863220144, 'epoch': 0.01}         \n",
      "{'loss': 0.8663, 'learning_rate': 0.0003998456350988122, 'epoch': 0.01}         \n",
      "{'loss': 0.867, 'learning_rate': 0.00039984528347574404, 'epoch': 0.01}         \n",
      "{'loss': 0.8697, 'learning_rate': 0.00039984493145281066, 'epoch': 0.01}        \n",
      "{'loss': 0.8666, 'learning_rate': 0.0003998445790300127, 'epoch': 0.01}         \n",
      "{'loss': 0.8666, 'learning_rate': 0.0003998442262073508, 'epoch': 0.01}         \n",
      "{'loss': 0.8697, 'learning_rate': 0.0003998438729848258, 'epoch': 0.01}         \n",
      "{'loss': 0.8674, 'learning_rate': 0.0003998435193624384, 'epoch': 0.01}         \n",
      "{'loss': 0.8699, 'learning_rate': 0.00039984316534018917, 'epoch': 0.01}        \n",
      "{'loss': 0.8665, 'learning_rate': 0.00039984281091807897, 'epoch': 0.01}        \n",
      "{'loss': 0.864, 'learning_rate': 0.0003998424560961085, 'epoch': 0.01}          \n",
      "{'loss': 0.8672, 'learning_rate': 0.0003998421008742783, 'epoch': 0.01}         \n",
      "{'loss': 0.869, 'learning_rate': 0.0003998417452525893, 'epoch': 0.01}          \n",
      "{'loss': 0.8692, 'learning_rate': 0.00039984138923104205, 'epoch': 0.01}        \n",
      "{'loss': 0.8701, 'learning_rate': 0.00039984103280963734, 'epoch': 0.01}        \n",
      "{'loss': 0.8714, 'learning_rate': 0.0003998406759883759, 'epoch': 0.01}         \n",
      "{'loss': 0.8698, 'learning_rate': 0.0003998403187672584, 'epoch': 0.01}         \n",
      "{'loss': 0.8728, 'learning_rate': 0.00039983996114628553, 'epoch': 0.01}        \n",
      "{'loss': 0.8722, 'learning_rate': 0.0003998396031254581, 'epoch': 0.01}         \n",
      "{'loss': 0.8714, 'learning_rate': 0.0003998392447047767, 'epoch': 0.01}         \n",
      "{'loss': 0.8739, 'learning_rate': 0.0003998388858842422, 'epoch': 0.01}         \n",
      "{'loss': 0.8735, 'learning_rate': 0.0003998385266638551, 'epoch': 0.01}         \n",
      "{'loss': 0.8727, 'learning_rate': 0.00039983816704361637, 'epoch': 0.01}        \n",
      "  1%|▍                               | 4500/351164 [1:08:54<79:19:01,  1.21it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.872, 'learning_rate': 0.00039983780702352657, 'epoch': 0.01}         \n",
      "{'loss': 0.8712, 'learning_rate': 0.00039983744660358647, 'epoch': 0.01}        \n",
      "{'loss': 0.8716, 'learning_rate': 0.0003998370857837968, 'epoch': 0.01}         \n",
      "{'loss': 0.8683, 'learning_rate': 0.0003998367245641583, 'epoch': 0.01}         \n",
      "{'loss': 0.8713, 'learning_rate': 0.0003998363629446716, 'epoch': 0.01}         \n",
      "{'loss': 0.8891, 'learning_rate': 0.00039983600092533743, 'epoch': 0.01}        \n",
      "{'loss': 0.876, 'learning_rate': 0.0003998356385061566, 'epoch': 0.01}          \n",
      "{'loss': 0.8692, 'learning_rate': 0.0003998352756871299, 'epoch': 0.01}         \n",
      "{'loss': 0.8694, 'learning_rate': 0.00039983491246825786, 'epoch': 0.01}        \n",
      "{'loss': 0.8656, 'learning_rate': 0.00039983454884954134, 'epoch': 0.01}        \n",
      "{'loss': 0.868, 'learning_rate': 0.000399834184830981, 'epoch': 0.01}           \n",
      "{'loss': 0.8657, 'learning_rate': 0.00039983382041257765, 'epoch': 0.01}        \n",
      "{'loss': 0.866, 'learning_rate': 0.0003998334555943319, 'epoch': 0.01}          \n",
      "{'loss': 0.8684, 'learning_rate': 0.00039983309037624457, 'epoch': 0.01}        \n",
      "{'loss': 0.8644, 'learning_rate': 0.00039983272475831643, 'epoch': 0.01}        \n",
      "{'loss': 0.8697, 'learning_rate': 0.0003998323587405481, 'epoch': 0.01}         \n",
      "{'loss': 0.868, 'learning_rate': 0.00039983199232294036, 'epoch': 0.01}         \n",
      "{'loss': 0.8759, 'learning_rate': 0.00039983162550549393, 'epoch': 0.01}        \n",
      "{'loss': 0.872, 'learning_rate': 0.0003998312582882096, 'epoch': 0.01}          \n",
      "{'loss': 0.8705, 'learning_rate': 0.00039983089067108804, 'epoch': 0.01}        \n",
      "{'loss': 0.8661, 'learning_rate': 0.0003998305226541301, 'epoch': 0.01}         \n",
      "{'loss': 0.8664, 'learning_rate': 0.0003998301542373363, 'epoch': 0.01}         \n",
      "{'loss': 0.8675, 'learning_rate': 0.00039982978542070757, 'epoch': 0.01}        \n",
      "{'loss': 0.8643, 'learning_rate': 0.0003998294162042446, 'epoch': 0.01}         \n",
      "{'loss': 0.8662, 'learning_rate': 0.0003998290465879481, 'epoch': 0.01}         \n",
      "{'loss': 0.8664, 'learning_rate': 0.0003998286765718188, 'epoch': 0.01}         \n",
      "{'loss': 0.8667, 'learning_rate': 0.0003998283061558574, 'epoch': 0.01}         \n",
      "{'loss': 0.8654, 'learning_rate': 0.0003998279353400648, 'epoch': 0.01}         \n",
      "{'loss': 0.8681, 'learning_rate': 0.0003998275641244416, 'epoch': 0.01}         \n",
      "{'loss': 0.8674, 'learning_rate': 0.0003998271925089886, 'epoch': 0.01}         \n",
      "{'loss': 0.8686, 'learning_rate': 0.0003998268204937065, 'epoch': 0.01}         \n",
      "{'loss': 0.8714, 'learning_rate': 0.00039982644807859614, 'epoch': 0.01}        \n",
      "{'loss': 0.8682, 'learning_rate': 0.00039982607526365814, 'epoch': 0.01}        \n",
      "{'loss': 0.8674, 'learning_rate': 0.00039982570204889333, 'epoch': 0.01}        \n",
      "{'loss': 0.8672, 'learning_rate': 0.0003998253284343024, 'epoch': 0.01}         \n",
      "{'loss': 0.8667, 'learning_rate': 0.0003998249544198862, 'epoch': 0.01}         \n",
      "{'loss': 0.8678, 'learning_rate': 0.00039982458000564536, 'epoch': 0.01}        \n",
      "{'loss': 0.8694, 'learning_rate': 0.0003998242051915807, 'epoch': 0.01}         \n",
      "{'loss': 0.8719, 'learning_rate': 0.00039982382997769296, 'epoch': 0.01}        \n",
      "{'loss': 0.8756, 'learning_rate': 0.00039982345436398285, 'epoch': 0.01}        \n",
      "{'loss': 0.8679, 'learning_rate': 0.0003998230783504511, 'epoch': 0.01}         \n",
      "{'loss': 0.8639, 'learning_rate': 0.0003998227019370986, 'epoch': 0.01}         \n",
      "{'loss': 0.8653, 'learning_rate': 0.00039982232512392597, 'epoch': 0.01}        \n",
      "{'loss': 0.8657, 'learning_rate': 0.00039982194791093406, 'epoch': 0.01}        \n",
      "{'loss': 0.8647, 'learning_rate': 0.0003998215702981235, 'epoch': 0.01}         \n",
      "{'loss': 0.8638, 'learning_rate': 0.0003998211922854951, 'epoch': 0.01}         \n",
      "{'loss': 0.8668, 'learning_rate': 0.00039982081387304974, 'epoch': 0.01}        \n",
      "{'loss': 0.8646, 'learning_rate': 0.000399820435060788, 'epoch': 0.01}          \n",
      "{'loss': 0.8634, 'learning_rate': 0.0003998200558487108, 'epoch': 0.01}         \n",
      "{'loss': 0.8618, 'learning_rate': 0.00039981967623681875, 'epoch': 0.01}        \n",
      "{'loss': 0.8654, 'learning_rate': 0.0003998192962251126, 'epoch': 0.01}         \n",
      "{'loss': 0.8661, 'learning_rate': 0.0003998189158135933, 'epoch': 0.01}         \n",
      "{'loss': 0.863, 'learning_rate': 0.00039981853500226143, 'epoch': 0.01}         \n",
      "{'loss': 0.8668, 'learning_rate': 0.00039981815379111783, 'epoch': 0.01}        \n",
      "{'loss': 0.8633, 'learning_rate': 0.0003998177721801632, 'epoch': 0.01}         \n",
      "{'loss': 0.8628, 'learning_rate': 0.00039981739016939843, 'epoch': 0.01}        \n",
      "{'loss': 0.8682, 'learning_rate': 0.00039981700775882414, 'epoch': 0.01}        \n",
      "{'loss': 0.8655, 'learning_rate': 0.0003998166249484412, 'epoch': 0.01}         \n",
      "{'loss': 0.8646, 'learning_rate': 0.0003998162417382503, 'epoch': 0.01}         \n",
      "{'loss': 0.8627, 'learning_rate': 0.0003998158581282523, 'epoch': 0.01}         \n",
      "{'loss': 0.8701, 'learning_rate': 0.0003998154741184478, 'epoch': 0.01}         \n",
      "{'loss': 0.8791, 'learning_rate': 0.0003998150897088378, 'epoch': 0.01}         \n",
      "{'loss': 0.8722, 'learning_rate': 0.00039981470489942287, 'epoch': 0.01}        \n",
      "{'loss': 0.8696, 'learning_rate': 0.00039981431969020385, 'epoch': 0.01}        \n",
      "{'loss': 0.8674, 'learning_rate': 0.00039981393408118155, 'epoch': 0.01}        \n",
      "{'loss': 0.8667, 'learning_rate': 0.00039981354807235676, 'epoch': 0.01}        \n",
      "{'loss': 0.8642, 'learning_rate': 0.0003998131616637301, 'epoch': 0.01}         \n",
      "{'loss': 0.8648, 'learning_rate': 0.00039981277485530247, 'epoch': 0.01}        \n",
      "{'loss': 0.8624, 'learning_rate': 0.00039981238764707464, 'epoch': 0.01}        \n",
      "{'loss': 0.8682, 'learning_rate': 0.00039981200003904737, 'epoch': 0.01}        \n",
      "{'loss': 0.8656, 'learning_rate': 0.0003998116120312214, 'epoch': 0.01}         \n",
      "{'loss': 0.8641, 'learning_rate': 0.0003998112236235976, 'epoch': 0.01}         \n",
      "{'loss': 0.8661, 'learning_rate': 0.0003998108348161766, 'epoch': 0.01}         \n",
      "{'loss': 0.8638, 'learning_rate': 0.0003998104456089593, 'epoch': 0.01}         \n",
      "{'loss': 0.8648, 'learning_rate': 0.00039981005600194647, 'epoch': 0.01}        \n",
      "{'loss': 0.8597, 'learning_rate': 0.0003998096659951388, 'epoch': 0.01}         \n",
      "{'loss': 0.8608, 'learning_rate': 0.0003998092755885372, 'epoch': 0.01}         \n",
      "{'loss': 0.8597, 'learning_rate': 0.00039980888478214233, 'epoch': 0.01}        \n",
      "{'loss': 0.8614, 'learning_rate': 0.00039980849357595493, 'epoch': 0.01}        \n",
      "{'loss': 0.8632, 'learning_rate': 0.000399808101969976, 'epoch': 0.01}          \n",
      "{'loss': 0.8652, 'learning_rate': 0.0003998077099642062, 'epoch': 0.01}         \n",
      "{'loss': 0.8652, 'learning_rate': 0.0003998073175586463, 'epoch': 0.01}         \n",
      "{'loss': 0.8655, 'learning_rate': 0.00039980692475329705, 'epoch': 0.01}        \n",
      "{'loss': 0.8671, 'learning_rate': 0.00039980653154815933, 'epoch': 0.01}        \n",
      "{'loss': 0.8677, 'learning_rate': 0.0003998061379432339, 'epoch': 0.01}         \n",
      "{'loss': 0.8655, 'learning_rate': 0.00039980574393852145, 'epoch': 0.01}        \n",
      "{'loss': 0.8651, 'learning_rate': 0.0003998053495340229, 'epoch': 0.01}         \n",
      "{'loss': 0.8632, 'learning_rate': 0.000399804954729739, 'epoch': 0.01}          \n",
      "{'loss': 0.866, 'learning_rate': 0.0003998045595256705, 'epoch': 0.01}          \n",
      "{'loss': 0.8659, 'learning_rate': 0.0003998041639218182, 'epoch': 0.01}         \n",
      "{'loss': 0.8649, 'learning_rate': 0.00039980376791818293, 'epoch': 0.01}        \n",
      "{'loss': 0.8623, 'learning_rate': 0.00039980337151476546, 'epoch': 0.01}        \n",
      "{'loss': 0.8634, 'learning_rate': 0.00039980297471156655, 'epoch': 0.01}        \n",
      "{'loss': 0.8641, 'learning_rate': 0.00039980257750858706, 'epoch': 0.01}        \n",
      "{'loss': 0.8647, 'learning_rate': 0.0003998021799058277, 'epoch': 0.01}         \n",
      "{'loss': 0.8663, 'learning_rate': 0.00039980178190328943, 'epoch': 0.01}        \n",
      "{'loss': 0.8613, 'learning_rate': 0.00039980138350097287, 'epoch': 0.01}        \n",
      "{'loss': 0.862, 'learning_rate': 0.0003998009846988788, 'epoch': 0.01}          \n",
      "{'loss': 0.8624, 'learning_rate': 0.00039980058549700826, 'epoch': 0.01}        \n",
      "{'loss': 0.8616, 'learning_rate': 0.0003998001858953618, 'epoch': 0.01}         \n",
      "  1%|▍                               | 5000/351164 [1:15:59<79:38:04,  1.21it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8636, 'learning_rate': 0.0003997997858939403, 'epoch': 0.01}         \n",
      "{'loss': 0.8619, 'learning_rate': 0.00039979938549274455, 'epoch': 0.01}        \n",
      "{'loss': 0.8613, 'learning_rate': 0.0003997989846917754, 'epoch': 0.01}         \n",
      "{'loss': 0.864, 'learning_rate': 0.00039979858349103363, 'epoch': 0.01}         \n",
      "{'loss': 0.861, 'learning_rate': 0.00039979818189052, 'epoch': 0.01}            \n",
      "{'loss': 0.8745, 'learning_rate': 0.00039979777989023537, 'epoch': 0.01}        \n",
      "{'loss': 0.8655, 'learning_rate': 0.0003997973774901806, 'epoch': 0.01}         \n",
      "{'loss': 0.8632, 'learning_rate': 0.0003997969746903563, 'epoch': 0.01}         \n",
      "{'loss': 0.8678, 'learning_rate': 0.00039979657149076346, 'epoch': 0.01}        \n",
      "{'loss': 0.8694, 'learning_rate': 0.00039979616789140277, 'epoch': 0.01}        \n",
      "{'loss': 0.8702, 'learning_rate': 0.0003997957638922751, 'epoch': 0.01}         \n",
      "{'loss': 0.8639, 'learning_rate': 0.00039979535949338123, 'epoch': 0.01}        \n",
      "{'loss': 0.8651, 'learning_rate': 0.000399794954694722, 'epoch': 0.01}          \n",
      "{'loss': 0.8642, 'learning_rate': 0.00039979454949629826, 'epoch': 0.01}        \n",
      "{'loss': 0.8637, 'learning_rate': 0.00039979414389811074, 'epoch': 0.01}        \n",
      "{'loss': 0.8612, 'learning_rate': 0.0003997937379001602, 'epoch': 0.01}         \n",
      "{'loss': 0.8654, 'learning_rate': 0.00039979333150244763, 'epoch': 0.01}        \n",
      "{'loss': 0.8627, 'learning_rate': 0.00039979292470497367, 'epoch': 0.01}        \n",
      "{'loss': 0.8623, 'learning_rate': 0.00039979251750773924, 'epoch': 0.01}        \n",
      "{'loss': 0.8593, 'learning_rate': 0.0003997921099107451, 'epoch': 0.01}         \n",
      "{'loss': 0.8622, 'learning_rate': 0.00039979170191399213, 'epoch': 0.01}        \n",
      "{'loss': 0.8637, 'learning_rate': 0.0003997912935174811, 'epoch': 0.01}         \n",
      "{'loss': 0.864, 'learning_rate': 0.00039979088472121276, 'epoch': 0.01}         \n",
      "{'loss': 0.8611, 'learning_rate': 0.00039979047552518804, 'epoch': 0.01}        \n",
      "{'loss': 0.8593, 'learning_rate': 0.0003997900659294077, 'epoch': 0.01}         \n",
      "{'loss': 0.8594, 'learning_rate': 0.0003997896559338726, 'epoch': 0.01}         \n",
      "{'loss': 0.8623, 'learning_rate': 0.0003997892455385835, 'epoch': 0.01}         \n",
      "{'loss': 0.8595, 'learning_rate': 0.00039978883474354137, 'epoch': 0.01}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.0003997884235487468, 'epoch': 0.01}         \n",
      "{'loss': 0.865, 'learning_rate': 0.0003997880119542008, 'epoch': 0.01}          \n",
      "{'loss': 0.8616, 'learning_rate': 0.00039978759995990405, 'epoch': 0.01}        \n",
      "{'loss': 0.8655, 'learning_rate': 0.0003997871875658575, 'epoch': 0.01}         \n",
      "{'loss': 0.8629, 'learning_rate': 0.00039978677477206195, 'epoch': 0.01}        \n",
      "{'loss': 0.8627, 'learning_rate': 0.00039978636157851817, 'epoch': 0.01}        \n",
      "{'loss': 0.8621, 'learning_rate': 0.00039978594798522704, 'epoch': 0.01}        \n",
      "{'loss': 0.8599, 'learning_rate': 0.0003997855339921893, 'epoch': 0.01}         \n",
      "{'loss': 0.8604, 'learning_rate': 0.0003997851195994059, 'epoch': 0.01}         \n",
      "{'loss': 0.8616, 'learning_rate': 0.0003997847048068776, 'epoch': 0.01}         \n",
      "{'loss': 0.8636, 'learning_rate': 0.0003997842896146053, 'epoch': 0.01}         \n",
      "{'loss': 0.8639, 'learning_rate': 0.00039978387402258967, 'epoch': 0.01}        \n",
      "{'loss': 0.8639, 'learning_rate': 0.0003997834580308317, 'epoch': 0.01}         \n",
      "{'loss': 0.8616, 'learning_rate': 0.00039978304163933214, 'epoch': 0.01}        \n",
      "{'loss': 0.8634, 'learning_rate': 0.0003997826248480919, 'epoch': 0.01}         \n",
      "{'loss': 0.867, 'learning_rate': 0.0003997822076571117, 'epoch': 0.01}          \n",
      "{'loss': 0.8693, 'learning_rate': 0.00039978179006639256, 'epoch': 0.01}        \n",
      "{'loss': 0.8654, 'learning_rate': 0.0003997813720759351, 'epoch': 0.01}         \n",
      "{'loss': 0.8627, 'learning_rate': 0.00039978095368574027, 'epoch': 0.01}        \n",
      "{'loss': 0.8604, 'learning_rate': 0.0003997805348958088, 'epoch': 0.01}         \n",
      "{'loss': 0.8586, 'learning_rate': 0.00039978011570614174, 'epoch': 0.01}        \n",
      "{'loss': 0.8597, 'learning_rate': 0.0003997796961167398, 'epoch': 0.01}         \n",
      "{'loss': 0.8601, 'learning_rate': 0.00039977927612760376, 'epoch': 0.01}        \n",
      "{'loss': 0.8594, 'learning_rate': 0.0003997788557387346, 'epoch': 0.01}         \n",
      "{'loss': 0.8604, 'learning_rate': 0.00039977843495013303, 'epoch': 0.01}        \n",
      "{'loss': 0.862, 'learning_rate': 0.00039977801376179996, 'epoch': 0.02}         \n",
      "{'loss': 0.8593, 'learning_rate': 0.0003997775921737362, 'epoch': 0.02}         \n",
      "{'loss': 0.861, 'learning_rate': 0.0003997771701859426, 'epoch': 0.02}          \n",
      "{'loss': 0.8617, 'learning_rate': 0.0003997767477984201, 'epoch': 0.02}         \n",
      "{'loss': 0.8623, 'learning_rate': 0.0003997763250111694, 'epoch': 0.02}         \n",
      "{'loss': 0.8662, 'learning_rate': 0.00039977590182419144, 'epoch': 0.02}        \n",
      "{'loss': 0.8638, 'learning_rate': 0.00039977547823748705, 'epoch': 0.02}        \n",
      "{'loss': 0.8639, 'learning_rate': 0.000399775054251057, 'epoch': 0.02}          \n",
      "{'loss': 0.863, 'learning_rate': 0.00039977462986490224, 'epoch': 0.02}         \n",
      "{'loss': 0.862, 'learning_rate': 0.00039977420507902357, 'epoch': 0.02}         \n",
      "{'loss': 0.8626, 'learning_rate': 0.00039977377989342195, 'epoch': 0.02}        \n",
      "{'loss': 0.8739, 'learning_rate': 0.000399773354308098, 'epoch': 0.02}          \n",
      "{'loss': 0.8692, 'learning_rate': 0.00039977292832305277, 'epoch': 0.02}        \n",
      "{'loss': 0.8643, 'learning_rate': 0.000399772501938287, 'epoch': 0.02}          \n",
      "{'loss': 0.8593, 'learning_rate': 0.0003997720751538016, 'epoch': 0.02}         \n",
      "{'loss': 0.8607, 'learning_rate': 0.00039977164796959746, 'epoch': 0.02}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.00039977122038567536, 'epoch': 0.02}        \n",
      "{'loss': 0.8604, 'learning_rate': 0.00039977079240203616, 'epoch': 0.02}        \n",
      "{'loss': 0.8587, 'learning_rate': 0.00039977036401868084, 'epoch': 0.02}        \n",
      "{'loss': 0.8596, 'learning_rate': 0.00039976993523561005, 'epoch': 0.02}        \n",
      "{'loss': 0.8599, 'learning_rate': 0.00039976950605282477, 'epoch': 0.02}        \n",
      "{'loss': 0.8595, 'learning_rate': 0.00039976907647032585, 'epoch': 0.02}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.0003997686464881142, 'epoch': 0.02}         \n",
      "{'loss': 0.8585, 'learning_rate': 0.00039976821610619056, 'epoch': 0.02}        \n",
      "{'loss': 0.8582, 'learning_rate': 0.00039976778532455586, 'epoch': 0.02}        \n",
      "{'loss': 0.859, 'learning_rate': 0.000399767354143211, 'epoch': 0.02}           \n",
      "{'loss': 0.8544, 'learning_rate': 0.00039976692256215674, 'epoch': 0.02}        \n",
      "{'loss': 0.8565, 'learning_rate': 0.00039976649058139405, 'epoch': 0.02}        \n",
      "{'loss': 0.8565, 'learning_rate': 0.0003997660582009237, 'epoch': 0.02}         \n",
      "{'loss': 0.8576, 'learning_rate': 0.0003997656254207467, 'epoch': 0.02}         \n",
      "{'loss': 0.8595, 'learning_rate': 0.0003997651922408637, 'epoch': 0.02}         \n",
      "{'loss': 0.8589, 'learning_rate': 0.0003997647586612757, 'epoch': 0.02}         \n",
      "{'loss': 0.8593, 'learning_rate': 0.00039976432468198365, 'epoch': 0.02}        \n",
      "{'loss': 0.8574, 'learning_rate': 0.00039976389030298826, 'epoch': 0.02}        \n",
      "{'loss': 0.8587, 'learning_rate': 0.00039976345552429046, 'epoch': 0.02}        \n",
      "{'loss': 0.8603, 'learning_rate': 0.0003997630203458911, 'epoch': 0.02}         \n",
      "{'loss': 0.8589, 'learning_rate': 0.0003997625847677911, 'epoch': 0.02}         \n",
      "{'loss': 0.858, 'learning_rate': 0.0003997621487899913, 'epoch': 0.02}          \n",
      "{'loss': 0.8559, 'learning_rate': 0.00039976171241249255, 'epoch': 0.02}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.0003997612756352958, 'epoch': 0.02}         \n",
      "{'loss': 0.8602, 'learning_rate': 0.0003997608384584018, 'epoch': 0.02}         \n",
      "{'loss': 0.8584, 'learning_rate': 0.00039976040088181156, 'epoch': 0.02}        \n",
      "{'loss': 0.8611, 'learning_rate': 0.0003997599629055259, 'epoch': 0.02}         \n",
      "{'loss': 0.8627, 'learning_rate': 0.0003997595245295457, 'epoch': 0.02}         \n",
      "{'loss': 0.8621, 'learning_rate': 0.00039975908575387174, 'epoch': 0.02}        \n",
      "{'loss': 0.8603, 'learning_rate': 0.000399758646578505, 'epoch': 0.02}          \n",
      "{'loss': 0.8588, 'learning_rate': 0.0003997582070034464, 'epoch': 0.02}         \n",
      "  2%|▌                               | 5500/351164 [1:23:06<78:08:14,  1.23it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8602, 'learning_rate': 0.00039975776702869673, 'epoch': 0.02}        \n",
      "{'loss': 0.8585, 'learning_rate': 0.00039975732665425685, 'epoch': 0.02}        \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039975688588012774, 'epoch': 0.02}        \n",
      "{'loss': 0.8605, 'learning_rate': 0.00039975644470631027, 'epoch': 0.02}        \n",
      "{'loss': 0.8615, 'learning_rate': 0.00039975600313280524, 'epoch': 0.02}        \n",
      "{'loss': 0.8607, 'learning_rate': 0.00039975556115961363, 'epoch': 0.02}        \n",
      "{'loss': 0.8618, 'learning_rate': 0.00039975511878673626, 'epoch': 0.02}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.000399754676014174, 'epoch': 0.02}          \n",
      "{'loss': 0.8583, 'learning_rate': 0.0003997542328419278, 'epoch': 0.02}         \n",
      "{'loss': 0.8583, 'learning_rate': 0.00039975378926999846, 'epoch': 0.02}        \n",
      "{'loss': 0.8611, 'learning_rate': 0.000399753345298387, 'epoch': 0.02}          \n",
      "{'loss': 0.8631, 'learning_rate': 0.0003997529009270942, 'epoch': 0.02}         \n",
      "{'loss': 0.8626, 'learning_rate': 0.000399752456156121, 'epoch': 0.02}          \n",
      "{'loss': 0.8585, 'learning_rate': 0.0003997520109854682, 'epoch': 0.02}         \n",
      "{'loss': 0.8604, 'learning_rate': 0.0003997515654151368, 'epoch': 0.02}         \n",
      "{'loss': 0.8597, 'learning_rate': 0.0003997511194451276, 'epoch': 0.02}         \n",
      "{'loss': 0.8602, 'learning_rate': 0.0003997506730754416, 'epoch': 0.02}         \n",
      "{'loss': 0.8627, 'learning_rate': 0.00039975022630607966, 'epoch': 0.02}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.0003997497791370426, 'epoch': 0.02}         \n",
      "{'loss': 0.8586, 'learning_rate': 0.0003997493315683314, 'epoch': 0.02}         \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039974888359994685, 'epoch': 0.02}        \n",
      "{'loss': 0.8595, 'learning_rate': 0.00039974843523189, 'epoch': 0.02}           \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039974798646416165, 'epoch': 0.02}        \n",
      "{'loss': 0.8589, 'learning_rate': 0.0003997475372967627, 'epoch': 0.02}         \n",
      "{'loss': 0.8633, 'learning_rate': 0.00039974708772969405, 'epoch': 0.02}        \n",
      "{'loss': 0.8604, 'learning_rate': 0.0003997466377629566, 'epoch': 0.02}         \n",
      "{'loss': 0.8596, 'learning_rate': 0.00039974618739655127, 'epoch': 0.02}        \n",
      "{'loss': 0.8628, 'learning_rate': 0.00039974573663047896, 'epoch': 0.02}        \n",
      "{'loss': 0.8578, 'learning_rate': 0.00039974528546474057, 'epoch': 0.02}        \n",
      "{'loss': 0.859, 'learning_rate': 0.000399744833899337, 'epoch': 0.02}           \n",
      "{'loss': 0.8582, 'learning_rate': 0.00039974438193426915, 'epoch': 0.02}        \n",
      "{'loss': 0.8579, 'learning_rate': 0.0003997439295695379, 'epoch': 0.02}         \n",
      "{'loss': 0.8573, 'learning_rate': 0.0003997434768051442, 'epoch': 0.02}         \n",
      "{'loss': 0.8577, 'learning_rate': 0.0003997430236410889, 'epoch': 0.02}         \n",
      "{'loss': 0.859, 'learning_rate': 0.00039974257007737297, 'epoch': 0.02}         \n",
      "{'loss': 0.8588, 'learning_rate': 0.0003997421161139973, 'epoch': 0.02}         \n",
      "{'loss': 0.8577, 'learning_rate': 0.0003997416617509628, 'epoch': 0.02}         \n",
      "{'loss': 0.8579, 'learning_rate': 0.00039974120698827033, 'epoch': 0.02}        \n",
      "{'loss': 0.8614, 'learning_rate': 0.0003997407518259208, 'epoch': 0.02}         \n",
      "{'loss': 0.8612, 'learning_rate': 0.00039974029626391525, 'epoch': 0.02}        \n",
      "{'loss': 0.861, 'learning_rate': 0.00039973984030225446, 'epoch': 0.02}         \n",
      "{'loss': 0.8632, 'learning_rate': 0.00039973938394093935, 'epoch': 0.02}        \n",
      "{'loss': 0.8588, 'learning_rate': 0.00039973892717997094, 'epoch': 0.02}        \n",
      "{'loss': 0.8567, 'learning_rate': 0.00039973847001935, 'epoch': 0.02}           \n",
      "{'loss': 0.861, 'learning_rate': 0.0003997380124590775, 'epoch': 0.02}          \n",
      "{'loss': 0.857, 'learning_rate': 0.00039973755449915444, 'epoch': 0.02}         \n",
      "{'loss': 0.8588, 'learning_rate': 0.0003997370961395816, 'epoch': 0.02}         \n",
      "{'loss': 0.8578, 'learning_rate': 0.00039973663738035995, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.0003997361782214905, 'epoch': 0.02}          \n",
      "{'loss': 0.8556, 'learning_rate': 0.00039973571866297404, 'epoch': 0.02}        \n",
      "{'loss': 0.8579, 'learning_rate': 0.00039973525870481155, 'epoch': 0.02}        \n",
      "{'loss': 0.8585, 'learning_rate': 0.00039973479834700396, 'epoch': 0.02}        \n",
      "{'loss': 0.8561, 'learning_rate': 0.0003997343375895521, 'epoch': 0.02}         \n",
      "{'loss': 0.8577, 'learning_rate': 0.00039973387643245703, 'epoch': 0.02}        \n",
      "{'loss': 0.8562, 'learning_rate': 0.00039973341487571954, 'epoch': 0.02}        \n",
      "{'loss': 0.8574, 'learning_rate': 0.00039973295291934074, 'epoch': 0.02}        \n",
      "{'loss': 0.8582, 'learning_rate': 0.0003997324905633213, 'epoch': 0.02}         \n",
      "{'loss': 0.8583, 'learning_rate': 0.00039973202780766234, 'epoch': 0.02}        \n",
      "{'loss': 0.856, 'learning_rate': 0.0003997315646523647, 'epoch': 0.02}          \n",
      "{'loss': 0.855, 'learning_rate': 0.0003997311010974294, 'epoch': 0.02}          \n",
      "{'loss': 0.8571, 'learning_rate': 0.0003997306371428572, 'epoch': 0.02}         \n",
      "{'loss': 0.8573, 'learning_rate': 0.0003997301727886491, 'epoch': 0.02}         \n",
      "{'loss': 0.8597, 'learning_rate': 0.0003997297080348061, 'epoch': 0.02}         \n",
      "{'loss': 0.862, 'learning_rate': 0.0003997292428813292, 'epoch': 0.02}          \n",
      "{'loss': 0.8613, 'learning_rate': 0.00039972877732821906, 'epoch': 0.02}        \n",
      "{'loss': 0.8607, 'learning_rate': 0.00039972831137547685, 'epoch': 0.02}        \n",
      "{'loss': 0.8638, 'learning_rate': 0.00039972784502310336, 'epoch': 0.02}        \n",
      "{'loss': 0.8611, 'learning_rate': 0.00039972737827109967, 'epoch': 0.02}        \n",
      "{'loss': 0.8635, 'learning_rate': 0.00039972691111946654, 'epoch': 0.02}        \n",
      "{'loss': 0.859, 'learning_rate': 0.000399726443568205, 'epoch': 0.02}           \n",
      "{'loss': 0.8574, 'learning_rate': 0.000399725975617316, 'epoch': 0.02}          \n",
      "{'loss': 0.8574, 'learning_rate': 0.0003997255072668005, 'epoch': 0.02}         \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039972503851665934, 'epoch': 0.02}        \n",
      "{'loss': 0.8581, 'learning_rate': 0.0003997245693668935, 'epoch': 0.02}         \n",
      "{'loss': 0.857, 'learning_rate': 0.00039972409981750394, 'epoch': 0.02}         \n",
      "{'loss': 0.8587, 'learning_rate': 0.00039972362986849156, 'epoch': 0.02}        \n",
      "{'loss': 0.8572, 'learning_rate': 0.00039972315951985733, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.00039972268877160223, 'epoch': 0.02}         \n",
      "{'loss': 0.8589, 'learning_rate': 0.0003997222176237271, 'epoch': 0.02}         \n",
      "{'loss': 0.857, 'learning_rate': 0.00039972174607623304, 'epoch': 0.02}         \n",
      "{'loss': 0.8563, 'learning_rate': 0.00039972127412912084, 'epoch': 0.02}        \n",
      "{'loss': 0.8566, 'learning_rate': 0.00039972080178239146, 'epoch': 0.02}        \n",
      "{'loss': 0.857, 'learning_rate': 0.0003997203290360459, 'epoch': 0.02}          \n",
      "{'loss': 0.857, 'learning_rate': 0.00039971985589008514, 'epoch': 0.02}         \n",
      "{'loss': 0.8556, 'learning_rate': 0.00039971938234451004, 'epoch': 0.02}        \n",
      "{'loss': 0.8618, 'learning_rate': 0.00039971890839932155, 'epoch': 0.02}        \n",
      "{'loss': 0.856, 'learning_rate': 0.0003997184340545207, 'epoch': 0.02}          \n",
      "{'loss': 0.857, 'learning_rate': 0.00039971795931010846, 'epoch': 0.02}         \n",
      "{'loss': 0.8566, 'learning_rate': 0.0003997174841660856, 'epoch': 0.02}         \n",
      "{'loss': 0.8547, 'learning_rate': 0.00039971700862245324, 'epoch': 0.02}        \n",
      "{'loss': 0.8559, 'learning_rate': 0.00039971653267921226, 'epoch': 0.02}        \n",
      "{'loss': 0.8536, 'learning_rate': 0.00039971605633636357, 'epoch': 0.02}        \n",
      "{'loss': 0.8571, 'learning_rate': 0.0003997155795939083, 'epoch': 0.02}         \n",
      "{'loss': 0.8555, 'learning_rate': 0.0003997151024518472, 'epoch': 0.02}         \n",
      "{'loss': 0.8568, 'learning_rate': 0.00039971462491018134, 'epoch': 0.02}        \n",
      "{'loss': 0.8556, 'learning_rate': 0.0003997141469689116, 'epoch': 0.02}         \n",
      "{'loss': 0.8557, 'learning_rate': 0.000399713668628039, 'epoch': 0.02}          \n",
      "{'loss': 0.856, 'learning_rate': 0.00039971318988756455, 'epoch': 0.02}         \n",
      "{'loss': 0.8576, 'learning_rate': 0.00039971271074748906, 'epoch': 0.02}        \n",
      "{'loss': 0.8594, 'learning_rate': 0.0003997122312078136, 'epoch': 0.02}         \n",
      "  2%|▌                               | 6000/351164 [1:30:13<79:36:20,  1.20it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<01:00,  2.31it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:18,  1.75it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:28,  1.55it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:34,  1.44it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:03<01:37,  1.38it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:04<01:40,  1.33it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:05<01:42,  1.30it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:45,  1.26it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:46,  1.23it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:42,  1.26it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:08<01:44,  1.24it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:09<01:47,  1.19it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:10<01:45,  1.20it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:11<01:41,  1.24it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:44,  1.20it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:46,  1.17it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:47,  1.14it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:14<01:46,  1.14it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:15<01:43,  1.17it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:16<01:46,  1.12it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:17<01:43,  1.15it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:18<01:42,  1.15it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:19<01:41,  1.16it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:39,  1.17it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:20<01:39,  1.16it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:21<01:42,  1.12it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:22<01:39,  1.14it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:23<01:34,  1.18it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:24<01:35,  1.17it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:29,  1.23it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:26<01:31,  1.19it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:27<01:34,  1.14it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:28<01:41,  1.05it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:29<01:38,  1.08it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:29<01:38,  1.07it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:30<01:33,  1.11it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:31<01:28,  1.16it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:32<01:34,  1.07it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:33<01:31,  1.10it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:34<01:28,  1.13it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:35<01:28,  1.12it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:36<01:28,  1.10it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:37<01:27,  1.11it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:37<01:23,  1.14it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:38<01:24,  1.13it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:39<01:20,  1.17it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:40<01:16,  1.21it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:41<01:17,  1.19it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:42<01:15,  1.20it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:42<01:13,  1.22it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:43<01:14,  1.19it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:44<01:13,  1.19it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:45<01:11,  1.21it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:46<01:10,  1.22it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:46<01:10,  1.21it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:47<01:09,  1.21it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:48<01:09,  1.19it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:49<01:06,  1.23it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:50<01:04,  1.26it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:51<01:04,  1.25it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:51<01:04,  1.23it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:52<01:02,  1.24it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:53<01:02,  1.22it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:54<01:01,  1.23it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:55<01:03,  1.19it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:56<01:06,  1.12it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:57<01:03,  1.16it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:57<01:01,  1.17it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:58<01:00,  1.18it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [00:59<00:59,  1.17it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:00<00:56,  1.22it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:01<00:54,  1.24it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:01<00:54,  1.23it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:02<00:55,  1.19it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:03<00:52,  1.24it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:04<00:53,  1.20it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:05<00:55,  1.13it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:06<00:54,  1.14it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:07<00:53,  1.14it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:07<00:51,  1.16it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:08<00:51,  1.14it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:09<00:50,  1.16it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:10<00:50,  1.13it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:11<00:49,  1.14it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:12<00:48,  1.14it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:13<00:46,  1.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:14<00:45,  1.16it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:14<00:43,  1.20it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:15<00:42,  1.19it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:16<00:41,  1.21it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:17<00:40,  1.22it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:18<00:40,  1.19it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:18<00:38,  1.22it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:19<00:38,  1.19it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:20<00:37,  1.21it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:21<00:37,  1.19it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:22<00:34,  1.23it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:23<00:34,  1.21it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:23<00:33,  1.23it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:24<00:33,  1.21it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:25<00:33,  1.18it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:26<00:32,  1.18it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:27<00:31,  1.16it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:28<00:30,  1.19it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:29<00:29,  1.18it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:29<00:28,  1.19it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:30<00:28,  1.16it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:31<00:29,  1.10it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:32<00:27,  1.14it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:33<00:25,  1.17it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:34<00:24,  1.19it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:35<00:23,  1.20it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:35<00:22,  1.19it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:36<00:22,  1.17it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:37<00:21,  1.18it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:38<00:20,  1.18it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:39<00:19,  1.19it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:40<00:18,  1.22it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:40<00:17,  1.20it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:41<00:16,  1.19it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:42<00:16,  1.19it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:43<00:15,  1.18it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:44<00:13,  1.23it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:45<00:13,  1.22it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:45<00:12,  1.18it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:46<00:11,  1.20it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:47<00:11,  1.17it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:48<00:10,  1.16it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:49<00:09,  1.20it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:50<00:08,  1.15it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:51<00:07,  1.13it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:52<00:07,  1.12it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:52<00:06,  1.14it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:53<00:05,  1.16it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:54<00:04,  1.18it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:55<00:03,  1.19it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:56<00:02,  1.18it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:57<00:01,  1.15it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:57<00:00,  1.19it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [01:58<00:00,  1.17it/s]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8529885411262512, 'eval_cer': 0.03366160124577136, 'eval_runtime': 126.756, 'eval_samples_per_second': 70.932, 'eval_steps_per_second': 1.112, 'epoch': 0.02}\n",
      "  2%|▌                               | 6000/351164 [1:32:20<79:36:20,  1.20it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [01:59<00:00,  1.17it/s]\u001b[A\n",
      "                                                                                \u001b[ACheckpoint destination directory models/checkpoint-6000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.855, 'learning_rate': 0.00039971175126853905, 'epoch': 0.02}         \n",
      "{'loss': 0.8563, 'learning_rate': 0.0003997112709296665, 'epoch': 0.02}         \n",
      "{'loss': 0.856, 'learning_rate': 0.0003997107901911967, 'epoch': 0.02}          \n",
      "{'loss': 0.8558, 'learning_rate': 0.0003997103090531308, 'epoch': 0.02}         \n",
      "{'loss': 0.8562, 'learning_rate': 0.0003997098275154697, 'epoch': 0.02}         \n",
      "{'loss': 0.857, 'learning_rate': 0.00039970934557821436, 'epoch': 0.02}         \n",
      "{'loss': 0.8569, 'learning_rate': 0.0003997088632413658, 'epoch': 0.02}         \n",
      "{'loss': 0.8586, 'learning_rate': 0.00039970838050492485, 'epoch': 0.02}        \n",
      "{'loss': 0.8632, 'learning_rate': 0.00039970789736889264, 'epoch': 0.02}        \n",
      "{'loss': 0.8638, 'learning_rate': 0.00039970741383326997, 'epoch': 0.02}        \n",
      "{'loss': 0.8605, 'learning_rate': 0.0003997069298980579, 'epoch': 0.02}         \n",
      "{'loss': 0.8604, 'learning_rate': 0.00039970644556325746, 'epoch': 0.02}        \n",
      "{'loss': 0.8592, 'learning_rate': 0.00039970596082886947, 'epoch': 0.02}        \n",
      "{'loss': 0.8588, 'learning_rate': 0.000399705475694895, 'epoch': 0.02}          \n",
      "{'loss': 0.8565, 'learning_rate': 0.0003997049901613351, 'epoch': 0.02}         \n",
      "{'loss': 0.8605, 'learning_rate': 0.0003997045042281905, 'epoch': 0.02}         \n",
      "{'loss': 0.8595, 'learning_rate': 0.00039970401789546237, 'epoch': 0.02}        \n",
      "{'loss': 0.8575, 'learning_rate': 0.00039970353116315166, 'epoch': 0.02}        \n",
      "{'loss': 0.8589, 'learning_rate': 0.0003997030440312593, 'epoch': 0.02}         \n",
      "{'loss': 0.8575, 'learning_rate': 0.0003997025564997863, 'epoch': 0.02}         \n",
      "{'loss': 0.8574, 'learning_rate': 0.0003997020685687336, 'epoch': 0.02}         \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039970158023810206, 'epoch': 0.02}        \n",
      "{'loss': 0.8608, 'learning_rate': 0.0003997010915078929, 'epoch': 0.02}         \n",
      "{'loss': 0.8563, 'learning_rate': 0.000399700602378107, 'epoch': 0.02}          \n",
      "{'loss': 0.8581, 'learning_rate': 0.0003997001128487453, 'epoch': 0.02}         \n",
      "{'loss': 0.8558, 'learning_rate': 0.0003996996229198088, 'epoch': 0.02}         \n",
      "{'loss': 0.8565, 'learning_rate': 0.00039969913259129845, 'epoch': 0.02}        \n",
      "{'loss': 0.856, 'learning_rate': 0.0003996986418632153, 'epoch': 0.02}          \n",
      "{'loss': 0.8565, 'learning_rate': 0.0003996981507355603, 'epoch': 0.02}         \n",
      "{'loss': 0.8543, 'learning_rate': 0.00039969765920833437, 'epoch': 0.02}        \n",
      "{'loss': 0.8536, 'learning_rate': 0.00039969716728153863, 'epoch': 0.02}        \n",
      "{'loss': 0.8515, 'learning_rate': 0.00039969667495517384, 'epoch': 0.02}        \n",
      "{'loss': 0.8543, 'learning_rate': 0.0003996961822292413, 'epoch': 0.02}         \n",
      "{'loss': 0.8577, 'learning_rate': 0.0003996956891037417, 'epoch': 0.02}         \n",
      "{'loss': 0.8551, 'learning_rate': 0.00039969519557867623, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.0003996947016540458, 'epoch': 0.02}          \n",
      "{'loss': 0.8546, 'learning_rate': 0.0003996942073298514, 'epoch': 0.02}         \n",
      "{'loss': 0.8544, 'learning_rate': 0.00039969371260609394, 'epoch': 0.02}        \n",
      "{'loss': 0.8557, 'learning_rate': 0.00039969321748277453, 'epoch': 0.02}        \n",
      "{'loss': 0.8548, 'learning_rate': 0.00039969272195989415, 'epoch': 0.02}        \n",
      "{'loss': 0.8546, 'learning_rate': 0.0003996922260374538, 'epoch': 0.02}         \n",
      "{'loss': 0.856, 'learning_rate': 0.0003996917297154544, 'epoch': 0.02}          \n",
      "{'loss': 0.8564, 'learning_rate': 0.0003996912329938969, 'epoch': 0.02}         \n",
      "{'loss': 0.8581, 'learning_rate': 0.0003996907358727824, 'epoch': 0.02}         \n",
      "{'loss': 0.855, 'learning_rate': 0.0003996902383521119, 'epoch': 0.02}          \n",
      "{'loss': 0.8538, 'learning_rate': 0.0003996897404318863, 'epoch': 0.02}         \n",
      "{'loss': 0.8554, 'learning_rate': 0.0003996892421121067, 'epoch': 0.02}         \n",
      "{'loss': 0.8572, 'learning_rate': 0.00039968874339277403, 'epoch': 0.02}        \n",
      "{'loss': 0.8602, 'learning_rate': 0.0003996882442738893, 'epoch': 0.02}         \n",
      "{'loss': 0.8652, 'learning_rate': 0.00039968774475545357, 'epoch': 0.02}        \n",
      "{'loss': 0.8607, 'learning_rate': 0.00039968724483746776, 'epoch': 0.02}        \n",
      "{'loss': 0.8574, 'learning_rate': 0.0003996867445199329, 'epoch': 0.02}         \n",
      "{'loss': 0.8545, 'learning_rate': 0.00039968624380285, 'epoch': 0.02}           \n",
      "{'loss': 0.8526, 'learning_rate': 0.00039968574268622, 'epoch': 0.02}           \n",
      "{'loss': 0.8548, 'learning_rate': 0.000399685241170044, 'epoch': 0.02}          \n",
      "{'loss': 0.8534, 'learning_rate': 0.00039968473925432294, 'epoch': 0.02}        \n",
      "{'loss': 0.8522, 'learning_rate': 0.00039968423693905787, 'epoch': 0.02}        \n",
      "{'loss': 0.8556, 'learning_rate': 0.0003996837342242497, 'epoch': 0.02}         \n",
      "{'loss': 0.8549, 'learning_rate': 0.0003996832311098996, 'epoch': 0.02}         \n",
      "{'loss': 0.8562, 'learning_rate': 0.0003996827275960084, 'epoch': 0.02}         \n",
      "{'loss': 0.8533, 'learning_rate': 0.00039968222368257723, 'epoch': 0.02}        \n",
      "{'loss': 0.8547, 'learning_rate': 0.00039968171936960705, 'epoch': 0.02}        \n",
      "{'loss': 0.8523, 'learning_rate': 0.0003996812146570989, 'epoch': 0.02}         \n",
      "{'loss': 0.8535, 'learning_rate': 0.0003996807095450537, 'epoch': 0.02}         \n",
      "{'loss': 0.8526, 'learning_rate': 0.00039968020403347254, 'epoch': 0.02}        \n",
      "{'loss': 0.8549, 'learning_rate': 0.0003996796981223564, 'epoch': 0.02}         \n",
      "{'loss': 0.8534, 'learning_rate': 0.00039967919181170634, 'epoch': 0.02}        \n",
      "{'loss': 0.8506, 'learning_rate': 0.00039967868510152335, 'epoch': 0.02}        \n",
      "{'loss': 0.8529, 'learning_rate': 0.00039967817799180846, 'epoch': 0.02}        \n",
      "{'loss': 0.8507, 'learning_rate': 0.0003996776704825626, 'epoch': 0.02}         \n",
      "{'loss': 0.8545, 'learning_rate': 0.0003996771625737869, 'epoch': 0.02}         \n",
      "{'loss': 0.8551, 'learning_rate': 0.00039967665426548225, 'epoch': 0.02}        \n",
      "{'loss': 0.8567, 'learning_rate': 0.00039967614555764977, 'epoch': 0.02}        \n",
      "{'loss': 0.8541, 'learning_rate': 0.00039967563645029047, 'epoch': 0.02}        \n",
      "{'loss': 0.8579, 'learning_rate': 0.00039967512694340533, 'epoch': 0.02}        \n",
      "{'loss': 0.8677, 'learning_rate': 0.0003996746170369954, 'epoch': 0.02}         \n",
      "{'loss': 0.8583, 'learning_rate': 0.00039967410673106163, 'epoch': 0.02}        \n",
      "{'loss': 0.8564, 'learning_rate': 0.0003996735960256052, 'epoch': 0.02}         \n",
      "{'loss': 0.8578, 'learning_rate': 0.0003996730849206269, 'epoch': 0.02}         \n",
      "{'loss': 0.858, 'learning_rate': 0.00039967257341612795, 'epoch': 0.02}         \n",
      "{'loss': 0.8558, 'learning_rate': 0.0003996720615121093, 'epoch': 0.02}         \n",
      "{'loss': 0.8561, 'learning_rate': 0.000399671549208572, 'epoch': 0.02}          \n",
      "{'loss': 0.8555, 'learning_rate': 0.000399671036505517, 'epoch': 0.02}          \n",
      "{'loss': 0.8563, 'learning_rate': 0.0003996705234029454, 'epoch': 0.02}         \n",
      "{'loss': 0.8588, 'learning_rate': 0.00039967000990085826, 'epoch': 0.02}        \n",
      "{'loss': 0.8555, 'learning_rate': 0.0003996694959992565, 'epoch': 0.02}         \n",
      "{'loss': 0.8583, 'learning_rate': 0.0003996689816981412, 'epoch': 0.02}         \n",
      "{'loss': 0.8567, 'learning_rate': 0.0003996684669975134, 'epoch': 0.02}         \n",
      "{'loss': 0.867, 'learning_rate': 0.0003996679518973741, 'epoch': 0.02}          \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039966743639772436, 'epoch': 0.02}        \n",
      "{'loss': 0.8587, 'learning_rate': 0.00039966692049856525, 'epoch': 0.02}        \n",
      "{'loss': 0.8553, 'learning_rate': 0.0003996664041998977, 'epoch': 0.02}         \n",
      "{'loss': 0.854, 'learning_rate': 0.00039966588750172283, 'epoch': 0.02}         \n",
      "{'loss': 0.8571, 'learning_rate': 0.00039966537040404164, 'epoch': 0.02}        \n",
      "{'loss': 0.8556, 'learning_rate': 0.00039966485290685516, 'epoch': 0.02}        \n",
      "{'loss': 0.8557, 'learning_rate': 0.0003996643350101644, 'epoch': 0.02}         \n",
      "{'loss': 0.8555, 'learning_rate': 0.00039966381671397046, 'epoch': 0.02}        \n",
      "{'loss': 0.8542, 'learning_rate': 0.0003996632980182743, 'epoch': 0.02}         \n",
      "{'loss': 0.855, 'learning_rate': 0.0003996627789230771, 'epoch': 0.02}          \n",
      "{'loss': 0.8538, 'learning_rate': 0.00039966225942837967, 'epoch': 0.02}        \n",
      "  2%|▌                               | 6500/351164 [1:39:26<81:38:13,  1.17it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8538, 'learning_rate': 0.0003996617395341833, 'epoch': 0.02}         \n",
      "{'loss': 0.8531, 'learning_rate': 0.0003996612192404888, 'epoch': 0.02}         \n",
      "{'loss': 0.8536, 'learning_rate': 0.00039966069854729746, 'epoch': 0.02}        \n",
      "{'loss': 0.8547, 'learning_rate': 0.00039966017745461007, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.00039965965596242784, 'epoch': 0.02}         \n",
      "{'loss': 0.8516, 'learning_rate': 0.00039965913407075175, 'epoch': 0.02}        \n",
      "{'loss': 0.8528, 'learning_rate': 0.00039965861177958283, 'epoch': 0.02}        \n",
      "{'loss': 0.8561, 'learning_rate': 0.00039965808908892217, 'epoch': 0.02}        \n",
      "{'loss': 0.8528, 'learning_rate': 0.00039965756599877084, 'epoch': 0.02}        \n",
      "{'loss': 0.8546, 'learning_rate': 0.0003996570425091298, 'epoch': 0.02}         \n",
      "{'loss': 0.8576, 'learning_rate': 0.0003996565186200001, 'epoch': 0.02}         \n",
      "{'loss': 0.8546, 'learning_rate': 0.0003996559943313829, 'epoch': 0.02}         \n",
      "{'loss': 0.854, 'learning_rate': 0.00039965546964327914, 'epoch': 0.02}         \n",
      "{'loss': 0.8544, 'learning_rate': 0.0003996549445556899, 'epoch': 0.02}         \n",
      "{'loss': 0.8531, 'learning_rate': 0.0003996544190686162, 'epoch': 0.02}         \n",
      "{'loss': 0.8526, 'learning_rate': 0.0003996538931820592, 'epoch': 0.02}         \n",
      "{'loss': 0.8534, 'learning_rate': 0.0003996533668960199, 'epoch': 0.02}         \n",
      "{'loss': 0.853, 'learning_rate': 0.0003996528402104993, 'epoch': 0.02}          \n",
      "{'loss': 0.8544, 'learning_rate': 0.0003996523131254984, 'epoch': 0.02}         \n",
      "{'loss': 0.8515, 'learning_rate': 0.00039965178564101844, 'epoch': 0.02}        \n",
      "{'loss': 0.8526, 'learning_rate': 0.0003996512577570604, 'epoch': 0.02}         \n",
      "{'loss': 0.8542, 'learning_rate': 0.0003996507294736252, 'epoch': 0.02}         \n",
      "{'loss': 0.8577, 'learning_rate': 0.0003996502007907141, 'epoch': 0.02}         \n",
      "{'loss': 0.8594, 'learning_rate': 0.00039964967170832803, 'epoch': 0.02}        \n",
      "{'loss': 0.8588, 'learning_rate': 0.00039964914222646815, 'epoch': 0.02}        \n",
      "{'loss': 0.861, 'learning_rate': 0.00039964861234513543, 'epoch': 0.02}         \n",
      "{'loss': 0.8622, 'learning_rate': 0.0003996480820643309, 'epoch': 0.02}         \n",
      "{'loss': 0.8614, 'learning_rate': 0.0003996475513840557, 'epoch': 0.02}         \n",
      "{'loss': 0.8595, 'learning_rate': 0.0003996470203043109, 'epoch': 0.02}         \n",
      "{'loss': 0.8549, 'learning_rate': 0.00039964648882509756, 'epoch': 0.02}        \n",
      "{'loss': 0.8532, 'learning_rate': 0.00039964595694641665, 'epoch': 0.02}        \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003996454246682693, 'epoch': 0.02}         \n",
      "{'loss': 0.8527, 'learning_rate': 0.00039964489199065663, 'epoch': 0.02}        \n",
      "{'loss': 0.8528, 'learning_rate': 0.0003996443589135796, 'epoch': 0.02}         \n",
      "{'loss': 0.8515, 'learning_rate': 0.0003996438254370394, 'epoch': 0.02}         \n",
      "{'loss': 0.852, 'learning_rate': 0.00039964329156103696, 'epoch': 0.02}         \n",
      "{'loss': 0.8514, 'learning_rate': 0.0003996427572855734, 'epoch': 0.02}         \n",
      "{'loss': 0.8545, 'learning_rate': 0.0003996422226106499, 'epoch': 0.02}         \n",
      "{'loss': 0.8537, 'learning_rate': 0.00039964168753626734, 'epoch': 0.02}        \n",
      "{'loss': 0.8524, 'learning_rate': 0.00039964115206242684, 'epoch': 0.02}        \n",
      "{'loss': 0.8533, 'learning_rate': 0.00039964061618912966, 'epoch': 0.02}        \n",
      "{'loss': 0.8524, 'learning_rate': 0.0003996400799163766, 'epoch': 0.02}         \n",
      "{'loss': 0.854, 'learning_rate': 0.0003996395432441689, 'epoch': 0.02}          \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003996390061725076, 'epoch': 0.02}         \n",
      "{'loss': 0.8539, 'learning_rate': 0.00039963846870139373, 'epoch': 0.02}        \n",
      "{'loss': 0.8538, 'learning_rate': 0.0003996379308308285, 'epoch': 0.02}         \n",
      "{'loss': 0.8721, 'learning_rate': 0.00039963739256081285, 'epoch': 0.02}        \n",
      "{'loss': 0.8597, 'learning_rate': 0.00039963685389134785, 'epoch': 0.02}        \n",
      "{'loss': 0.8572, 'learning_rate': 0.00039963631482243465, 'epoch': 0.02}        \n",
      "{'loss': 0.8572, 'learning_rate': 0.00039963577535407426, 'epoch': 0.02}        \n",
      "{'loss': 0.8552, 'learning_rate': 0.0003996352354862679, 'epoch': 0.02}         \n",
      "{'loss': 0.8541, 'learning_rate': 0.00039963469521901647, 'epoch': 0.02}        \n",
      "{'loss': 0.8537, 'learning_rate': 0.0003996341545523212, 'epoch': 0.02}         \n",
      "{'loss': 0.8528, 'learning_rate': 0.000399633613486183, 'epoch': 0.02}          \n",
      "{'loss': 0.8506, 'learning_rate': 0.0003996330720206031, 'epoch': 0.02}         \n",
      "{'loss': 0.8547, 'learning_rate': 0.00039963253015558265, 'epoch': 0.02}        \n",
      "{'loss': 0.8487, 'learning_rate': 0.0003996319878911225, 'epoch': 0.02}         \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003996314452272239, 'epoch': 0.02}         \n",
      "{'loss': 0.8507, 'learning_rate': 0.0003996309021638879, 'epoch': 0.02}         \n",
      "{'loss': 0.8519, 'learning_rate': 0.00039963035870111557, 'epoch': 0.02}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.000399629814838908, 'epoch': 0.02}          \n",
      "{'loss': 0.8498, 'learning_rate': 0.0003996292705772663, 'epoch': 0.02}         \n",
      "{'loss': 0.853, 'learning_rate': 0.0003996287259161916, 'epoch': 0.02}          \n",
      "{'loss': 0.8503, 'learning_rate': 0.0003996281808556849, 'epoch': 0.02}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.0003996276353957473, 'epoch': 0.02}         \n",
      "{'loss': 0.8502, 'learning_rate': 0.00039962708953637994, 'epoch': 0.02}        \n",
      "{'loss': 0.8516, 'learning_rate': 0.0003996265432775839, 'epoch': 0.02}         \n",
      "{'loss': 0.852, 'learning_rate': 0.00039962599661936025, 'epoch': 0.02}         \n",
      "{'loss': 0.8536, 'learning_rate': 0.0003996254495617101, 'epoch': 0.02}         \n",
      "{'loss': 0.8526, 'learning_rate': 0.00039962490210463454, 'epoch': 0.02}        \n",
      "{'loss': 0.8533, 'learning_rate': 0.0003996243542481347, 'epoch': 0.02}         \n",
      "{'loss': 0.8519, 'learning_rate': 0.0003996238059922116, 'epoch': 0.02}         \n",
      "{'loss': 0.8515, 'learning_rate': 0.0003996232573368664, 'epoch': 0.02}         \n",
      "{'loss': 0.8537, 'learning_rate': 0.0003996227082821002, 'epoch': 0.02}         \n",
      "{'loss': 0.852, 'learning_rate': 0.00039962215882791407, 'epoch': 0.02}         \n",
      "{'loss': 0.8569, 'learning_rate': 0.0003996216089743091, 'epoch': 0.02}         \n",
      "{'loss': 0.8533, 'learning_rate': 0.00039962105872128637, 'epoch': 0.02}        \n",
      "{'loss': 0.8556, 'learning_rate': 0.0003996205080688471, 'epoch': 0.02}         \n",
      "{'loss': 0.8522, 'learning_rate': 0.0003996199570169922, 'epoch': 0.02}         \n",
      "{'loss': 0.8545, 'learning_rate': 0.000399619405565723, 'epoch': 0.02}          \n",
      "{'loss': 0.8528, 'learning_rate': 0.00039961885371504047, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.0003996183014649457, 'epoch': 0.02}          \n",
      "{'loss': 0.8555, 'learning_rate': 0.00039961774881543984, 'epoch': 0.02}        \n",
      "{'loss': 0.8536, 'learning_rate': 0.00039961719576652393, 'epoch': 0.02}        \n",
      "{'loss': 0.8521, 'learning_rate': 0.00039961664231819916, 'epoch': 0.02}        \n",
      "{'loss': 0.8535, 'learning_rate': 0.00039961608847046657, 'epoch': 0.02}        \n",
      "{'loss': 0.8548, 'learning_rate': 0.0003996155342233274, 'epoch': 0.02}         \n",
      "{'loss': 0.8525, 'learning_rate': 0.0003996149795767826, 'epoch': 0.02}         \n",
      "{'loss': 0.8523, 'learning_rate': 0.0003996144245308333, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.00039961386908548077, 'epoch': 0.02}        \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003996133132407259, 'epoch': 0.02}         \n",
      "{'loss': 0.8547, 'learning_rate': 0.0003996127569965699, 'epoch': 0.02}         \n",
      "{'loss': 0.8558, 'learning_rate': 0.00039961220035301395, 'epoch': 0.02}        \n",
      "{'loss': 0.8525, 'learning_rate': 0.0003996116433100591, 'epoch': 0.02}         \n",
      "{'loss': 0.8533, 'learning_rate': 0.00039961108586770647, 'epoch': 0.02}        \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003996105280259571, 'epoch': 0.02}         \n",
      "{'loss': 0.8524, 'learning_rate': 0.0003996099697848123, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.0003996094111442729, 'epoch': 0.02}         \n",
      "{'loss': 0.8557, 'learning_rate': 0.0003996088521043403, 'epoch': 0.02}         \n",
      "{'loss': 0.8543, 'learning_rate': 0.0003996082926650155, 'epoch': 0.02}         \n",
      "  2%|▋                               | 7000/351164 [1:46:33<78:08:10,  1.22it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8535, 'learning_rate': 0.0003996077328262996, 'epoch': 0.02}         \n",
      "{'loss': 0.8526, 'learning_rate': 0.00039960717258819375, 'epoch': 0.02}        \n",
      "{'loss': 0.8542, 'learning_rate': 0.00039960661195069904, 'epoch': 0.02}        \n",
      "{'loss': 0.856, 'learning_rate': 0.00039960605091381667, 'epoch': 0.02}         \n",
      "{'loss': 0.8551, 'learning_rate': 0.0003996054894775476, 'epoch': 0.02}         \n",
      "{'loss': 0.8563, 'learning_rate': 0.00039960492764189317, 'epoch': 0.02}        \n",
      "{'loss': 0.8539, 'learning_rate': 0.00039960436540685437, 'epoch': 0.02}        \n",
      "{'loss': 0.8531, 'learning_rate': 0.0003996038027724323, 'epoch': 0.02}         \n",
      "{'loss': 0.8523, 'learning_rate': 0.0003996032397386282, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.0003996026763054431, 'epoch': 0.02}         \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039960211247287817, 'epoch': 0.02}        \n",
      "{'loss': 0.8523, 'learning_rate': 0.0003996015482409345, 'epoch': 0.02}         \n",
      "{'loss': 0.8548, 'learning_rate': 0.0003996009836096133, 'epoch': 0.02}         \n",
      "{'loss': 0.8531, 'learning_rate': 0.00039960041857891557, 'epoch': 0.02}        \n",
      "{'loss': 0.8537, 'learning_rate': 0.0003995998531488426, 'epoch': 0.02}         \n",
      "{'loss': 0.8528, 'learning_rate': 0.0003995992873193954, 'epoch': 0.02}         \n",
      "{'loss': 0.8533, 'learning_rate': 0.0003995987210905751, 'epoch': 0.02}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.0003995981544623829, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.0003995975874348199, 'epoch': 0.02}         \n",
      "{'loss': 0.8521, 'learning_rate': 0.00039959702000788724, 'epoch': 0.02}        \n",
      "{'loss': 0.8542, 'learning_rate': 0.00039959645218158607, 'epoch': 0.02}        \n",
      "{'loss': 0.8521, 'learning_rate': 0.0003995958839559175, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.0003995953153308827, 'epoch': 0.02}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.00039959474630648284, 'epoch': 0.02}        \n",
      "{'loss': 0.8536, 'learning_rate': 0.00039959417688271894, 'epoch': 0.02}        \n",
      "{'loss': 0.8525, 'learning_rate': 0.0003995936070595922, 'epoch': 0.02}         \n",
      "{'loss': 0.8514, 'learning_rate': 0.0003995930368371038, 'epoch': 0.02}         \n",
      "{'loss': 0.8543, 'learning_rate': 0.0003995924662152548, 'epoch': 0.02}         \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003995918951940464, 'epoch': 0.02}         \n",
      "{'loss': 0.8538, 'learning_rate': 0.0003995913237734798, 'epoch': 0.02}         \n",
      "{'loss': 0.8542, 'learning_rate': 0.000399590751953556, 'epoch': 0.02}          \n",
      "{'loss': 0.8717, 'learning_rate': 0.00039959017973427625, 'epoch': 0.02}        \n",
      "{'loss': 0.8613, 'learning_rate': 0.0003995896071156416, 'epoch': 0.02}         \n",
      "{'loss': 0.8543, 'learning_rate': 0.00039958903409765336, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.00039958846068031257, 'epoch': 0.02}         \n",
      "{'loss': 0.852, 'learning_rate': 0.0003995878868636203, 'epoch': 0.02}          \n",
      "{'loss': 0.8497, 'learning_rate': 0.0003995873126475778, 'epoch': 0.02}         \n",
      "{'loss': 0.8507, 'learning_rate': 0.0003995867380321862, 'epoch': 0.02}         \n",
      "{'loss': 0.8511, 'learning_rate': 0.0003995861630174467, 'epoch': 0.02}         \n",
      "{'loss': 0.8499, 'learning_rate': 0.0003995855876033604, 'epoch': 0.02}         \n",
      "{'loss': 0.8513, 'learning_rate': 0.0003995850117899284, 'epoch': 0.02}         \n",
      "{'loss': 0.8514, 'learning_rate': 0.0003995844355771519, 'epoch': 0.02}         \n",
      "{'loss': 0.8517, 'learning_rate': 0.0003995838589650321, 'epoch': 0.02}         \n",
      "{'loss': 0.8524, 'learning_rate': 0.0003995832819535701, 'epoch': 0.02}         \n",
      "{'loss': 0.8522, 'learning_rate': 0.0003995827045427671, 'epoch': 0.02}         \n",
      "{'loss': 0.853, 'learning_rate': 0.0003995821267326242, 'epoch': 0.02}          \n",
      "{'loss': 0.8525, 'learning_rate': 0.00039958154852314247, 'epoch': 0.02}        \n",
      "{'loss': 0.8513, 'learning_rate': 0.0003995809699143233, 'epoch': 0.02}         \n",
      "{'loss': 0.8502, 'learning_rate': 0.00039958039090616764, 'epoch': 0.02}        \n",
      "{'loss': 0.8516, 'learning_rate': 0.00039957981149867675, 'epoch': 0.02}        \n",
      "{'loss': 0.8512, 'learning_rate': 0.0003995792316918518, 'epoch': 0.02}         \n",
      "{'loss': 0.8523, 'learning_rate': 0.00039957865148569394, 'epoch': 0.02}        \n",
      "{'loss': 0.8513, 'learning_rate': 0.0003995780708802043, 'epoch': 0.02}         \n",
      "{'loss': 0.8533, 'learning_rate': 0.000399577489875384, 'epoch': 0.02}          \n",
      "{'loss': 0.8552, 'learning_rate': 0.0003995769084712343, 'epoch': 0.02}         \n",
      "{'loss': 0.8533, 'learning_rate': 0.00039957632666775633, 'epoch': 0.02}        \n",
      "{'loss': 0.8534, 'learning_rate': 0.00039957574446495116, 'epoch': 0.02}        \n",
      "{'loss': 0.8539, 'learning_rate': 0.00039957516186282007, 'epoch': 0.02}        \n",
      "{'loss': 0.8519, 'learning_rate': 0.00039957457886136426, 'epoch': 0.02}        \n",
      "{'loss': 0.8529, 'learning_rate': 0.00039957399546058475, 'epoch': 0.02}        \n",
      "{'loss': 0.8516, 'learning_rate': 0.0003995734116604828, 'epoch': 0.02}         \n",
      "{'loss': 0.854, 'learning_rate': 0.0003995728274610596, 'epoch': 0.02}          \n",
      "{'loss': 0.849, 'learning_rate': 0.00039957224286231625, 'epoch': 0.02}         \n",
      "{'loss': 0.8528, 'learning_rate': 0.00039957165786425394, 'epoch': 0.02}        \n",
      "{'loss': 0.8499, 'learning_rate': 0.0003995710724668739, 'epoch': 0.02}         \n",
      "{'loss': 0.8532, 'learning_rate': 0.0003995704866701773, 'epoch': 0.02}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.00039956990047416513, 'epoch': 0.02}        \n",
      "{'loss': 0.8516, 'learning_rate': 0.0003995693138788388, 'epoch': 0.02}         \n",
      "{'loss': 0.85, 'learning_rate': 0.00039956872688419936, 'epoch': 0.02}          \n",
      "{'loss': 0.8548, 'learning_rate': 0.00039956813949024796, 'epoch': 0.02}        \n",
      "{'loss': 0.8549, 'learning_rate': 0.00039956755169698587, 'epoch': 0.02}        \n",
      "{'loss': 0.855, 'learning_rate': 0.00039956696350441424, 'epoch': 0.02}         \n",
      "{'loss': 0.8525, 'learning_rate': 0.0003995663749125342, 'epoch': 0.02}         \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003995657859213469, 'epoch': 0.02}         \n",
      "{'loss': 0.8524, 'learning_rate': 0.00039956519653085366, 'epoch': 0.02}        \n",
      "{'loss': 0.8497, 'learning_rate': 0.00039956460674105555, 'epoch': 0.02}        \n",
      "{'loss': 0.8508, 'learning_rate': 0.00039956401655195375, 'epoch': 0.02}        \n",
      "{'loss': 0.8512, 'learning_rate': 0.00039956342596354945, 'epoch': 0.02}        \n",
      "{'loss': 0.8494, 'learning_rate': 0.00039956283497584384, 'epoch': 0.02}        \n",
      "{'loss': 0.851, 'learning_rate': 0.0003995622435888382, 'epoch': 0.02}          \n",
      "{'loss': 0.8512, 'learning_rate': 0.0003995616518025335, 'epoch': 0.02}         \n",
      "{'loss': 0.8523, 'learning_rate': 0.00039956105961693107, 'epoch': 0.02}        \n",
      "{'loss': 0.8521, 'learning_rate': 0.00039956046703203216, 'epoch': 0.02}        \n",
      "{'loss': 0.8533, 'learning_rate': 0.00039955987404783776, 'epoch': 0.02}        \n",
      "{'loss': 0.8527, 'learning_rate': 0.0003995592806643492, 'epoch': 0.02}         \n",
      "{'loss': 0.8517, 'learning_rate': 0.00039955868688156763, 'epoch': 0.02}        \n",
      "{'loss': 0.8519, 'learning_rate': 0.00039955809269949424, 'epoch': 0.02}        \n",
      "{'loss': 0.8528, 'learning_rate': 0.0003995574981181302, 'epoch': 0.02}         \n",
      "{'loss': 0.8528, 'learning_rate': 0.0003995569031374767, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.00039955630775753497, 'epoch': 0.02}        \n",
      "{'loss': 0.8516, 'learning_rate': 0.0003995557119783062, 'epoch': 0.02}         \n",
      "{'loss': 0.8497, 'learning_rate': 0.00039955511579979153, 'epoch': 0.02}        \n",
      "{'loss': 0.8497, 'learning_rate': 0.00039955451922199216, 'epoch': 0.02}        \n",
      "{'loss': 0.8508, 'learning_rate': 0.0003995539222449094, 'epoch': 0.02}         \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003995533248685442, 'epoch': 0.02}         \n",
      "{'loss': 0.8532, 'learning_rate': 0.00039955272709289806, 'epoch': 0.02}        \n",
      "{'loss': 0.8512, 'learning_rate': 0.00039955212891797196, 'epoch': 0.02}        \n",
      "{'loss': 0.8517, 'learning_rate': 0.0003995515303437671, 'epoch': 0.02}         \n",
      "{'loss': 0.8511, 'learning_rate': 0.0003995509313702848, 'epoch': 0.02}         \n",
      "{'loss': 0.8537, 'learning_rate': 0.0003995503319975262, 'epoch': 0.02}         \n",
      "  2%|▋                               | 7500/351164 [1:53:42<77:38:59,  1.23it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8508, 'learning_rate': 0.00039954973222549244, 'epoch': 0.02}        \n",
      "{'loss': 0.8495, 'learning_rate': 0.0003995491320541848, 'epoch': 0.02}         \n",
      "{'loss': 0.8543, 'learning_rate': 0.00039954853148360447, 'epoch': 0.02}        \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003995479305137527, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.0003995473291446305, 'epoch': 0.02}         \n",
      "{'loss': 0.8517, 'learning_rate': 0.00039954672737623924, 'epoch': 0.02}        \n",
      "{'loss': 0.8502, 'learning_rate': 0.0003995461252085801, 'epoch': 0.02}         \n",
      "{'loss': 0.8514, 'learning_rate': 0.0003995455226416543, 'epoch': 0.02}         \n",
      "{'loss': 0.8498, 'learning_rate': 0.000399544919675463, 'epoch': 0.02}          \n",
      "{'loss': 0.8503, 'learning_rate': 0.00039954431631000737, 'epoch': 0.02}        \n",
      "{'loss': 0.8524, 'learning_rate': 0.0003995437125452887, 'epoch': 0.02}         \n",
      "{'loss': 0.8516, 'learning_rate': 0.0003995431083813082, 'epoch': 0.02}         \n",
      "{'loss': 0.8511, 'learning_rate': 0.00039954250381806704, 'epoch': 0.02}        \n",
      "{'loss': 0.8526, 'learning_rate': 0.0003995418988555664, 'epoch': 0.02}         \n",
      "{'loss': 0.8493, 'learning_rate': 0.0003995412934938076, 'epoch': 0.02}         \n",
      "{'loss': 0.8496, 'learning_rate': 0.0003995406877327917, 'epoch': 0.02}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.00039954008157252005, 'epoch': 0.02}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.0003995394750129938, 'epoch': 0.02}         \n",
      "{'loss': 0.8501, 'learning_rate': 0.00039953886805421413, 'epoch': 0.02}        \n",
      "{'loss': 0.851, 'learning_rate': 0.0003995382606961823, 'epoch': 0.02}          \n",
      "{'loss': 0.848, 'learning_rate': 0.00039953765293889956, 'epoch': 0.02}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.00039953704478236704, 'epoch': 0.02}        \n",
      "{'loss': 0.8507, 'learning_rate': 0.00039953643622658597, 'epoch': 0.02}        \n",
      "{'loss': 0.8492, 'learning_rate': 0.0003995358272715576, 'epoch': 0.02}         \n",
      "{'loss': 0.8517, 'learning_rate': 0.0003995352179172832, 'epoch': 0.02}         \n",
      "{'loss': 0.8509, 'learning_rate': 0.0003995346081637639, 'epoch': 0.02}         \n",
      "{'loss': 0.851, 'learning_rate': 0.000399533998011001, 'epoch': 0.02}           \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039953338745899564, 'epoch': 0.02}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.0003995327765077491, 'epoch': 0.02}         \n",
      "{'loss': 0.8544, 'learning_rate': 0.0003995321651572625, 'epoch': 0.02}         \n",
      "{'loss': 0.8542, 'learning_rate': 0.00039953155340753725, 'epoch': 0.02}        \n",
      "{'loss': 0.8537, 'learning_rate': 0.00039953094125857444, 'epoch': 0.02}        \n",
      "{'loss': 0.8514, 'learning_rate': 0.0003995303287103752, 'epoch': 0.02}         \n",
      "{'loss': 0.8519, 'learning_rate': 0.000399529715762941, 'epoch': 0.02}          \n",
      "{'loss': 0.8523, 'learning_rate': 0.000399529102416273, 'epoch': 0.02}          \n",
      "{'loss': 0.8503, 'learning_rate': 0.0003995284886703723, 'epoch': 0.02}         \n",
      "{'loss': 0.8496, 'learning_rate': 0.00039952787452524015, 'epoch': 0.02}        \n",
      "{'loss': 0.8505, 'learning_rate': 0.00039952725998087786, 'epoch': 0.02}        \n",
      "{'loss': 0.8511, 'learning_rate': 0.0003995266450372867, 'epoch': 0.02}         \n",
      "{'loss': 0.8497, 'learning_rate': 0.00039952602969446773, 'epoch': 0.02}        \n",
      "{'loss': 0.8495, 'learning_rate': 0.00039952541395242233, 'epoch': 0.02}        \n",
      "{'loss': 0.85, 'learning_rate': 0.0003995247978111516, 'epoch': 0.02}           \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039952418127065696, 'epoch': 0.02}        \n",
      "{'loss': 0.8478, 'learning_rate': 0.00039952356433093955, 'epoch': 0.02}        \n",
      "{'loss': 0.85, 'learning_rate': 0.0003995229469920005, 'epoch': 0.02}           \n",
      "{'loss': 0.8531, 'learning_rate': 0.00039952232925384123, 'epoch': 0.02}        \n",
      "{'loss': 0.8515, 'learning_rate': 0.0003995217111164628, 'epoch': 0.02}         \n",
      "{'loss': 0.8491, 'learning_rate': 0.0003995210925798666, 'epoch': 0.02}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.0003995204736440537, 'epoch': 0.02}         \n",
      "{'loss': 0.8524, 'learning_rate': 0.0003995198543090255, 'epoch': 0.02}         \n",
      "{'loss': 0.8508, 'learning_rate': 0.00039951923457478324, 'epoch': 0.02}        \n",
      "{'loss': 0.8506, 'learning_rate': 0.000399518614441328, 'epoch': 0.02}          \n",
      "{'loss': 0.8505, 'learning_rate': 0.00039951799390866116, 'epoch': 0.02}        \n",
      "{'loss': 0.8494, 'learning_rate': 0.0003995173729767839, 'epoch': 0.02}         \n",
      "{'loss': 0.853, 'learning_rate': 0.0003995167516456975, 'epoch': 0.02}          \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003995161299154032, 'epoch': 0.02}         \n",
      "{'loss': 0.8529, 'learning_rate': 0.00039951550778590217, 'epoch': 0.02}        \n",
      "{'loss': 0.8496, 'learning_rate': 0.00039951488525719574, 'epoch': 0.02}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.00039951426232928515, 'epoch': 0.02}        \n",
      "{'loss': 0.8485, 'learning_rate': 0.0003995136390021716, 'epoch': 0.02}         \n",
      "{'loss': 0.8645, 'learning_rate': 0.0003995130152758563, 'epoch': 0.02}         \n",
      "{'loss': 0.8515, 'learning_rate': 0.00039951239115034067, 'epoch': 0.02}        \n",
      "{'loss': 0.85, 'learning_rate': 0.0003995117666256258, 'epoch': 0.02}           \n",
      "{'loss': 0.85, 'learning_rate': 0.000399511141701713, 'epoch': 0.02}            \n",
      "{'loss': 0.8497, 'learning_rate': 0.0003995105163786035, 'epoch': 0.02}         \n",
      "{'loss': 0.8512, 'learning_rate': 0.00039950989065629854, 'epoch': 0.02}        \n",
      "{'loss': 0.8491, 'learning_rate': 0.00039950926453479943, 'epoch': 0.02}        \n",
      "{'loss': 0.851, 'learning_rate': 0.00039950863801410734, 'epoch': 0.02}         \n",
      "{'loss': 0.8494, 'learning_rate': 0.0003995080110942236, 'epoch': 0.02}         \n",
      "{'loss': 0.8501, 'learning_rate': 0.00039950738377514947, 'epoch': 0.02}        \n",
      "{'loss': 0.8533, 'learning_rate': 0.0003995067560568861, 'epoch': 0.02}         \n",
      "{'loss': 0.8484, 'learning_rate': 0.00039950612793943486, 'epoch': 0.02}        \n",
      "{'loss': 0.8481, 'learning_rate': 0.00039950549942279693, 'epoch': 0.02}        \n",
      "{'loss': 0.849, 'learning_rate': 0.0003995048705069736, 'epoch': 0.02}          \n",
      "{'loss': 0.8499, 'learning_rate': 0.0003995042411919661, 'epoch': 0.02}         \n",
      "{'loss': 0.8512, 'learning_rate': 0.0003995036114777758, 'epoch': 0.02}         \n",
      "{'loss': 0.8488, 'learning_rate': 0.00039950298136440384, 'epoch': 0.02}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.00039950235085185146, 'epoch': 0.02}        \n",
      "{'loss': 0.8489, 'learning_rate': 0.00039950171994012, 'epoch': 0.02}           \n",
      "{'loss': 0.85, 'learning_rate': 0.0003995010886292107, 'epoch': 0.02}           \n",
      "{'loss': 0.8511, 'learning_rate': 0.0003995004569191249, 'epoch': 0.02}         \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003994998248098637, 'epoch': 0.02}         \n",
      "{'loss': 0.8501, 'learning_rate': 0.0003994991923014285, 'epoch': 0.02}         \n",
      "{'loss': 0.8535, 'learning_rate': 0.00039949855939382047, 'epoch': 0.02}        \n",
      "{'loss': 0.8546, 'learning_rate': 0.000399497926087041, 'epoch': 0.02}          \n",
      "{'loss': 0.8527, 'learning_rate': 0.0003994972923810912, 'epoch': 0.02}         \n",
      "{'loss': 0.8513, 'learning_rate': 0.00039949665827597247, 'epoch': 0.02}        \n",
      "{'loss': 0.8512, 'learning_rate': 0.000399496023771686, 'epoch': 0.02}          \n",
      "{'loss': 0.8509, 'learning_rate': 0.0003994953888682331, 'epoch': 0.02}         \n",
      "{'loss': 0.8516, 'learning_rate': 0.000399494753565615, 'epoch': 0.02}          \n",
      "{'loss': 0.8515, 'learning_rate': 0.000399494117863833, 'epoch': 0.02}          \n",
      "{'loss': 0.8518, 'learning_rate': 0.00039949348176288843, 'epoch': 0.02}        \n",
      "{'loss': 0.8513, 'learning_rate': 0.0003994928452627825, 'epoch': 0.02}         \n",
      "{'loss': 0.8499, 'learning_rate': 0.0003994922083635165, 'epoch': 0.02}         \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039949157106509156, 'epoch': 0.02}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.0003994909333675092, 'epoch': 0.02}         \n",
      "{'loss': 0.8513, 'learning_rate': 0.0003994902952707706, 'epoch': 0.02}         \n",
      "{'loss': 0.8511, 'learning_rate': 0.00039948965677487694, 'epoch': 0.02}        \n",
      "{'loss': 0.8503, 'learning_rate': 0.0003994890178798296, 'epoch': 0.02}         \n",
      "{'loss': 0.8498, 'learning_rate': 0.00039948837858562984, 'epoch': 0.02}        \n",
      "  2%|▋                               | 8000/351164 [2:00:49<82:44:52,  1.15it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<01:02,  2.21it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:23,  1.65it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:33,  1.46it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:38,  1.38it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:43,  1.30it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:05<01:45,  1.28it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:05<01:46,  1.24it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:47,  1.23it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:46,  1.23it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:43,  1.26it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:44,  1.23it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:09<01:44,  1.22it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:10<01:42,  1.23it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:11<01:45,  1.19it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:44,  1.20it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:45,  1.18it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:44,  1.18it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:15<01:44,  1.17it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:15<01:41,  1.19it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:16<01:48,  1.11it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:17<01:45,  1.13it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:18<01:39,  1.18it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:19<01:37,  1.20it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:35,  1.21it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:36,  1.19it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:21<01:36,  1.18it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:22<01:35,  1.18it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:23<01:33,  1.20it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:24<01:33,  1.19it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:29,  1.23it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:26<01:33,  1.17it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:26<01:34,  1.15it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:28<01:37,  1.10it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:28<01:34,  1.12it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:29<01:31,  1.15it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:30<01:29,  1.16it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:31<01:27,  1.17it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:32<01:28,  1.15it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:33<01:31,  1.10it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:34<01:29,  1.12it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:35<01:30,  1.09it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:35<01:29,  1.10it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:36<01:23,  1.17it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:37<01:20,  1.19it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:38<01:20,  1.17it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:39<01:19,  1.19it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:39<01:15,  1.22it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:40<01:18,  1.17it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:41<01:17,  1.17it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:42<01:14,  1.21it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:43<01:14,  1.20it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:44<01:13,  1.19it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:45<01:13,  1.19it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:45<01:11,  1.20it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:46<01:11,  1.19it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:47<01:11,  1.17it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:48<01:11,  1.16it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:49<01:09,  1.19it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:50<01:08,  1.18it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:50<01:06,  1.21it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:51<01:05,  1.20it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:52<01:02,  1.24it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:53<01:01,  1.24it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:54<01:01,  1.24it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:54<01:00,  1.23it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:55<01:01,  1.21it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:56<00:59,  1.22it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:57<01:00,  1.19it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:58<00:59,  1.19it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [00:59<00:59,  1.17it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:00<00:57,  1.21it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:00<00:55,  1.21it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:01<00:57,  1.17it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:02<00:56,  1.17it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:03<00:54,  1.20it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:04<00:55,  1.16it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:05<00:53,  1.18it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:05<00:52,  1.19it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:06<00:51,  1.19it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:07<00:52,  1.15it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:08<00:51,  1.15it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:09<00:49,  1.17it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:10<00:49,  1.15it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:11<00:48,  1.16it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:12<00:47,  1.15it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:12<00:47,  1.13it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:13<00:46,  1.15it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:14<00:43,  1.19it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:15<00:43,  1.17it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:16<00:41,  1.20it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:17<00:40,  1.21it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:17<00:40,  1.18it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:18<00:39,  1.19it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:19<00:39,  1.17it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:20<00:37,  1.20it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:21<00:36,  1.22it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:22<00:36,  1.19it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:23<00:35,  1.18it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:23<00:34,  1.18it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:24<00:33,  1.19it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:25<00:33,  1.18it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:26<00:31,  1.19it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:27<00:30,  1.20it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:27<00:29,  1.24it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:28<00:28,  1.21it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:29<00:28,  1.19it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:30<00:28,  1.17it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:31<00:29,  1.10it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:32<00:27,  1.12it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:33<00:26,  1.15it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:34<00:24,  1.17it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:34<00:23,  1.20it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:35<00:22,  1.23it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:36<00:22,  1.18it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:37<00:21,  1.16it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:38<00:20,  1.15it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:39<00:19,  1.15it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:40<00:19,  1.15it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:40<00:17,  1.17it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:41<00:17,  1.17it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:42<00:16,  1.15it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:43<00:15,  1.15it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:44<00:14,  1.16it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:45<00:13,  1.18it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:46<00:12,  1.17it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:46<00:11,  1.19it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:47<00:10,  1.21it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:48<00:09,  1.22it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:49<00:08,  1.23it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:50<00:08,  1.22it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:50<00:07,  1.20it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:51<00:06,  1.22it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:52<00:05,  1.19it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:53<00:05,  1.16it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:54<00:04,  1.17it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:55<00:03,  1.15it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:56<00:02,  1.15it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:57<00:01,  1.15it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:57<00:00,  1.12it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [01:58<00:00,  1.10it/s]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8457926511764526, 'eval_cer': 0.024132733253742624, 'eval_runtime': 126.6663, 'eval_samples_per_second': 70.982, 'eval_steps_per_second': 1.113, 'epoch': 0.02}\n",
      "  2%|▋                               | 8000/351164 [2:02:56<82:44:52,  1.15it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [02:00<00:00,  1.10it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8509, 'learning_rate': 0.000399487738892279, 'epoch': 0.02}          \n",
      "{'loss': 0.8529, 'learning_rate': 0.0003994870987997782, 'epoch': 0.02}         \n",
      "{'loss': 0.853, 'learning_rate': 0.0003994864583081289, 'epoch': 0.02}          \n",
      "{'loss': 0.8526, 'learning_rate': 0.0003994858174173322, 'epoch': 0.02}         \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003994851761273895, 'epoch': 0.02}         \n",
      "{'loss': 0.8506, 'learning_rate': 0.0003994845344383022, 'epoch': 0.02}         \n",
      "{'loss': 0.8502, 'learning_rate': 0.0003994838923500713, 'epoch': 0.02}         \n",
      "{'loss': 0.8491, 'learning_rate': 0.00039948324986269825, 'epoch': 0.02}        \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003994826069761843, 'epoch': 0.02}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.00039948196369053084, 'epoch': 0.02}        \n",
      "{'loss': 0.8477, 'learning_rate': 0.000399481320005739, 'epoch': 0.02}          \n",
      "{'loss': 0.8485, 'learning_rate': 0.00039948067592181013, 'epoch': 0.02}        \n",
      "{'loss': 0.8472, 'learning_rate': 0.0003994800314387456, 'epoch': 0.02}         \n",
      "{'loss': 0.8487, 'learning_rate': 0.0003994793865565466, 'epoch': 0.02}         \n",
      "{'loss': 0.8481, 'learning_rate': 0.00039947874127521443, 'epoch': 0.02}        \n",
      "{'loss': 0.8471, 'learning_rate': 0.0003994780955947504, 'epoch': 0.02}         \n",
      "{'loss': 0.8509, 'learning_rate': 0.00039947744951515575, 'epoch': 0.02}        \n",
      "{'loss': 0.8496, 'learning_rate': 0.0003994768030364319, 'epoch': 0.02}         \n",
      "{'loss': 0.8558, 'learning_rate': 0.00039947615615858, 'epoch': 0.02}           \n",
      "{'loss': 0.8521, 'learning_rate': 0.00039947550888160146, 'epoch': 0.02}        \n",
      "{'loss': 0.8493, 'learning_rate': 0.0003994748612054975, 'epoch': 0.02}         \n",
      "{'loss': 0.8522, 'learning_rate': 0.0003994742131302695, 'epoch': 0.02}         \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003994735646559186, 'epoch': 0.02}         \n",
      "{'loss': 0.8492, 'learning_rate': 0.00039947291578244624, 'epoch': 0.02}        \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003994722665098537, 'epoch': 0.02}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.00039947161683814223, 'epoch': 0.02}        \n",
      "{'loss': 0.8492, 'learning_rate': 0.00039947096676731315, 'epoch': 0.02}        \n",
      "{'loss': 0.8488, 'learning_rate': 0.00039947031629736777, 'epoch': 0.02}        \n",
      "{'loss': 0.8484, 'learning_rate': 0.00039946966542830735, 'epoch': 0.02}        \n",
      "{'loss': 0.8497, 'learning_rate': 0.0003994690141601333, 'epoch': 0.02}         \n",
      "{'loss': 0.8502, 'learning_rate': 0.00039946836249284677, 'epoch': 0.02}        \n",
      "{'loss': 0.8504, 'learning_rate': 0.0003994677104264492, 'epoch': 0.02}         \n",
      "{'loss': 0.8494, 'learning_rate': 0.0003994670579609418, 'epoch': 0.02}         \n",
      "{'loss': 0.8487, 'learning_rate': 0.00039946640509632596, 'epoch': 0.02}        \n",
      "{'loss': 0.8502, 'learning_rate': 0.0003994657518326029, 'epoch': 0.02}         \n",
      "{'loss': 0.8522, 'learning_rate': 0.000399465098169774, 'epoch': 0.02}          \n",
      "{'loss': 0.8508, 'learning_rate': 0.00039946444410784055, 'epoch': 0.02}        \n",
      "{'loss': 0.8499, 'learning_rate': 0.0003994637896468038, 'epoch': 0.02}         \n",
      "{'loss': 0.852, 'learning_rate': 0.0003994631347866651, 'epoch': 0.02}          \n",
      "{'loss': 0.849, 'learning_rate': 0.00039946247952742575, 'epoch': 0.02}         \n",
      "{'loss': 0.8487, 'learning_rate': 0.00039946182386908714, 'epoch': 0.02}        \n",
      "{'loss': 0.8477, 'learning_rate': 0.00039946116781165047, 'epoch': 0.02}        \n",
      "{'loss': 0.8487, 'learning_rate': 0.00039946051135511713, 'epoch': 0.02}        \n",
      "{'loss': 0.8491, 'learning_rate': 0.0003994598544994884, 'epoch': 0.02}         \n",
      "{'loss': 0.8491, 'learning_rate': 0.00039945919724476556, 'epoch': 0.02}        \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039945853959095, 'epoch': 0.02}           \n",
      "{'loss': 0.8558, 'learning_rate': 0.00039945788153804296, 'epoch': 0.02}        \n",
      "{'loss': 0.8539, 'learning_rate': 0.0003994572230860459, 'epoch': 0.02}         \n",
      "{'loss': 0.8535, 'learning_rate': 0.00039945656423495993, 'epoch': 0.02}        \n",
      "{'loss': 0.8551, 'learning_rate': 0.0003994559049847865, 'epoch': 0.02}         \n",
      "{'loss': 0.8514, 'learning_rate': 0.00039945524533552685, 'epoch': 0.02}        \n",
      "{'loss': 0.8509, 'learning_rate': 0.0003994545852871824, 'epoch': 0.02}         \n",
      "{'loss': 0.847, 'learning_rate': 0.0003994539248397544, 'epoch': 0.02}          \n",
      "{'loss': 0.8485, 'learning_rate': 0.0003994532639932443, 'epoch': 0.02}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.0003994526027476532, 'epoch': 0.02}         \n",
      "{'loss': 0.8494, 'learning_rate': 0.00039945194110298254, 'epoch': 0.02}        \n",
      "{'loss': 0.8505, 'learning_rate': 0.0003994512790592337, 'epoch': 0.02}         \n",
      "{'loss': 0.8487, 'learning_rate': 0.00039945061661640787, 'epoch': 0.02}        \n",
      "{'loss': 0.8492, 'learning_rate': 0.0003994499537745065, 'epoch': 0.02}         \n",
      "{'loss': 0.848, 'learning_rate': 0.00039944929053353084, 'epoch': 0.02}         \n",
      "{'loss': 0.8511, 'learning_rate': 0.0003994486268934823, 'epoch': 0.02}         \n",
      "{'loss': 0.848, 'learning_rate': 0.0003994479628543621, 'epoch': 0.02}          \n",
      "{'loss': 0.8476, 'learning_rate': 0.00039944729841617164, 'epoch': 0.02}        \n",
      "{'loss': 0.8488, 'learning_rate': 0.00039944663357891223, 'epoch': 0.02}        \n",
      "{'loss': 0.8494, 'learning_rate': 0.0003994459683425852, 'epoch': 0.02}         \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003994453027071919, 'epoch': 0.02}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.0003994446366727336, 'epoch': 0.02}         \n",
      "{'loss': 0.848, 'learning_rate': 0.0003994439702392117, 'epoch': 0.02}          \n",
      "{'loss': 0.8518, 'learning_rate': 0.00039944330340662754, 'epoch': 0.02}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003994426361749824, 'epoch': 0.02}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.0003994419685442776, 'epoch': 0.02}         \n",
      "{'loss': 0.8485, 'learning_rate': 0.0003994413005145146, 'epoch': 0.02}         \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003994406320856946, 'epoch': 0.02}         \n",
      "{'loss': 0.8496, 'learning_rate': 0.00039943996325781896, 'epoch': 0.02}        \n",
      "{'loss': 0.8472, 'learning_rate': 0.00039943929403088907, 'epoch': 0.02}        \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003994386244049063, 'epoch': 0.02}         \n",
      "{'loss': 0.8479, 'learning_rate': 0.00039943795437987183, 'epoch': 0.02}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.0003994372839557872, 'epoch': 0.02}         \n",
      "{'loss': 0.8489, 'learning_rate': 0.0003994366131326537, 'epoch': 0.02}         \n",
      "{'loss': 0.8491, 'learning_rate': 0.00039943594191047254, 'epoch': 0.02}        \n",
      "{'loss': 0.8468, 'learning_rate': 0.0003994352702892451, 'epoch': 0.02}         \n",
      "{'loss': 0.848, 'learning_rate': 0.0003994345982689729, 'epoch': 0.02}          \n",
      "{'loss': 0.8497, 'learning_rate': 0.0003994339258496571, 'epoch': 0.02}         \n",
      "{'loss': 0.8467, 'learning_rate': 0.00039943325303129913, 'epoch': 0.02}        \n",
      "{'loss': 0.848, 'learning_rate': 0.0003994325798139003, 'epoch': 0.02}          \n",
      "{'loss': 0.8484, 'learning_rate': 0.00039943190619746196, 'epoch': 0.02}        \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003994312321819855, 'epoch': 0.02}         \n",
      "{'loss': 0.8487, 'learning_rate': 0.0003994305577674722, 'epoch': 0.02}         \n",
      "{'loss': 0.8496, 'learning_rate': 0.0003994298829539235, 'epoch': 0.02}         \n",
      "{'loss': 0.8509, 'learning_rate': 0.00039942920774134065, 'epoch': 0.02}        \n",
      "{'loss': 0.8601, 'learning_rate': 0.00039942853212972506, 'epoch': 0.02}        \n",
      "{'loss': 0.8531, 'learning_rate': 0.0003994278561190781, 'epoch': 0.02}         \n",
      "{'loss': 0.8498, 'learning_rate': 0.0003994271797094011, 'epoch': 0.02}         \n",
      "{'loss': 0.8493, 'learning_rate': 0.00039942650290069535, 'epoch': 0.02}        \n",
      "{'loss': 0.8497, 'learning_rate': 0.0003994258256929623, 'epoch': 0.02}         \n",
      "{'loss': 0.8501, 'learning_rate': 0.00039942514808620326, 'epoch': 0.02}        \n",
      "{'loss': 0.8518, 'learning_rate': 0.0003994244700804195, 'epoch': 0.02}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003994237916756126, 'epoch': 0.02}         \n",
      "{'loss': 0.8491, 'learning_rate': 0.0003994231128717837, 'epoch': 0.02}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.00039942243366893434, 'epoch': 0.02}        \n",
      "  2%|▊                               | 8500/351164 [2:10:02<81:13:36,  1.17it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8497, 'learning_rate': 0.0003994217540670657, 'epoch': 0.02}         \n",
      "{'loss': 0.848, 'learning_rate': 0.00039942107406617925, 'epoch': 0.02}         \n",
      "{'loss': 0.8488, 'learning_rate': 0.0003994203936662762, 'epoch': 0.02}         \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003994197128673582, 'epoch': 0.02}         \n",
      "{'loss': 0.8481, 'learning_rate': 0.0003994190316694264, 'epoch': 0.02}         \n",
      "{'loss': 0.8464, 'learning_rate': 0.00039941835007248225, 'epoch': 0.02}        \n",
      "{'loss': 0.8484, 'learning_rate': 0.000399417668076527, 'epoch': 0.02}          \n",
      "{'loss': 0.8469, 'learning_rate': 0.00039941698568156207, 'epoch': 0.02}        \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003994163028875889, 'epoch': 0.02}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.0003994156196946088, 'epoch': 0.02}         \n",
      "{'loss': 0.8459, 'learning_rate': 0.0003994149361026231, 'epoch': 0.02}         \n",
      "{'loss': 0.8489, 'learning_rate': 0.00039941425211163323, 'epoch': 0.02}        \n",
      "{'loss': 0.8476, 'learning_rate': 0.00039941356772164047, 'epoch': 0.02}        \n",
      "{'loss': 0.8481, 'learning_rate': 0.00039941288293264635, 'epoch': 0.02}        \n",
      "{'loss': 0.8469, 'learning_rate': 0.0003994121977446521, 'epoch': 0.02}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.0003994115121576591, 'epoch': 0.02}         \n",
      "{'loss': 0.848, 'learning_rate': 0.00039941082617166884, 'epoch': 0.02}         \n",
      "{'loss': 0.8461, 'learning_rate': 0.00039941013978668255, 'epoch': 0.02}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003994094530027017, 'epoch': 0.02}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.0003994087658197275, 'epoch': 0.02}         \n",
      "{'loss': 0.8509, 'learning_rate': 0.00039940807823776156, 'epoch': 0.02}        \n",
      "{'loss': 0.8522, 'learning_rate': 0.0003994073902568051, 'epoch': 0.02}         \n",
      "{'loss': 0.8492, 'learning_rate': 0.0003994067018768596, 'epoch': 0.02}         \n",
      "{'loss': 0.852, 'learning_rate': 0.0003994060130979263, 'epoch': 0.02}          \n",
      "{'loss': 0.8486, 'learning_rate': 0.00039940532392000673, 'epoch': 0.02}        \n",
      "{'loss': 0.8493, 'learning_rate': 0.00039940463434310215, 'epoch': 0.02}        \n",
      "{'loss': 0.8502, 'learning_rate': 0.00039940394436721404, 'epoch': 0.02}        \n",
      "{'loss': 0.8515, 'learning_rate': 0.00039940325399234365, 'epoch': 0.02}        \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003994025632184925, 'epoch': 0.02}         \n",
      "{'loss': 0.8471, 'learning_rate': 0.0003994018720456619, 'epoch': 0.02}         \n",
      "{'loss': 0.849, 'learning_rate': 0.0003994011804738532, 'epoch': 0.02}          \n",
      "{'loss': 0.8472, 'learning_rate': 0.0003994004885030679, 'epoch': 0.02}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039939979613330727, 'epoch': 0.02}        \n",
      "{'loss': 0.8491, 'learning_rate': 0.00039939910336457275, 'epoch': 0.02}        \n",
      "{'loss': 0.848, 'learning_rate': 0.0003993984101968657, 'epoch': 0.02}          \n",
      "{'loss': 0.8483, 'learning_rate': 0.00039939771663018755, 'epoch': 0.02}        \n",
      "{'loss': 0.8464, 'learning_rate': 0.0003993970226645396, 'epoch': 0.02}         \n",
      "{'loss': 0.8485, 'learning_rate': 0.0003993963282999233, 'epoch': 0.02}         \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003993956335363401, 'epoch': 0.02}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039939493837379123, 'epoch': 0.02}        \n",
      "{'loss': 0.8467, 'learning_rate': 0.0003993942428122783, 'epoch': 0.02}         \n",
      "{'loss': 0.8478, 'learning_rate': 0.0003993935468518025, 'epoch': 0.02}         \n",
      "{'loss': 0.8475, 'learning_rate': 0.00039939285049236527, 'epoch': 0.02}        \n",
      "{'loss': 0.8477, 'learning_rate': 0.00039939215373396814, 'epoch': 0.02}        \n",
      "{'loss': 0.849, 'learning_rate': 0.0003993914565766123, 'epoch': 0.02}          \n",
      "{'loss': 0.847, 'learning_rate': 0.0003993907590202993, 'epoch': 0.02}          \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003993900610650305, 'epoch': 0.02}         \n",
      "{'loss': 0.8471, 'learning_rate': 0.0003993893627108072, 'epoch': 0.02}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.0003993886639576309, 'epoch': 0.02}         \n",
      "{'loss': 0.8471, 'learning_rate': 0.000399387964805503, 'epoch': 0.02}          \n",
      "{'loss': 0.8469, 'learning_rate': 0.00039938726525442483, 'epoch': 0.02}        \n",
      "{'loss': 0.8486, 'learning_rate': 0.00039938656530439786, 'epoch': 0.02}        \n",
      "{'loss': 0.8492, 'learning_rate': 0.0003993858649554234, 'epoch': 0.02}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.000399385164207503, 'epoch': 0.02}          \n",
      "{'loss': 0.847, 'learning_rate': 0.0003993844630606379, 'epoch': 0.02}          \n",
      "{'loss': 0.8487, 'learning_rate': 0.0003993837615148296, 'epoch': 0.03}         \n",
      "{'loss': 0.848, 'learning_rate': 0.0003993830595700795, 'epoch': 0.03}          \n",
      "{'loss': 0.8508, 'learning_rate': 0.000399382357226389, 'epoch': 0.03}          \n",
      "{'loss': 0.8519, 'learning_rate': 0.0003993816544837595, 'epoch': 0.03}         \n",
      "{'loss': 0.8504, 'learning_rate': 0.0003993809513421923, 'epoch': 0.03}         \n",
      "{'loss': 0.8524, 'learning_rate': 0.000399380247801689, 'epoch': 0.03}          \n",
      "{'loss': 0.852, 'learning_rate': 0.00039937954386225086, 'epoch': 0.03}         \n",
      "{'loss': 0.8512, 'learning_rate': 0.0003993788395238793, 'epoch': 0.03}         \n",
      "{'loss': 0.85, 'learning_rate': 0.00039937813478657587, 'epoch': 0.03}          \n",
      "{'loss': 0.8498, 'learning_rate': 0.00039937742965034186, 'epoch': 0.03}        \n",
      "{'loss': 0.8493, 'learning_rate': 0.00039937672411517863, 'epoch': 0.03}        \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003993760181810877, 'epoch': 0.03}         \n",
      "{'loss': 0.8456, 'learning_rate': 0.00039937531184807047, 'epoch': 0.03}        \n",
      "{'loss': 0.8471, 'learning_rate': 0.0003993746051161283, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039937389798526266, 'epoch': 0.03}         \n",
      "{'loss': 0.8464, 'learning_rate': 0.0003993731904554749, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003993724825267664, 'epoch': 0.03}         \n",
      "{'loss': 0.8495, 'learning_rate': 0.0003993717741991388, 'epoch': 0.03}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003993710654725933, 'epoch': 0.03}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.00039937035634713135, 'epoch': 0.03}        \n",
      "{'loss': 0.845, 'learning_rate': 0.00039936964682275443, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003993689368994639, 'epoch': 0.03}         \n",
      "{'loss': 0.8478, 'learning_rate': 0.0003993682265772613, 'epoch': 0.03}         \n",
      "{'loss': 0.847, 'learning_rate': 0.00039936751585614786, 'epoch': 0.03}         \n",
      "{'loss': 0.8469, 'learning_rate': 0.00039936680473612513, 'epoch': 0.03}        \n",
      "{'loss': 0.8485, 'learning_rate': 0.0003993660932171946, 'epoch': 0.03}         \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003993653812993575, 'epoch': 0.03}         \n",
      "{'loss': 0.8467, 'learning_rate': 0.0003993646689826154, 'epoch': 0.03}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.00039936395626696965, 'epoch': 0.03}        \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003993632431524217, 'epoch': 0.03}         \n",
      "{'loss': 0.8486, 'learning_rate': 0.00039936252963897304, 'epoch': 0.03}        \n",
      "{'loss': 0.8534, 'learning_rate': 0.00039936181572662507, 'epoch': 0.03}        \n",
      "{'loss': 0.8632, 'learning_rate': 0.0003993611014153791, 'epoch': 0.03}         \n",
      "{'loss': 0.8559, 'learning_rate': 0.0003993603867052367, 'epoch': 0.03}         \n",
      "{'loss': 0.8503, 'learning_rate': 0.00039935967159619924, 'epoch': 0.03}        \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003993589560882682, 'epoch': 0.03}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.0003993582401814449, 'epoch': 0.03}         \n",
      "{'loss': 0.846, 'learning_rate': 0.0003993575238757309, 'epoch': 0.03}          \n",
      "{'loss': 0.8478, 'learning_rate': 0.00039935680717112753, 'epoch': 0.03}        \n",
      "{'loss': 0.8464, 'learning_rate': 0.0003993560900676363, 'epoch': 0.03}         \n",
      "{'loss': 0.8458, 'learning_rate': 0.0003993553725652586, 'epoch': 0.03}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003993546546639959, 'epoch': 0.03}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.00039935393636384965, 'epoch': 0.03}        \n",
      "{'loss': 0.8464, 'learning_rate': 0.0003993532176648212, 'epoch': 0.03}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.00039935249856691205, 'epoch': 0.03}        \n",
      "  3%|▊                               | 9000/351164 [2:17:07<82:20:29,  1.15it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8451, 'learning_rate': 0.00039935177907012367, 'epoch': 0.03}        \n",
      "{'loss': 0.847, 'learning_rate': 0.0003993510591744574, 'epoch': 0.03}          \n",
      "{'loss': 0.8466, 'learning_rate': 0.00039935033887991483, 'epoch': 0.03}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003993496181864973, 'epoch': 0.03}         \n",
      "{'loss': 0.8471, 'learning_rate': 0.0003993488970942062, 'epoch': 0.03}         \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003993481756030431, 'epoch': 0.03}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.00039934745371300937, 'epoch': 0.03}        \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039934673142410647, 'epoch': 0.03}        \n",
      "{'loss': 0.8466, 'learning_rate': 0.00039934600873633584, 'epoch': 0.03}        \n",
      "{'loss': 0.8484, 'learning_rate': 0.0003993452856496989, 'epoch': 0.03}         \n",
      "{'loss': 0.8469, 'learning_rate': 0.00039934456216419713, 'epoch': 0.03}        \n",
      "{'loss': 0.8467, 'learning_rate': 0.000399343838279832, 'epoch': 0.03}          \n",
      "{'loss': 0.8468, 'learning_rate': 0.000399343113996605, 'epoch': 0.03}          \n",
      "{'loss': 0.8481, 'learning_rate': 0.0003993423893145174, 'epoch': 0.03}         \n",
      "{'loss': 0.8485, 'learning_rate': 0.00039934166423357076, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.0003993409387537666, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.00039934021287510625, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039933948659759123, 'epoch': 0.03}        \n",
      "{'loss': 0.8456, 'learning_rate': 0.00039933875992122296, 'epoch': 0.03}        \n",
      "{'loss': 0.8464, 'learning_rate': 0.000399338032846003, 'epoch': 0.03}          \n",
      "{'loss': 0.8491, 'learning_rate': 0.0003993373053719326, 'epoch': 0.03}         \n",
      "{'loss': 0.846, 'learning_rate': 0.0003993365774990134, 'epoch': 0.03}          \n",
      "{'loss': 0.8477, 'learning_rate': 0.0003993358492272468, 'epoch': 0.03}         \n",
      "{'loss': 0.8464, 'learning_rate': 0.0003993351205566342, 'epoch': 0.03}         \n",
      "{'loss': 0.8461, 'learning_rate': 0.00039933439148717714, 'epoch': 0.03}        \n",
      "{'loss': 0.8461, 'learning_rate': 0.00039933366201887703, 'epoch': 0.03}        \n",
      "{'loss': 0.8466, 'learning_rate': 0.0003993329321517354, 'epoch': 0.03}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003993322018857535, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039933147122093304, 'epoch': 0.03}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.00039933074015727546, 'epoch': 0.03}        \n",
      "{'loss': 0.8476, 'learning_rate': 0.000399330008694782, 'epoch': 0.03}          \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003993292768334544, 'epoch': 0.03}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.0003993285445732939, 'epoch': 0.03}         \n",
      "{'loss': 0.85, 'learning_rate': 0.00039932781191430217, 'epoch': 0.03}          \n",
      "{'loss': 0.8489, 'learning_rate': 0.0003993270788564805, 'epoch': 0.03}         \n",
      "{'loss': 0.8488, 'learning_rate': 0.0003993263453998304, 'epoch': 0.03}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.0003993256115443534, 'epoch': 0.03}         \n",
      "{'loss': 0.847, 'learning_rate': 0.00039932487729005094, 'epoch': 0.03}         \n",
      "{'loss': 0.8488, 'learning_rate': 0.00039932414263692446, 'epoch': 0.03}        \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039932340758497547, 'epoch': 0.03}        \n",
      "{'loss': 0.8461, 'learning_rate': 0.00039932267213420536, 'epoch': 0.03}        \n",
      "{'loss': 0.8476, 'learning_rate': 0.00039932193628461576, 'epoch': 0.03}        \n",
      "{'loss': 0.8469, 'learning_rate': 0.000399321200036208, 'epoch': 0.03}          \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003993204633889836, 'epoch': 0.03}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.000399319726342944, 'epoch': 0.03}          \n",
      "{'loss': 0.846, 'learning_rate': 0.00039931898889809076, 'epoch': 0.03}         \n",
      "{'loss': 0.8479, 'learning_rate': 0.00039931825105442526, 'epoch': 0.03}        \n",
      "{'loss': 0.8478, 'learning_rate': 0.00039931751281194905, 'epoch': 0.03}        \n",
      "{'loss': 0.8486, 'learning_rate': 0.00039931677417066354, 'epoch': 0.03}        \n",
      "{'loss': 0.846, 'learning_rate': 0.00039931603513057026, 'epoch': 0.03}         \n",
      "{'loss': 0.8481, 'learning_rate': 0.00039931529569167066, 'epoch': 0.03}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039931455585396627, 'epoch': 0.03}        \n",
      "{'loss': 0.8456, 'learning_rate': 0.0003993138156174585, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039931307498214884, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.00039931233394803885, 'epoch': 0.03}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003993115925151299, 'epoch': 0.03}         \n",
      "{'loss': 0.8461, 'learning_rate': 0.0003993108506834236, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039931010845292134, 'epoch': 0.03}        \n",
      "{'loss': 0.8482, 'learning_rate': 0.00039930936582362463, 'epoch': 0.03}        \n",
      "{'loss': 0.8468, 'learning_rate': 0.0003993086227955349, 'epoch': 0.03}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.00039930787936865374, 'epoch': 0.03}        \n",
      "{'loss': 0.8488, 'learning_rate': 0.0003993071355429826, 'epoch': 0.03}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.000399306391318523, 'epoch': 0.03}          \n",
      "{'loss': 0.8461, 'learning_rate': 0.0003993056466952763, 'epoch': 0.03}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003993049016732441, 'epoch': 0.03}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.0003993041562524279, 'epoch': 0.03}         \n",
      "{'loss': 0.8451, 'learning_rate': 0.00039930341043282916, 'epoch': 0.03}        \n",
      "{'loss': 0.8477, 'learning_rate': 0.0003993026642144493, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039930191759729, 'epoch': 0.03}           \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039930117058135256, 'epoch': 0.03}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.00039930042316663856, 'epoch': 0.03}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039929967535314953, 'epoch': 0.03}        \n",
      "{'loss': 0.8467, 'learning_rate': 0.00039929892714088693, 'epoch': 0.03}        \n",
      "{'loss': 0.8485, 'learning_rate': 0.00039929817852985217, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039929742952004687, 'epoch': 0.03}        \n",
      "{'loss': 0.8485, 'learning_rate': 0.00039929668011147256, 'epoch': 0.03}        \n",
      "{'loss': 0.8472, 'learning_rate': 0.0003992959303041306, 'epoch': 0.03}         \n",
      "{'loss': 0.8478, 'learning_rate': 0.00039929518009802263, 'epoch': 0.03}        \n",
      "{'loss': 0.8482, 'learning_rate': 0.00039929442949315, 'epoch': 0.03}           \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003992936784895143, 'epoch': 0.03}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.000399292927087117, 'epoch': 0.03}          \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003992921752859597, 'epoch': 0.03}         \n",
      "{'loss': 0.8469, 'learning_rate': 0.0003992914230860438, 'epoch': 0.03}         \n",
      "{'loss': 0.8464, 'learning_rate': 0.00039929067048737087, 'epoch': 0.03}        \n",
      "{'loss': 0.8481, 'learning_rate': 0.00039928991748994236, 'epoch': 0.03}        \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003992891640937598, 'epoch': 0.03}         \n",
      "{'loss': 0.8486, 'learning_rate': 0.0003992884102988247, 'epoch': 0.03}         \n",
      "{'loss': 0.8478, 'learning_rate': 0.00039928765610513855, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039928690151270287, 'epoch': 0.03}        \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003992861465215192, 'epoch': 0.03}         \n",
      "{'loss': 0.8457, 'learning_rate': 0.00039928539113158896, 'epoch': 0.03}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.0003992846353429138, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039928387915549515, 'epoch': 0.03}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003992831225693345, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.0003992823655844335, 'epoch': 0.03}         \n",
      "{'loss': 0.8458, 'learning_rate': 0.0003992816082007934, 'epoch': 0.03}         \n",
      "{'loss': 0.8481, 'learning_rate': 0.000399280850418416, 'epoch': 0.03}          \n",
      "{'loss': 0.8459, 'learning_rate': 0.00039928009223730266, 'epoch': 0.03}        \n",
      "{'loss': 0.8467, 'learning_rate': 0.0003992793336574549, 'epoch': 0.03}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039927857467887424, 'epoch': 0.03}        \n",
      "  3%|▊                               | 9500/351164 [2:24:13<77:51:15,  1.22it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8469, 'learning_rate': 0.0003992778153015623, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003992770555255205, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003992762953507504, 'epoch': 0.03}         \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003992755347772535, 'epoch': 0.03}         \n",
      "{'loss': 0.847, 'learning_rate': 0.0003992747738050313, 'epoch': 0.03}          \n",
      "{'loss': 0.8461, 'learning_rate': 0.00039927401243408536, 'epoch': 0.03}        \n",
      "{'loss': 0.8457, 'learning_rate': 0.00039927325066441724, 'epoch': 0.03}        \n",
      "{'loss': 0.848, 'learning_rate': 0.0003992724884960284, 'epoch': 0.03}          \n",
      "{'loss': 0.8457, 'learning_rate': 0.00039927172592892036, 'epoch': 0.03}        \n",
      "{'loss': 0.8475, 'learning_rate': 0.00039927096296309464, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003992701995985528, 'epoch': 0.03}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.0003992694358352964, 'epoch': 0.03}         \n",
      "{'loss': 0.8457, 'learning_rate': 0.0003992686716733269, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.00039926790711264593, 'epoch': 0.03}        \n",
      "{'loss': 0.8501, 'learning_rate': 0.0003992671421532549, 'epoch': 0.03}         \n",
      "{'loss': 0.8471, 'learning_rate': 0.0003992663767951554, 'epoch': 0.03}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003992656110383489, 'epoch': 0.03}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.00039926484488283706, 'epoch': 0.03}        \n",
      "{'loss': 0.8555, 'learning_rate': 0.0003992640783286213, 'epoch': 0.03}         \n",
      "{'loss': 0.8514, 'learning_rate': 0.00039926331137570323, 'epoch': 0.03}        \n",
      "{'loss': 0.8494, 'learning_rate': 0.00039926254402408435, 'epoch': 0.03}        \n",
      "{'loss': 0.8485, 'learning_rate': 0.00039926177627376606, 'epoch': 0.03}        \n",
      "{'loss': 0.8475, 'learning_rate': 0.0003992610081247502, 'epoch': 0.03}         \n",
      "{'loss': 0.8481, 'learning_rate': 0.000399260239577038, 'epoch': 0.03}          \n",
      "{'loss': 0.8475, 'learning_rate': 0.0003992594706306312, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039925870128553127, 'epoch': 0.03}        \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003992579315417397, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.0003992571613992582, 'epoch': 0.03}         \n",
      "{'loss': 0.847, 'learning_rate': 0.0003992563908580881, 'epoch': 0.03}          \n",
      "{'loss': 0.846, 'learning_rate': 0.00039925561991823106, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003992548485796886, 'epoch': 0.03}         \n",
      "{'loss': 0.8456, 'learning_rate': 0.00039925407684246217, 'epoch': 0.03}        \n",
      "{'loss': 0.8469, 'learning_rate': 0.0003992533047065535, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.000399252532171964, 'epoch': 0.03}          \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003992517592386953, 'epoch': 0.03}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.00039925098590674885, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039925021217612625, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003992494380468291, 'epoch': 0.03}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039924866351885883, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039924788859221704, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003992471132669054, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003992463375429252, 'epoch': 0.03}         \n",
      "{'loss': 0.8469, 'learning_rate': 0.00039924556142027827, 'epoch': 0.03}        \n",
      "{'loss': 0.847, 'learning_rate': 0.000399244784898966, 'epoch': 0.03}           \n",
      "{'loss': 0.8469, 'learning_rate': 0.00039924400797899007, 'epoch': 0.03}        \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003992432306603518, 'epoch': 0.03}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.000399242452943053, 'epoch': 0.03}          \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003992416748270951, 'epoch': 0.03}         \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003992408963124796, 'epoch': 0.03}         \n",
      "{'loss': 0.8483, 'learning_rate': 0.0003992401173992082, 'epoch': 0.03}         \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003992393380872824, 'epoch': 0.03}         \n",
      "{'loss': 0.8454, 'learning_rate': 0.00039923855837670376, 'epoch': 0.03}        \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039923777826747384, 'epoch': 0.03}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039923699775959415, 'epoch': 0.03}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039923621685306634, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003992354355478919, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039923465384407246, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003992338717416095, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039923308924050467, 'epoch': 0.03}        \n",
      "{'loss': 0.846, 'learning_rate': 0.00039923230634075947, 'epoch': 0.03}         \n",
      "{'loss': 0.8456, 'learning_rate': 0.00039923152304237547, 'epoch': 0.03}        \n",
      "{'loss': 0.8458, 'learning_rate': 0.0003992307393453543, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.00039922995524969745, 'epoch': 0.03}        \n",
      "{'loss': 0.8468, 'learning_rate': 0.0003992291707554066, 'epoch': 0.03}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.00039922838586248314, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.00039922760057092886, 'epoch': 0.03}        \n",
      "{'loss': 0.847, 'learning_rate': 0.00039922681488074516, 'epoch': 0.03}         \n",
      "{'loss': 0.846, 'learning_rate': 0.00039922602879193366, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.000399225242304496, 'epoch': 0.03}          \n",
      "{'loss': 0.8448, 'learning_rate': 0.00039922445541843365, 'epoch': 0.03}        \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003992236681337482, 'epoch': 0.03}         \n",
      "{'loss': 0.8467, 'learning_rate': 0.00039922288045044136, 'epoch': 0.03}        \n",
      "{'loss': 0.8451, 'learning_rate': 0.0003992220923685145, 'epoch': 0.03}         \n",
      "{'loss': 0.8454, 'learning_rate': 0.0003992213038879693, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003992205150088074, 'epoch': 0.03}         \n",
      "{'loss': 0.8461, 'learning_rate': 0.0003992197257310303, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003992189360546396, 'epoch': 0.03}         \n",
      "{'loss': 0.8458, 'learning_rate': 0.00039921814597963687, 'epoch': 0.03}        \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039921735550602365, 'epoch': 0.03}        \n",
      "{'loss': 0.8454, 'learning_rate': 0.0003992165646338016, 'epoch': 0.03}         \n",
      "{'loss': 0.8517, 'learning_rate': 0.0003992157733629723, 'epoch': 0.03}         \n",
      "{'loss': 0.8574, 'learning_rate': 0.0003992149816935373, 'epoch': 0.03}         \n",
      "{'loss': 0.8513, 'learning_rate': 0.0003992141896254982, 'epoch': 0.03}         \n",
      "{'loss': 0.8498, 'learning_rate': 0.00039921339715885646, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.0003992126042936139, 'epoch': 0.03}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.00039921181102977194, 'epoch': 0.03}        \n",
      "{'loss': 0.8453, 'learning_rate': 0.0003992110173673322, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003992102233062963, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003992094288466658, 'epoch': 0.03}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003992086339884423, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003992078387316274, 'epoch': 0.03}         \n",
      "{'loss': 0.843, 'learning_rate': 0.0003992070430762226, 'epoch': 0.03}          \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039920624702222964, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003992054505696501, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039920465371848544, 'epoch': 0.03}         \n",
      "{'loss': 0.844, 'learning_rate': 0.00039920385646873734, 'epoch': 0.03}         \n",
      "{'loss': 0.8446, 'learning_rate': 0.00039920305882040736, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.00039920226077349723, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.0003992014623280084, 'epoch': 0.03}          \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003992006634839425, 'epoch': 0.03}         \n",
      "  3%|▉                              | 10000/351164 [2:31:19<82:55:15,  1.14it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:01<01:13,  1.88it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:32,  1.50it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:40,  1.36it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:43,  1.32it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:45,  1.28it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:05<01:45,  1.27it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:06<01:45,  1.26it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:44,  1.27it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:50,  1.19it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:49,  1.18it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:50,  1.17it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:10<01:50,  1.15it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:11<01:49,  1.16it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:12<01:46,  1.19it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:44,  1.19it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:47,  1.15it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:51,  1.11it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:15<01:49,  1.12it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:16<01:47,  1.13it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:17<01:49,  1.10it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:18<01:45,  1.13it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:19<01:43,  1.14it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:20<01:41,  1.15it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:37,  1.19it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:37,  1.17it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:22<01:40,  1.13it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:23<01:38,  1.14it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:24<01:37,  1.15it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:25<01:35,  1.17it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:31,  1.21it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:26<01:34,  1.16it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:27<01:34,  1.14it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:28<01:39,  1.08it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:29<01:33,  1.14it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:30<01:34,  1.11it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:31<01:35,  1.09it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:32<01:33,  1.11it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:33<01:31,  1.12it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:34<01:28,  1.14it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:34<01:26,  1.16it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:35<01:26,  1.15it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:36<01:32,  1.06it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:37<01:27,  1.10it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:38<01:25,  1.12it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:39<01:25,  1.11it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:40<01:25,  1.10it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:41<01:20,  1.15it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:42<01:19,  1.15it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:42<01:18,  1.15it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:43<01:15,  1.19it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:44<01:14,  1.20it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:45<01:13,  1.20it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:46<01:11,  1.22it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:46<01:10,  1.23it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:47<01:09,  1.22it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:48<01:07,  1.24it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:49<01:08,  1.21it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:50<01:06,  1.23it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:51<01:11,  1.14it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:52<01:08,  1.17it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:53<01:11,  1.11it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:53<01:07,  1.16it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:54<01:05,  1.17it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:55<01:06,  1.15it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:56<01:05,  1.14it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:57<01:04,  1.15it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:58<01:01,  1.18it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:59<01:04,  1.11it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [01:00<01:02,  1.14it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [01:00<01:00,  1.15it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:01<00:56,  1.21it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:02<00:55,  1.23it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:03<00:54,  1.22it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:04<00:54,  1.20it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:04<00:53,  1.21it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:05<00:55,  1.15it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:06<00:55,  1.13it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:07<00:54,  1.13it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:08<00:52,  1.16it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:09<00:52,  1.15it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:10<00:53,  1.10it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:11<00:51,  1.13it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:11<00:49,  1.15it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:12<00:48,  1.16it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:13<00:47,  1.15it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:14<00:45,  1.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:15<00:45,  1.17it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:16<00:42,  1.21it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:16<00:42,  1.20it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:17<00:40,  1.22it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:18<00:39,  1.26it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:19<00:39,  1.21it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:20<00:38,  1.23it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:21<00:39,  1.16it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:22<00:38,  1.16it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:22<00:37,  1.18it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:23<00:35,  1.22it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:24<00:34,  1.21it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:25<00:33,  1.23it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:26<00:33,  1.20it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:26<00:33,  1.18it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:27<00:32,  1.18it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:28<00:30,  1.21it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:29<00:29,  1.20it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:30<00:29,  1.19it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:31<00:28,  1.19it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:31<00:27,  1.21it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:32<00:27,  1.16it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:33<00:26,  1.16it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:34<00:25,  1.18it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:35<00:24,  1.19it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:36<00:23,  1.21it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:37<00:22,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:37<00:21,  1.19it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:38<00:21,  1.19it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:39<00:20,  1.18it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:40<00:19,  1.16it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:41<00:19,  1.12it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:42<00:19,  1.10it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:43<00:17,  1.15it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:44<00:16,  1.15it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:44<00:15,  1.15it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:45<00:14,  1.15it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:46<00:13,  1.16it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:47<00:13,  1.15it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:48<00:11,  1.17it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:49<00:11,  1.17it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:50<00:10,  1.17it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:50<00:09,  1.17it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:51<00:08,  1.18it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:52<00:07,  1.20it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:53<00:06,  1.20it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:54<00:06,  1.12it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:55<00:05,  1.16it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:55<00:04,  1.21it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:56<00:03,  1.21it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:57<00:02,  1.20it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:58<00:01,  1.15it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:59<00:00,  1.19it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [02:00<00:00,  1.16it/s]\u001b[A[Ds]CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 [Ds]CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8428561091423035, 'eval_cer': 0.019258976104524185, 'eval_runtime': 126.996, 'eval_samples_per_second': 70.798, 'eval_steps_per_second': 1.11, 'epoch': 0.03}\n",
      "  3%|▉                              | 10000/351164 [2:33:26<82:55:15,  1.14it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [02:01<00:00,  1.16it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8467, 'learning_rate': 0.00039919986424130107, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039919906460008584, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003991982645602983, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003991974641219401, 'epoch': 0.03}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.00039919666328501284, 'epoch': 0.03}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003991958620495182, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039919506041545766, 'epoch': 0.03}        \n",
      "{'loss': 0.8454, 'learning_rate': 0.00039919425838283283, 'epoch': 0.03}        \n",
      "{'loss': 0.8475, 'learning_rate': 0.0003991934559516454, 'epoch': 0.03}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003991926531218969, 'epoch': 0.03}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.00039919184989358896, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039919104626672317, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003991902422413012, 'epoch': 0.03}         \n",
      "{'loss': 0.8454, 'learning_rate': 0.0003991894378173246, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.000399188632994795, 'epoch': 0.03}          \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039918782777371406, 'epoch': 0.03}        \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039918702215408327, 'epoch': 0.03}        \n",
      "{'loss': 0.8458, 'learning_rate': 0.0003991862161359043, 'epoch': 0.03}         \n",
      "{'loss': 0.846, 'learning_rate': 0.0003991854097191788, 'epoch': 0.03}          \n",
      "{'loss': 0.845, 'learning_rate': 0.0003991846029039084, 'epoch': 0.03}          \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039918379569009465, 'epoch': 0.03}        \n",
      "{'loss': 0.844, 'learning_rate': 0.0003991829880777392, 'epoch': 0.03}          \n",
      "{'loss': 0.8459, 'learning_rate': 0.0003991821800668436, 'epoch': 0.03}         \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003991813716574095, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039918056284943856, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.00039917975364293245, 'epoch': 0.03}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.0003991789440378926, 'epoch': 0.03}         \n",
      "{'loss': 0.844, 'learning_rate': 0.00039917813403432084, 'epoch': 0.03}         \n",
      "{'loss': 0.8626, 'learning_rate': 0.00039917732363221864, 'epoch': 0.03}        \n",
      "{'loss': 0.8499, 'learning_rate': 0.00039917651283158774, 'epoch': 0.03}        \n",
      "{'loss': 0.8474, 'learning_rate': 0.00039917570163242966, 'epoch': 0.03}        \n",
      "{'loss': 0.8459, 'learning_rate': 0.000399174890034746, 'epoch': 0.03}          \n",
      "{'loss': 0.8485, 'learning_rate': 0.0003991740780385385, 'epoch': 0.03}         \n",
      "{'loss': 0.846, 'learning_rate': 0.00039917326564380877, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039917245285055837, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003991716396587889, 'epoch': 0.03}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003991708260685021, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003991700120796995, 'epoch': 0.03}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039916919769238275, 'epoch': 0.03}        \n",
      "{'loss': 0.8457, 'learning_rate': 0.00039916838290655356, 'epoch': 0.03}        \n",
      "{'loss': 0.8467, 'learning_rate': 0.00039916756772221345, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.00039916675213936414, 'epoch': 0.03}        \n",
      "{'loss': 0.8461, 'learning_rate': 0.00039916593615800717, 'epoch': 0.03}        \n",
      "{'loss': 0.8487, 'learning_rate': 0.00039916511977814426, 'epoch': 0.03}        \n",
      "{'loss': 0.8491, 'learning_rate': 0.00039916430299977694, 'epoch': 0.03}        \n",
      "{'loss': 0.8454, 'learning_rate': 0.000399163485822907, 'epoch': 0.03}          \n",
      "{'loss': 0.8482, 'learning_rate': 0.0003991626682475359, 'epoch': 0.03}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003991618502736654, 'epoch': 0.03}         \n",
      "{'loss': 0.8465, 'learning_rate': 0.0003991610319012971, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003991602131304326, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003991593939610736, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003991585743932218, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039915775442687863, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003991569340620459, 'epoch': 0.03}         \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003991561132987252, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039915529213691817, 'epoch': 0.03}        \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003991544705766264, 'epoch': 0.03}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003991536486178516, 'epoch': 0.03}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039915282626059554, 'epoch': 0.03}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003991520035048596, 'epoch': 0.03}         \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039915118035064565, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003991503567979552, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039914953284678987, 'epoch': 0.03}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003991487084971515, 'epoch': 0.03}         \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003991478837490416, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.0003991470586024618, 'epoch': 0.03}          \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003991462330574138, 'epoch': 0.03}         \n",
      "{'loss': 0.8475, 'learning_rate': 0.0003991454071138993, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003991445807719198, 'epoch': 0.03}         \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039914375403147715, 'epoch': 0.03}        \n",
      "{'loss': 0.8466, 'learning_rate': 0.00039914292689257285, 'epoch': 0.03}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003991420993552086, 'epoch': 0.03}         \n",
      "{'loss': 0.8457, 'learning_rate': 0.0003991412714193861, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.000399140443085107, 'epoch': 0.03}          \n",
      "{'loss': 0.844, 'learning_rate': 0.0003991396143523728, 'epoch': 0.03}          \n",
      "{'loss': 0.8458, 'learning_rate': 0.00039913878522118544, 'epoch': 0.03}        \n",
      "{'loss': 0.8457, 'learning_rate': 0.00039913795569154634, 'epoch': 0.03}        \n",
      "{'loss': 0.846, 'learning_rate': 0.00039913712576345725, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039913629543691985, 'epoch': 0.03}        \n",
      "{'loss': 0.8473, 'learning_rate': 0.00039913546471193577, 'epoch': 0.03}        \n",
      "{'loss': 0.8475, 'learning_rate': 0.00039913463358850674, 'epoch': 0.03}        \n",
      "{'loss': 0.845, 'learning_rate': 0.0003991338020666343, 'epoch': 0.03}          \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039913297014632017, 'epoch': 0.03}        \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039913213782756605, 'epoch': 0.03}        \n",
      "{'loss': 0.8458, 'learning_rate': 0.00039913130511037354, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003991304719947444, 'epoch': 0.03}         \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003991296384806802, 'epoch': 0.03}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039912880456818264, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039912797025725344, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003991271355478942, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039912630044010663, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003991254649338924, 'epoch': 0.03}         \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003991246290292531, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039912379272619055, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003991229560247063, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003991221189248021, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003991212814264795, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039912044352974043, 'epoch': 0.03}        \n",
      "{'loss': 0.8451, 'learning_rate': 0.0003991196052345863, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039911876654101893, 'epoch': 0.03}        \n",
      "  3%|▉                              | 10500/351164 [2:40:29<80:20:22,  1.18it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8453, 'learning_rate': 0.0003991179274490399, 'epoch': 0.03}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039911708795865104, 'epoch': 0.03}        \n",
      "{'loss': 0.8461, 'learning_rate': 0.0003991162480698539, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039911540778265017, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.00039911456709704164, 'epoch': 0.03}         \n",
      "{'loss': 0.847, 'learning_rate': 0.00039911372601302984, 'epoch': 0.03}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003991128845306165, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.0003991120426498034, 'epoch': 0.03}         \n",
      "{'loss': 0.8477, 'learning_rate': 0.0003991112003705922, 'epoch': 0.03}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003991103576929845, 'epoch': 0.03}         \n",
      "{'loss': 0.8449, 'learning_rate': 0.000399109514616982, 'epoch': 0.03}          \n",
      "{'loss': 0.8472, 'learning_rate': 0.00039910867114258645, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.00039910782726979943, 'epoch': 0.03}        \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039910698299862275, 'epoch': 0.03}        \n",
      "{'loss': 0.8463, 'learning_rate': 0.000399106138329058, 'epoch': 0.03}          \n",
      "{'loss': 0.8466, 'learning_rate': 0.000399105293261107, 'epoch': 0.03}          \n",
      "{'loss': 0.8453, 'learning_rate': 0.0003991044477947713, 'epoch': 0.03}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.0003991036019300527, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003991027556669528, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003991019090054734, 'epoch': 0.03}         \n",
      "{'loss': 0.8459, 'learning_rate': 0.0003991010619456161, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.0003991002144873826, 'epoch': 0.03}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003990993666307746, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.00039909851837579386, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.00039909766972244206, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.0003990968206707208, 'epoch': 0.03}          \n",
      "{'loss': 0.8459, 'learning_rate': 0.00039909597122063194, 'epoch': 0.03}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039909512137217704, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039909427112535785, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039909342048017606, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003990925694366334, 'epoch': 0.03}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003990917179947316, 'epoch': 0.03}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003990908661544723, 'epoch': 0.03}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003990900139158572, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039908916127888807, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003990883082435666, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003990874548098944, 'epoch': 0.03}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003990866009778733, 'epoch': 0.03}         \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003990857467475049, 'epoch': 0.03}         \n",
      "{'loss': 0.8461, 'learning_rate': 0.0003990848921187911, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039908403709173335, 'epoch': 0.03}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.00039908318166633356, 'epoch': 0.03}        \n",
      "{'loss': 0.8459, 'learning_rate': 0.0003990823258425933, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.0003990814696205145, 'epoch': 0.03}          \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003990806130000986, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039907975598134745, 'epoch': 0.03}        \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003990788985642628, 'epoch': 0.03}         \n",
      "{'loss': 0.8456, 'learning_rate': 0.00039907804074884633, 'epoch': 0.03}        \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039907718253509973, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039907632392302474, 'epoch': 0.03}        \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039907546491262303, 'epoch': 0.03}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039907460550389645, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003990737456968465, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.00039907288549147516, 'epoch': 0.03}        \n",
      "{'loss': 0.846, 'learning_rate': 0.000399072024887784, 'epoch': 0.03}           \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039907116388577477, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003990703024854491, 'epoch': 0.03}         \n",
      "{'loss': 0.8459, 'learning_rate': 0.00039906944068680893, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039906857848985577, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003990677158945914, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.00039906685290101767, 'epoch': 0.03}        \n",
      "{'loss': 0.8435, 'learning_rate': 0.0003990659895091362, 'epoch': 0.03}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003990651257189487, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039906426153045693, 'epoch': 0.03}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039906339694366263, 'epoch': 0.03}        \n",
      "{'loss': 0.8436, 'learning_rate': 0.0003990625319585675, 'epoch': 0.03}         \n",
      "{'loss': 0.8465, 'learning_rate': 0.00039906166657517335, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.00039906080079348184, 'epoch': 0.03}        \n",
      "{'loss': 0.8436, 'learning_rate': 0.0003990599346134946, 'epoch': 0.03}         \n",
      "{'loss': 0.8456, 'learning_rate': 0.0003990590680352136, 'epoch': 0.03}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003990582010586404, 'epoch': 0.03}         \n",
      "{'loss': 0.8451, 'learning_rate': 0.0003990573336837768, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039905646591062454, 'epoch': 0.03}        \n",
      "{'loss': 0.8456, 'learning_rate': 0.0003990555977391853, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039905472916946085, 'epoch': 0.03}        \n",
      "{'loss': 0.8457, 'learning_rate': 0.000399053860201453, 'epoch': 0.03}          \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003990529908351634, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039905212107059376, 'epoch': 0.03}         \n",
      "{'loss': 0.8458, 'learning_rate': 0.0003990512509077459, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003990503803466215, 'epoch': 0.03}         \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003990495093872224, 'epoch': 0.03}         \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003990486380295502, 'epoch': 0.03}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.00039904776627360677, 'epoch': 0.03}        \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039904689411939377, 'epoch': 0.03}        \n",
      "{'loss': 0.8473, 'learning_rate': 0.00039904602156691304, 'epoch': 0.03}        \n",
      "{'loss': 0.8456, 'learning_rate': 0.00039904514861616625, 'epoch': 0.03}        \n",
      "{'loss': 0.8469, 'learning_rate': 0.0003990442752671551, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.00039904340151988144, 'epoch': 0.03}        \n",
      "{'loss': 0.8443, 'learning_rate': 0.000399042527374347, 'epoch': 0.03}          \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003990416528305535, 'epoch': 0.03}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.00039904077788850266, 'epoch': 0.03}        \n",
      "{'loss': 0.8462, 'learning_rate': 0.0003990399025481963, 'epoch': 0.03}         \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003990390268096361, 'epoch': 0.03}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.00039903815067282393, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003990372741377614, 'epoch': 0.03}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039903639720445034, 'epoch': 0.03}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039903551987289246, 'epoch': 0.03}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003990346421430896, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003990337640150434, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003990328854887558, 'epoch': 0.03}         \n",
      "  3%|▉                              | 11000/351164 [2:47:34<81:45:46,  1.16it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8452, 'learning_rate': 0.00039903200656422834, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003990311272414629, 'epoch': 0.03}         \n",
      "{'loss': 0.8449, 'learning_rate': 0.00039903024752046125, 'epoch': 0.03}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003990293674012251, 'epoch': 0.03}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003990284868837562, 'epoch': 0.03}         \n",
      "{'loss': 0.8459, 'learning_rate': 0.00039902760596805637, 'epoch': 0.03}        \n",
      "{'loss': 0.8435, 'learning_rate': 0.0003990267246541273, 'epoch': 0.03}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003990258429419708, 'epoch': 0.03}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039902496083158866, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003990240783229826, 'epoch': 0.03}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.00039902319541615443, 'epoch': 0.03}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.00039902231211110586, 'epoch': 0.03}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.00039902142840783866, 'epoch': 0.03}        \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003990205443063547, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.0003990196598066557, 'epoch': 0.03}         \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003990187749087433, 'epoch': 0.03}         \n",
      "{'loss': 0.8454, 'learning_rate': 0.00039901788961261935, 'epoch': 0.03}        \n",
      "{'loss': 0.8456, 'learning_rate': 0.0003989983123539709, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039899741789947235, 'epoch': 0.03}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.000398996523046805, 'epoch': 0.03}          \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003989956277959707, 'epoch': 0.03}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003989947321469712, 'epoch': 0.03}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039899383609980825, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.00039899293965448365, 'epoch': 0.03}        \n",
      "{'loss': 0.8454, 'learning_rate': 0.00039899204281099924, 'epoch': 0.03}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039899114556935677, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003989902479295581, 'epoch': 0.03}         \n",
      "{'loss': 0.844, 'learning_rate': 0.00039898934989160493, 'epoch': 0.03}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039898845145549915, 'epoch': 0.03}        \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039898755262124245, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.0003989866533888368, 'epoch': 0.03}          \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003989857537582838, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039898485372958536, 'epoch': 0.03}        \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003989839533027433, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039898305247775933, 'epoch': 0.03}        \n",
      "{'loss': 0.8451, 'learning_rate': 0.00039898215125463537, 'epoch': 0.03}        \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039898124963337313, 'epoch': 0.03}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039898034761397445, 'epoch': 0.03}        \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039897944519644117, 'epoch': 0.03}        \n",
      "{'loss': 0.8451, 'learning_rate': 0.000398978542380775, 'epoch': 0.03}          \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003989776391669778, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039897673555505143, 'epoch': 0.03}        \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039897583154499755, 'epoch': 0.03}        \n",
      "{'loss': 0.8436, 'learning_rate': 0.0003989749271368182, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.000398974022330515, 'epoch': 0.03}          \n",
      "{'loss': 0.8457, 'learning_rate': 0.0003989731171260898, 'epoch': 0.03}         \n",
      "{'loss': 0.846, 'learning_rate': 0.0003989722115235444, 'epoch': 0.03}          \n",
      "{'loss': 0.845, 'learning_rate': 0.00039897130552288073, 'epoch': 0.03}         \n",
      "{'loss': 0.847, 'learning_rate': 0.0003989703991241005, 'epoch': 0.03}          \n",
      "{'loss': 0.8465, 'learning_rate': 0.0003989694923272055, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039896858513219756, 'epoch': 0.03}        \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039896767753907846, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039896676954785014, 'epoch': 0.03}        \n",
      "{'loss': 0.8459, 'learning_rate': 0.0003989658611585144, 'epoch': 0.03}         \n",
      "{'loss': 0.8461, 'learning_rate': 0.0003989649523710729, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.00039896404318552766, 'epoch': 0.03}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003989631336018804, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003989622236201329, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039896131324028704, 'epoch': 0.03}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003989604024623446, 'epoch': 0.03}          \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003989594912863074, 'epoch': 0.03}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003989585797121774, 'epoch': 0.03}         \n",
      "{'loss': 0.843, 'learning_rate': 0.0003989576677399563, 'epoch': 0.03}          \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039895675536964585, 'epoch': 0.03}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.00039895584260124804, 'epoch': 0.03}        \n",
      "{'loss': 0.844, 'learning_rate': 0.0003989549294347646, 'epoch': 0.03}          \n",
      "{'loss': 0.8458, 'learning_rate': 0.00039895401587019733, 'epoch': 0.03}        \n",
      "{'loss': 0.8458, 'learning_rate': 0.00039895310190754817, 'epoch': 0.03}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003989521875468189, 'epoch': 0.03}         \n",
      "{'loss': 0.8455, 'learning_rate': 0.00039895127278801135, 'epoch': 0.03}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003989503576311272, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039894944207616854, 'epoch': 0.03}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.000398948526123137, 'epoch': 0.03}          \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039894760977203454, 'epoch': 0.03}        \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039894669302286296, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003989457758756241, 'epoch': 0.03}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003989448583303197, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039894394038695176, 'epoch': 0.03}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003989430220455219, 'epoch': 0.03}         \n",
      "  3%|█                              | 11500/351164 [2:54:41<77:43:30,  1.21it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8454, 'learning_rate': 0.0003989421033060322, 'epoch': 0.03}         \n",
      "{'loss': 0.8459, 'learning_rate': 0.0003989411841684843, 'epoch': 0.03}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.0003989402646328802, 'epoch': 0.03}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039893934469922165, 'epoch': 0.03}        \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003989384243675105, 'epoch': 0.03}         \n",
      "{'loss': 0.8466, 'learning_rate': 0.0003989375036377485, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003989365825099377, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039893566098407975, 'epoch': 0.03}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003989347390601766, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039893381673823013, 'epoch': 0.03}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039893289401824204, 'epoch': 0.03}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003989319709002143, 'epoch': 0.03}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003989310473841487, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003989301234700471, 'epoch': 0.03}         \n",
      "{'loss': 0.8454, 'learning_rate': 0.0003989291991579113, 'epoch': 0.03}         \n",
      "{'loss': 0.8463, 'learning_rate': 0.0003989282744477433, 'epoch': 0.03}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003989273493395448, 'epoch': 0.03}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039892642383331775, 'epoch': 0.03}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039892549792906387, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003989245716267852, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039892364492648345, 'epoch': 0.03}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039892271782816053, 'epoch': 0.03}        \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003989217903318182, 'epoch': 0.03}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039892086243745845, 'epoch': 0.03}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039891993414508314, 'epoch': 0.03}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.000398919005454694, 'epoch': 0.03}          \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039891807636629296, 'epoch': 0.03}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039891714687988194, 'epoch': 0.03}        \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003989162169954627, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003989152867130371, 'epoch': 0.03}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039891435603260704, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003989134249541745, 'epoch': 0.03}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039891249347774106, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.0003989115616033089, 'epoch': 0.03}          \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003989106293308796, 'epoch': 0.03}         \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003989096966604552, 'epoch': 0.03}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.0003989087635920376, 'epoch': 0.03}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003989078301256285, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003989068962612299, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003989059619988436, 'epoch': 0.03}         \n",
      "{'loss': 0.8457, 'learning_rate': 0.0003989050273384715, 'epoch': 0.03}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003989040922801155, 'epoch': 0.03}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003989031568237774, 'epoch': 0.03}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039890222096945917, 'epoch': 0.03}        \n",
      "{'loss': 0.8452, 'learning_rate': 0.00039890128471716256, 'epoch': 0.03}        \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039890034806688954, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003988994110186419, 'epoch': 0.03}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039889847357242164, 'epoch': 0.03}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003988975357282305, 'epoch': 0.03}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003988965974860705, 'epoch': 0.03}         \n",
      "{'loss': 0.843, 'learning_rate': 0.0003988956588459433, 'epoch': 0.03}          \n",
      "{'loss': 0.8424, 'learning_rate': 0.000398894719807851, 'epoch': 0.03}          \n",
      "{'loss': 0.843, 'learning_rate': 0.0003988937803717954, 'epoch': 0.03}          \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039889284053777835, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003988919003058017, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039889095967586747, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003988900186479774, 'epoch': 0.03}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039888907722213345, 'epoch': 0.03}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003988881353983375, 'epoch': 0.03}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003988871931765914, 'epoch': 0.03}         \n",
      "{'loss': 0.8446, 'learning_rate': 0.000398886250556897, 'epoch': 0.03}          \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003988853075392563, 'epoch': 0.03}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003988843641236711, 'epoch': 0.03}         \n",
      "{'loss': 0.844, 'learning_rate': 0.0003988834203101433, 'epoch': 0.03}          \n",
      "{'loss': 0.844, 'learning_rate': 0.00039888247609867484, 'epoch': 0.03}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039888153148926755, 'epoch': 0.03}        \n",
      "{'loss': 0.8435, 'learning_rate': 0.0003988805864819233, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.000398879641076644, 'epoch': 0.03}          \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003988786952734317, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.000398877749072288, 'epoch': 0.03}          \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039887680247321504, 'epoch': 0.03}        \n",
      "{'loss': 0.8454, 'learning_rate': 0.00039887585547621464, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039887490808128857, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039887396028843894, 'epoch': 0.03}        \n",
      "{'loss': 0.844, 'learning_rate': 0.00039887301209766743, 'epoch': 0.03}         \n",
      "{'loss': 0.8476, 'learning_rate': 0.00039887206350897617, 'epoch': 0.03}        \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003988711145223669, 'epoch': 0.03}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003988701651378415, 'epoch': 0.03}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039886921535540196, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039886826517505013, 'epoch': 0.03}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003988673145967879, 'epoch': 0.03}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039886636362061723, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.00039886541224653995, 'epoch': 0.03}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003988644604745581, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039886350830467337, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003988625557368878, 'epoch': 0.03}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003988616027712033, 'epoch': 0.03}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039886064940762177, 'epoch': 0.03}        \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039885969564614507, 'epoch': 0.03}        \n",
      "{'loss': 0.8455, 'learning_rate': 0.0003988587414867752, 'epoch': 0.03}         \n",
      "{'loss': 0.8517, 'learning_rate': 0.0003988577869295139, 'epoch': 0.03}         \n",
      "{'loss': 0.8551, 'learning_rate': 0.0003988568319743633, 'epoch': 0.03}         \n",
      "{'loss': 0.8472, 'learning_rate': 0.00039885587662132516, 'epoch': 0.03}        \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003988549208704014, 'epoch': 0.03}         \n",
      "{'loss': 0.8451, 'learning_rate': 0.000398853964721594, 'epoch': 0.03}          \n",
      "{'loss': 0.845, 'learning_rate': 0.00039885300817490483, 'epoch': 0.03}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039885205123033583, 'epoch': 0.03}        \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039885109388788887, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003988501361475659, 'epoch': 0.03}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003988491780093688, 'epoch': 0.03}         \n",
      "  3%|█                              | 12000/351164 [3:01:49<76:15:45,  1.24it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<00:59,  2.34it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:18,  1.75it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:30,  1.52it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:35,  1.42it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:38,  1.37it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:04<01:42,  1.31it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:05<01:42,  1.30it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:47,  1.23it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:49,  1.20it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:45,  1.24it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:45,  1.22it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:09<01:45,  1.21it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:10<01:44,  1.21it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:11<01:41,  1.24it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:41,  1.23it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:44,  1.19it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:45,  1.17it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:14<01:45,  1.16it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:15<01:45,  1.15it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:16<01:49,  1.10it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:17<01:48,  1.10it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:18<01:45,  1.12it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:19<01:42,  1.14it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:41,  1.15it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:42,  1.12it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:22<01:43,  1.11it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:23<01:40,  1.12it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:23<01:37,  1.15it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:24<01:36,  1.15it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:33,  1.18it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:26<01:32,  1.18it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:27<01:34,  1.14it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:28<01:37,  1.10it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:29<01:33,  1.13it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:29<01:30,  1.16it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:30<01:29,  1.16it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:31<01:29,  1.15it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:32<01:31,  1.11it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:33<01:29,  1.13it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:34<01:24,  1.18it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:35<01:23,  1.18it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:35<01:23,  1.18it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:36<01:19,  1.22it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:37<01:18,  1.22it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:38<01:22,  1.16it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:39<01:20,  1.16it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:40<01:19,  1.17it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:41<01:19,  1.16it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:41<01:18,  1.16it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:42<01:14,  1.21it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:43<01:13,  1.21it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:44<01:12,  1.21it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:45<01:10,  1.23it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:46<01:13,  1.18it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:46<01:11,  1.19it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:47<01:08,  1.22it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:48<01:12,  1.15it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:49<01:10,  1.16it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:50<01:08,  1.18it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:51<01:06,  1.21it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:51<01:07,  1.17it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:52<01:06,  1.16it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:53<01:04,  1.20it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:54<01:02,  1.21it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:55<01:02,  1.21it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:56<01:03,  1.17it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:56<01:00,  1.20it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:57<01:01,  1.17it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:58<00:59,  1.18it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [00:59<00:59,  1.17it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:00<00:56,  1.22it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:01<00:55,  1.23it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:01<00:53,  1.26it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:02<00:52,  1.26it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:03<00:53,  1.22it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:04<00:54,  1.18it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:05<00:53,  1.19it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:06<00:53,  1.15it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:07<00:53,  1.14it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:07<00:52,  1.15it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:08<00:54,  1.09it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:09<00:52,  1.11it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:10<00:51,  1.11it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:11<00:49,  1.13it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:12<00:48,  1.13it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:13<00:48,  1.11it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:14<00:46,  1.13it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:15<00:45,  1.14it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:15<00:44,  1.14it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:16<00:42,  1.18it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:17<00:40,  1.20it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:18<00:40,  1.17it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:19<00:38,  1.21it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:20<00:39,  1.16it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:20<00:37,  1.18it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:21<00:36,  1.20it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:22<00:34,  1.24it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:23<00:34,  1.23it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:24<00:32,  1.25it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:24<00:32,  1.24it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:25<00:32,  1.20it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:26<00:32,  1.19it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:27<00:31,  1.19it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:28<00:29,  1.23it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:29<00:28,  1.21it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:29<00:27,  1.22it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:30<00:26,  1.23it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:31<00:26,  1.21it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:32<00:25,  1.23it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:33<00:24,  1.21it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:34<00:24,  1.20it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:34<00:22,  1.22it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:35<00:22,  1.22it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:36<00:21,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:37<00:20,  1.20it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:38<00:20,  1.18it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:39<00:19,  1.19it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:39<00:18,  1.19it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:40<00:17,  1.17it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:41<00:16,  1.19it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:42<00:16,  1.16it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:43<00:15,  1.17it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:44<00:14,  1.19it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:44<00:13,  1.20it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:45<00:12,  1.18it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:46<00:11,  1.20it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:47<00:10,  1.21it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:48<00:09,  1.21it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:49<00:08,  1.24it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:49<00:08,  1.23it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:50<00:07,  1.20it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:51<00:06,  1.23it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:52<00:05,  1.22it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:53<00:04,  1.23it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:53<00:03,  1.27it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:54<00:03,  1.22it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:55<00:02,  1.20it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:56<00:01,  1.20it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:57<00:00,  1.21it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [01:58<00:00,  1.17it/s]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8402748107910156, 'eval_cer': 0.015931633185746603, 'eval_runtime': 125.7945, 'eval_samples_per_second': 71.474, 'eval_steps_per_second': 1.121, 'epoch': 0.03}\n",
      "  3%|█                              | 12000/351164 [3:03:54<76:15:45,  1.24it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [01:59<00:00,  1.17it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8422, 'learning_rate': 0.00039884821947329955, 'epoch': 0.03}        \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003988472605393601, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039884630120755213, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039884534147787787, 'epoch': 0.03}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039884438135033903, 'epoch': 0.03}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039884342082493763, 'epoch': 0.03}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039884245990167555, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039884149858055476, 'epoch': 0.03}        \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039884053686157714, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003988395747447446, 'epoch': 0.03}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039883861223005907, 'epoch': 0.03}        \n",
      "{'loss': 0.8435, 'learning_rate': 0.0003988376493175226, 'epoch': 0.03}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003988366860071369, 'epoch': 0.03}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039883572229890406, 'epoch': 0.03}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039883475819282594, 'epoch': 0.03}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003988337936889045, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003988328287871416, 'epoch': 0.03}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039883205657928683, 'epoch': 0.03}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039883109096141433, 'epoch': 0.03}        \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039883012494570583, 'epoch': 0.03}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039882915853216327, 'epoch': 0.03}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039882819172078855, 'epoch': 0.03}        \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003988272245115837, 'epoch': 0.03}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003988262569045505, 'epoch': 0.03}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.000398825288899691, 'epoch': 0.03}          \n",
      "{'loss': 0.843, 'learning_rate': 0.0003988243204970072, 'epoch': 0.03}          \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039882335169650083, 'epoch': 0.03}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039882238249817404, 'epoch': 0.03}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039882141290202864, 'epoch': 0.03}        \n",
      "{'loss': 0.843, 'learning_rate': 0.0003988204429080666, 'epoch': 0.03}          \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003988194725162899, 'epoch': 0.03}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039881850172670044, 'epoch': 0.03}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003988175305393002, 'epoch': 0.03}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039881655895409105, 'epoch': 0.03}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.000398815586971075, 'epoch': 0.03}          \n",
      "{'loss': 0.843, 'learning_rate': 0.00039881461459025395, 'epoch': 0.03}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003988136418116299, 'epoch': 0.03}          \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003988126686352048, 'epoch': 0.03}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003988116950609805, 'epoch': 0.03}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003988107210889591, 'epoch': 0.03}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003988097467191424, 'epoch': 0.03}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039880877195153244, 'epoch': 0.03}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003988077967861311, 'epoch': 0.03}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003988068212229403, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003988058452619622, 'epoch': 0.03}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003988048689031986, 'epoch': 0.03}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039880389214665146, 'epoch': 0.03}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003988029149923227, 'epoch': 0.03}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003988019374402144, 'epoch': 0.03}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003988009594903284, 'epoch': 0.03}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039879998114266665, 'epoch': 0.03}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003987990023972312, 'epoch': 0.03}          \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039879802325402394, 'epoch': 0.03}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039879704371304685, 'epoch': 0.03}        \n",
      "{'loss': 0.844, 'learning_rate': 0.0003987960637743019, 'epoch': 0.03}          \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039879508343779104, 'epoch': 0.03}        \n",
      "{'loss': 0.845, 'learning_rate': 0.0003987941027035162, 'epoch': 0.03}          \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003987931215714794, 'epoch': 0.03}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003987921400416826, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003987911581141277, 'epoch': 0.04}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003987901757888167, 'epoch': 0.04}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.0003987891930657516, 'epoch': 0.04}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003987882099449343, 'epoch': 0.04}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003987872264263668, 'epoch': 0.04}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039878624251005114, 'epoch': 0.04}        \n",
      "{'loss': 0.8443, 'learning_rate': 0.0003987852581959892, 'epoch': 0.04}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039878427348418295, 'epoch': 0.04}        \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003987832883746344, 'epoch': 0.04}         \n",
      "{'loss': 0.843, 'learning_rate': 0.00039878230286734544, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039878131696231817, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003987803306595545, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003987793439590563, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003987783568608258, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003987773693648647, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039877638147117506, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.000398775393179759, 'epoch': 0.04}          \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039877440449061837, 'epoch': 0.04}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003987734154037551, 'epoch': 0.04}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.00039877242591917133, 'epoch': 0.04}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003987714360368689, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039877044575684984, 'epoch': 0.04}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003987694550791161, 'epoch': 0.04}         \n",
      "{'loss': 0.844, 'learning_rate': 0.0003987684640036697, 'epoch': 0.04}          \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039876747253051267, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039876648065964685, 'epoch': 0.04}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003987654883910744, 'epoch': 0.04}         \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003987644957247971, 'epoch': 0.04}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003987635026608172, 'epoch': 0.04}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039876250919913646, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039876151533975695, 'epoch': 0.04}        \n",
      "{'loss': 0.8428, 'learning_rate': 0.00039876052108268065, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039875952642790956, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039875853137544563, 'epoch': 0.04}        \n",
      "{'loss': 0.8427, 'learning_rate': 0.000398757535925291, 'epoch': 0.04}          \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039875654007744745, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003987555438319171, 'epoch': 0.04}          \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003987545471887019, 'epoch': 0.04}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039875355014780384, 'epoch': 0.04}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.000398752552709225, 'epoch': 0.04}          \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039875155487296727, 'epoch': 0.04}        \n",
      "  4%|█                              | 12500/351164 [3:11:02<79:34:07,  1.18it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8452, 'learning_rate': 0.0003987505566390327, 'epoch': 0.04}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.00039874955800742325, 'epoch': 0.04}        \n",
      "{'loss': 0.845, 'learning_rate': 0.00039874855897814094, 'epoch': 0.04}         \n",
      "{'loss': 0.8458, 'learning_rate': 0.0003987475595511878, 'epoch': 0.04}         \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003987465597265658, 'epoch': 0.04}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039874555950427694, 'epoch': 0.04}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039874455888432324, 'epoch': 0.04}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003987435578667066, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039874255645142915, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003987415546384929, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003987405524278998, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003987395498196518, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.000398738546813751, 'epoch': 0.04}          \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039873754341019935, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003987365396089989, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039873553541015165, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003987345308136596, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039873352581952477, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003987325204277491, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003987315146383347, 'epoch': 0.04}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039873050845128354, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003987295018665976, 'epoch': 0.04}         \n",
      "{'loss': 0.844, 'learning_rate': 0.000398728494884279, 'epoch': 0.04}           \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003987274875043297, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003987264797267516, 'epoch': 0.04}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003987254715515469, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003987244629787175, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039872345400826547, 'epoch': 0.04}        \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039872244464019284, 'epoch': 0.04}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.00039872143487450153, 'epoch': 0.04}        \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003987204247111937, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003987194141502713, 'epoch': 0.04}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.00039871840319173635, 'epoch': 0.04}        \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003987173918355908, 'epoch': 0.04}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.00039871638008183685, 'epoch': 0.04}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003987153679304764, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039871435538151143, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039871334243494415, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003987123290907764, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039871131534901036, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003987103012096479, 'epoch': 0.04}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039870928667269114, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039870827173814214, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039870725640600286, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003987062406762754, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003987052245489617, 'epoch': 0.04}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039870420802406385, 'epoch': 0.04}        \n",
      "{'loss': 0.843, 'learning_rate': 0.0003987031911015839, 'epoch': 0.04}          \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039870217378152386, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039870115606388583, 'epoch': 0.04}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039870013794867173, 'epoch': 0.04}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003986991194358836, 'epoch': 0.04}         \n",
      "{'loss': 0.8456, 'learning_rate': 0.0003986981005255237, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039869708121759373, 'epoch': 0.04}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.00039869606151209596, 'epoch': 0.04}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.00039869504140903236, 'epoch': 0.04}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039869402090840505, 'epoch': 0.04}        \n",
      "{'loss': 0.8454, 'learning_rate': 0.00039869300001021593, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039869197871446717, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039869095702116066, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003986899349302987, 'epoch': 0.04}          \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003986889124418831, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039868788955591596, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039868686627239934, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003986858425913353, 'epoch': 0.04}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.000398684818512726, 'epoch': 0.04}          \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039868379403657325, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003986827691628793, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003986817438916461, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039868071822287576, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.00039867969215657027, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003986786656927317, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.0003986776388313621, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039867661157246367, 'epoch': 0.04}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039867558391603816, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003986745558620879, 'epoch': 0.04}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003986735274106149, 'epoch': 0.04}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039867249856162106, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039867146931510866, 'epoch': 0.04}        \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039867043967107955, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039866940962953595, 'epoch': 0.04}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003986683791904799, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003986673483539133, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039866631711983836, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039866528548825715, 'epoch': 0.04}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.00039866425345917175, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039866322103258406, 'epoch': 0.04}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039866218820849635, 'epoch': 0.04}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003986611549869106, 'epoch': 0.04}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.00039866012136782877, 'epoch': 0.04}        \n",
      "{'loss': 0.843, 'learning_rate': 0.0003986590873512531, 'epoch': 0.04}          \n",
      "{'loss': 0.843, 'learning_rate': 0.0003986580529371857, 'epoch': 0.04}          \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003986570181256284, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003986559829165834, 'epoch': 0.04}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039865494731005285, 'epoch': 0.04}        \n",
      "{'loss': 0.843, 'learning_rate': 0.00039865391130603867, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039865287490454306, 'epoch': 0.04}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.000398651838105568, 'epoch': 0.04}          \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003986508009091156, 'epoch': 0.04}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.000398649763315188, 'epoch': 0.04}          \n",
      "  4%|█▏                             | 13000/351164 [3:18:09<77:56:22,  1.21it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8417, 'learning_rate': 0.00039864872532378723, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003986476869349153, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039864664814857437, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039864560896476646, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003986445693834937, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003986435294047581, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003986424890285619, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.000398641448254907, 'epoch': 0.04}          \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003986404070837956, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003986393655152297, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039863832354921144, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003986372811857429, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003986362384248261, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003986351952664632, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003986341517106563, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039863310775740745, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.00039863206340671873, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039863101865859223, 'epoch': 0.04}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039862997351303007, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003986289279700343, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003986278820296071, 'epoch': 0.04}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039862683569175046, 'epoch': 0.04}        \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003986257889564665, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039862474182375735, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003986236942936251, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003986226463660718, 'epoch': 0.04}          \n",
      "{'loss': 0.8447, 'learning_rate': 0.0003986215980410996, 'epoch': 0.04}         \n",
      "{'loss': 0.8474, 'learning_rate': 0.0003986205493187105, 'epoch': 0.04}         \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003986195001989067, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003986184506816903, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003986174007670634, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039861635045502803, 'epoch': 0.04}        \n",
      "{'loss': 0.8444, 'learning_rate': 0.0003986152997455864, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039861424863874044, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003986131971344924, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039861214523284437, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039861109293379835, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003986100402373566, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.00039860898714352117, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039860793365229403, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003986068797636775, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003986058254776736, 'epoch': 0.04}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003986047707942844, 'epoch': 0.04}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003986037157135121, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039860266023535864, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039860160435982634, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003986005480869172, 'epoch': 0.04}         \n",
      "{'loss': 0.843, 'learning_rate': 0.00039859949141663327, 'epoch': 0.04}         \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003985984343489769, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003985973768839499, 'epoch': 0.04}         \n",
      "{'loss': 0.8464, 'learning_rate': 0.00039859631902155454, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039859526076179303, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039859420210466736, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003985931430501797, 'epoch': 0.04}          \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003985920835983321, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039859102374912675, 'epoch': 0.04}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.00039858996350256574, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039858890285865124, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003985878418173853, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039858678037877005, 'epoch': 0.04}        \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003985857185428077, 'epoch': 0.04}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039858465630950024, 'epoch': 0.04}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039858359367884994, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003985825306508588, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.000398581467225529, 'epoch': 0.04}          \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003985804034028627, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.000398579339182862, 'epoch': 0.04}          \n",
      "{'loss': 0.8415, 'learning_rate': 0.000398578274565529, 'epoch': 0.04}          \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039857720955086587, 'epoch': 0.04}        \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003985761441388748, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039857507832955776, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.000398574012122917, 'epoch': 0.04}           \n",
      "{'loss': 0.843, 'learning_rate': 0.00039857294551895467, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003985718785176728, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039857081111907355, 'epoch': 0.04}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003985697433231592, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039856867512993175, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003985676065393933, 'epoch': 0.04}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039856653755154613, 'epoch': 0.04}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039856546816639224, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003985643983839339, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039856332820417315, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039856225762711217, 'epoch': 0.04}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039856118665275306, 'epoch': 0.04}        \n",
      "{'loss': 0.841, 'learning_rate': 0.000398560115281098, 'epoch': 0.04}           \n",
      "{'loss': 0.842, 'learning_rate': 0.00039855904351214917, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039855797134590867, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039855689878237865, 'epoch': 0.04}        \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039855582582156124, 'epoch': 0.04}        \n",
      "{'loss': 0.845, 'learning_rate': 0.00039855475246345864, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039855367870807293, 'epoch': 0.04}        \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003985526045554063, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003985515300054609, 'epoch': 0.04}          \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003985504550582388, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003985493797137424, 'epoch': 0.04}          \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003985483039719735, 'epoch': 0.04}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003985472278329345, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039854615129662746, 'epoch': 0.04}        \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039854507436305455, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039854399703221797, 'epoch': 0.04}        \n",
      "  4%|█▏                             | 13500/351164 [3:25:17<80:15:13,  1.17it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.842, 'learning_rate': 0.00039854291930411975, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003985418411787622, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039854076265614734, 'epoch': 0.04}        \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039853968373627745, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003985386044191547, 'epoch': 0.04}         \n",
      "{'loss': 0.8428, 'learning_rate': 0.000398537524704781, 'epoch': 0.04}          \n",
      "{'loss': 0.8428, 'learning_rate': 0.00039853644459315885, 'epoch': 0.04}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003985353640842902, 'epoch': 0.04}         \n",
      "{'loss': 0.843, 'learning_rate': 0.0003985342831781773, 'epoch': 0.04}          \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003985332018748222, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.00039853212017422723, 'epoch': 0.04}        \n",
      "{'loss': 0.8462, 'learning_rate': 0.00039853103807639445, 'epoch': 0.04}        \n",
      "{'loss': 0.8447, 'learning_rate': 0.000398529955581326, 'epoch': 0.04}          \n",
      "{'loss': 0.844, 'learning_rate': 0.0003985288726890241, 'epoch': 0.04}          \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039852778939949095, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.00039852670571272866, 'epoch': 0.04}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039852562162873937, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003985245371475253, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039852345226908863, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039852236699343147, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003985212813205561, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003985201952504646, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039851910878315914, 'epoch': 0.04}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003985180219186419, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039851693465691514, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003985158469979809, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039851475894184154, 'epoch': 0.04}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039851367048849906, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003985125816379557, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039851149239021366, 'epoch': 0.04}        \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039851040274527504, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003985093127031421, 'epoch': 0.04}         \n",
      "{'loss': 0.8443, 'learning_rate': 0.00039850822226381705, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039850713142730197, 'epoch': 0.04}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039850604019359923, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039850494856271074, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003985038565346388, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003985027641093857, 'epoch': 0.04}         \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039850167128695354, 'epoch': 0.04}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003985005780673445, 'epoch': 0.04}         \n",
      "{'loss': 0.8448, 'learning_rate': 0.0003984994844505608, 'epoch': 0.04}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.0003984983904366046, 'epoch': 0.04}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039849729602547805, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003984962012171834, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039849510601172285, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039849401040909855, 'epoch': 0.04}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003984929144093128, 'epoch': 0.04}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003984918180123676, 'epoch': 0.04}         \n",
      "{'loss': 0.8437, 'learning_rate': 0.0003984907212182653, 'epoch': 0.04}         \n",
      "{'loss': 0.8516, 'learning_rate': 0.00039848962402700794, 'epoch': 0.04}        \n",
      "{'loss': 0.8479, 'learning_rate': 0.0003984885264385979, 'epoch': 0.04}         \n",
      "{'loss': 0.8473, 'learning_rate': 0.0003984874284530373, 'epoch': 0.04}         \n",
      "{'loss': 0.8468, 'learning_rate': 0.0003984863300703283, 'epoch': 0.04}         \n",
      "{'loss': 0.846, 'learning_rate': 0.0003984852312904732, 'epoch': 0.04}          \n",
      "{'loss': 0.8453, 'learning_rate': 0.0003984841321134741, 'epoch': 0.04}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.00039848303253933314, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039848193256805263, 'epoch': 0.04}        \n",
      "{'loss': 0.8432, 'learning_rate': 0.0003984808321996348, 'epoch': 0.04}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003984797314340818, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003984786302713958, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.000398477528711579, 'epoch': 0.04}          \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003984764267546337, 'epoch': 0.04}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.000398475324400562, 'epoch': 0.04}          \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003984742216493662, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003984731185010484, 'epoch': 0.04}          \n",
      "{'loss': 0.841, 'learning_rate': 0.0003984720149556109, 'epoch': 0.04}          \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039847091101305584, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003984698066733855, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.000398468701936602, 'epoch': 0.04}           \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003984675968027076, 'epoch': 0.04}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039846649127170457, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.000398465385343595, 'epoch': 0.04}          \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039846427901838117, 'epoch': 0.04}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003984631722960654, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039846206517664965, 'epoch': 0.04}        \n",
      "{'loss': 0.8427, 'learning_rate': 0.0003984609576601363, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003984598497465276, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003984587414358257, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003984576327280328, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003984565236231512, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.000398455414121183, 'epoch': 0.04}          \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003984543042221305, 'epoch': 0.04}         \n",
      "{'loss': 0.8451, 'learning_rate': 0.0003984531939259959, 'epoch': 0.04}         \n",
      "{'loss': 0.8482, 'learning_rate': 0.0003984520832327815, 'epoch': 0.04}         \n",
      "{'loss': 0.8452, 'learning_rate': 0.0003984509721424894, 'epoch': 0.04}         \n",
      "{'loss': 0.8442, 'learning_rate': 0.00039844986065512187, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003984487487706812, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003984476364891695, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.000398446523810589, 'epoch': 0.04}          \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039844541073494203, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039844429726223075, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039844318339245737, 'epoch': 0.04}        \n",
      "{'loss': 0.8448, 'learning_rate': 0.00039844206912562416, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003984409544617334, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039843983940078727, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003984387239427879, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003984376080877377, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039843649183563874, 'epoch': 0.04}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039843537518649335, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003984342581403037, 'epoch': 0.04}         \n",
      "  4%|█▏                             | 14000/351164 [3:32:25<81:50:17,  1.14it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<00:54,  2.53it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:18,  1.75it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:29,  1.52it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:39,  1.36it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:44,  1.29it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:04<01:43,  1.29it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:05<01:43,  1.28it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:48,  1.21it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:47,  1.22it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:45,  1.24it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:46,  1.21it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:09<01:45,  1.21it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:10<01:43,  1.22it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:11<01:43,  1.22it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:42,  1.22it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:45,  1.18it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:43,  1.18it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:15<01:46,  1.14it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:15<01:44,  1.16it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:16<01:47,  1.12it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:17<01:44,  1.14it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:18<01:39,  1.18it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:19<01:38,  1.19it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:37,  1.19it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:37,  1.17it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:21<01:37,  1.17it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:22<01:34,  1.20it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:23<01:30,  1.23it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:24<01:31,  1.21it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:29,  1.23it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:25<01:29,  1.22it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:26<01:30,  1.19it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:27<01:32,  1.16it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:28<01:29,  1.19it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:29<01:27,  1.20it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:30<01:26,  1.20it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:30<01:26,  1.20it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:31<01:25,  1.20it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:32<01:24,  1.20it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:33<01:20,  1.24it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:34<01:23,  1.19it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:35<01:24,  1.16it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:35<01:19,  1.21it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:36<01:18,  1.23it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:37<01:19,  1.20it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:38<01:15,  1.24it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:39<01:14,  1.25it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:39<01:14,  1.24it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:40<01:14,  1.22it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:41<01:12,  1.25it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:42<01:12,  1.23it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:43<01:11,  1.24it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:44<01:09,  1.25it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:44<01:08,  1.25it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:45<01:08,  1.24it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:46<01:06,  1.26it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:47<01:07,  1.23it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:48<01:07,  1.22it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:48<01:06,  1.22it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:49<01:06,  1.19it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:50<01:06,  1.20it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:51<01:05,  1.20it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:52<01:02,  1.23it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:53<01:04,  1.19it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:53<01:02,  1.19it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:54<01:03,  1.16it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:55<01:02,  1.17it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:56<01:05,  1.09it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:57<01:05,  1.09it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [00:58<01:02,  1.11it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [00:59<01:00,  1.13it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:00<01:00,  1.12it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:01<00:57,  1.16it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:02<00:58,  1.13it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:02<00:57,  1.14it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:03<00:56,  1.13it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:04<00:55,  1.13it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:05<00:54,  1.14it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:06<00:54,  1.12it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:07<00:53,  1.13it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:08<00:53,  1.09it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:09<00:51,  1.12it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:09<00:49,  1.14it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:10<00:48,  1.15it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:11<00:48,  1.14it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:12<00:46,  1.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:13<00:44,  1.20it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:14<00:43,  1.19it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:15<00:43,  1.19it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:15<00:41,  1.20it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:16<00:39,  1.24it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:17<00:40,  1.20it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:18<00:38,  1.22it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:19<00:42,  1.09it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:20<00:40,  1.10it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:21<00:38,  1.14it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:21<00:36,  1.19it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:22<00:35,  1.17it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:23<00:33,  1.21it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:24<00:32,  1.23it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:25<00:34,  1.13it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:26<00:32,  1.16it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:26<00:31,  1.16it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:27<00:29,  1.21it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:28<00:30,  1.15it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:29<00:28,  1.17it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:30<00:27,  1.20it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:31<00:26,  1.19it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:32<00:26,  1.17it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:32<00:25,  1.17it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:33<00:24,  1.19it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:34<00:23,  1.21it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:35<00:22,  1.21it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:36<00:21,  1.19it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:37<00:21,  1.18it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:37<00:20,  1.17it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:38<00:19,  1.16it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:39<00:18,  1.18it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:40<00:17,  1.18it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:41<00:16,  1.22it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:42<00:15,  1.19it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:43<00:15,  1.14it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:43<00:14,  1.18it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:44<00:13,  1.17it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:45<00:12,  1.16it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:46<00:11,  1.18it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:47<00:11,  1.15it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:48<00:10,  1.15it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:49<00:09,  1.16it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:49<00:08,  1.17it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:50<00:07,  1.17it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:51<00:06,  1.17it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:52<00:05,  1.19it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:53<00:04,  1.21it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:54<00:04,  1.20it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:54<00:03,  1.20it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:55<00:02,  1.19it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:56<00:01,  1.20it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:57<00:00,  1.24it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [01:58<00:00,  1.19it/s]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8392199873924255, 'eval_cer': 0.013444706549621667, 'eval_runtime': 125.9022, 'eval_samples_per_second': 71.413, 'eval_steps_per_second': 1.12, 'epoch': 0.04}\n",
      "  4%|█▏                             | 14000/351164 [3:34:31<81:50:17,  1.14it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [01:59<00:00,  1.19it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8396, 'learning_rate': 0.0003984331406970721, 'epoch': 0.04}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003984320228568008, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039843090461949196, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039842978598514785, 'epoch': 0.04}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039842866695377074, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.00039842754752536275, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039842642769992627, 'epoch': 0.04}        \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039842530747746346, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039842418685797655, 'epoch': 0.04}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039842306584146777, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039842194442793954, 'epoch': 0.04}        \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003984208226173938, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039841970040983306, 'epoch': 0.04}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039841857780525947, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003984174548036753, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039841633140508265, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039841520760948397, 'epoch': 0.04}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003984140834168814, 'epoch': 0.04}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039841295882727724, 'epoch': 0.04}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039841205886975424, 'epoch': 0.04}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003984109335655528, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039840980786435605, 'epoch': 0.04}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.00039840868176616625, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039840755527098564, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.00039840642837881654, 'epoch': 0.04}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003984053010896611, 'epoch': 0.04}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039840417340352157, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003984030453204003, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003984019168402995, 'epoch': 0.04}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003984007879632214, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039839965868916833, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039839852901814245, 'epoch': 0.04}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003983973989501461, 'epoch': 0.04}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039839626848518154, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039839513762325097, 'epoch': 0.04}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039839400636435674, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.000398392874708501, 'epoch': 0.04}          \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003983917426556861, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003983906102059143, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003983894773591879, 'epoch': 0.04}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003983883441155091, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039838721047488014, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.00039838607643730335, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039838494200278095, 'epoch': 0.04}        \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003983838071713153, 'epoch': 0.04}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003983826719429086, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003983815363175631, 'epoch': 0.04}         \n",
      "{'loss': 0.8453, 'learning_rate': 0.0003983804002952812, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003983792638760649, 'epoch': 0.04}         \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003983781270599168, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.000398376989846839, 'epoch': 0.04}          \n",
      "{'loss': 0.8429, 'learning_rate': 0.0003983758522368338, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039837471422990347, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003983735758260503, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039837243702527656, 'epoch': 0.04}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039837129782758455, 'epoch': 0.04}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003983701582329765, 'epoch': 0.04}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039836901824145477, 'epoch': 0.04}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039836787785302156, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039836673706767923, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039836559588542995, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003983644543062761, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039836331233021995, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003983621699572638, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039836102718740984, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003983598840206604, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003983587404570178, 'epoch': 0.04}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039835759649648443, 'epoch': 0.04}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039835645213906235, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.000398355307384754, 'epoch': 0.04}          \n",
      "{'loss': 0.8496, 'learning_rate': 0.00039835416223356167, 'epoch': 0.04}        \n",
      "{'loss': 0.8446, 'learning_rate': 0.0003983530166854876, 'epoch': 0.04}         \n",
      "{'loss': 0.8445, 'learning_rate': 0.00039835187074053417, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003983507243987035, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039834957765999806, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039834843052441996, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003983472829919717, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003983461350626555, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003983449867364736, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003983438380134283, 'epoch': 0.04}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.000398342688893522, 'epoch': 0.04}          \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003983415393767569, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039834038946313536, 'epoch': 0.04}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039833923915265964, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003983380884453321, 'epoch': 0.04}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039833693734115495, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003983357858401306, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003983346339422612, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003983334816475492, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003983323289559969, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003983311758676065, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003983300223823804, 'epoch': 0.04}         \n",
      "{'loss': 0.8441, 'learning_rate': 0.0003983288685003209, 'epoch': 0.04}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003983277142214303, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003983265595457108, 'epoch': 0.04}          \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003983254044731649, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003983242490037948, 'epoch': 0.04}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039832309313760284, 'epoch': 0.04}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003983219368745913, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003983207802147625, 'epoch': 0.04}         \n",
      "  4%|█▎                             | 14500/351164 [3:41:43<82:54:52,  1.13it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8436, 'learning_rate': 0.00039831962315811886, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003983184657046625, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039831730785439587, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.0003983161496073213, 'epoch': 0.04}          \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039831499096344106, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003983138319227575, 'epoch': 0.04}          \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003983126724852729, 'epoch': 0.04}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.0003983115126509895, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039831035241990985, 'epoch': 0.04}        \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039830919179203604, 'epoch': 0.04}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003983080307673705, 'epoch': 0.04}         \n",
      "{'loss': 0.8454, 'learning_rate': 0.0003983068693459156, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003983057075276736, 'epoch': 0.04}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003983045453126468, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003983033827008375, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003983022196922482, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.000398301056286881, 'epoch': 0.04}          \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003982998924847384, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039829872828582265, 'epoch': 0.04}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003982975636901361, 'epoch': 0.04}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039829639869768107, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003982952333084599, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003982940675224749, 'epoch': 0.04}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039829290133972845, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003982917347602229, 'epoch': 0.04}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039829056778396046, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039828940041094357, 'epoch': 0.04}        \n",
      "{'loss': 0.8434, 'learning_rate': 0.0003982882326411745, 'epoch': 0.04}         \n",
      "{'loss': 0.8488, 'learning_rate': 0.0003982870644746557, 'epoch': 0.04}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039828589591138936, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003982847269513779, 'epoch': 0.04}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003982835575946237, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.000398282387841129, 'epoch': 0.04}          \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039828121769089624, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003982800471439277, 'epoch': 0.04}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003982788762002257, 'epoch': 0.04}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.00039827770485979265, 'epoch': 0.04}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003982765331226308, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003982753609887426, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003982741884581304, 'epoch': 0.04}          \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003982730155307964, 'epoch': 0.04}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003982718422067431, 'epoch': 0.04}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003982706684859728, 'epoch': 0.04}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039826949436848786, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003982683198542906, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.0003982671449433833, 'epoch': 0.04}          \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003982659696357684, 'epoch': 0.04}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003982647939314483, 'epoch': 0.04}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039826361783042527, 'epoch': 0.04}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003982624413327017, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039826126443827994, 'epoch': 0.04}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039826008714716226, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039825890945935117, 'epoch': 0.04}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003982577313748489, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039825655289365793, 'epoch': 0.04}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003982553740157805, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.000398254194741219, 'epoch': 0.04}          \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039825301506997575, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039825183500205325, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.0003982506545374537, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003982494736761796, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003982482924182332, 'epoch': 0.04}          \n",
      "{'loss': 0.8417, 'learning_rate': 0.000398247110763617, 'epoch': 0.04}          \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039824592871233314, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.00039824474626438424, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039824356341977243, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039824238017850027, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039824119654057003, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003982400125059841, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003982388280747449, 'epoch': 0.04}          \n",
      "{'loss': 0.841, 'learning_rate': 0.00039823764324685467, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039823645802231593, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039823527240113093, 'epoch': 0.04}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003982340863833021, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003982328999688318, 'epoch': 0.04}          \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003982317131577224, 'epoch': 0.04}         \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039823052594997635, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003982293383455959, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003982281503445835, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003982269619469415, 'epoch': 0.04}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003982257731526723, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039822458396177827, 'epoch': 0.04}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003982233943742618, 'epoch': 0.04}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003982222043901252, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.000398221014009371, 'epoch': 0.04}          \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039821982323200145, 'epoch': 0.04}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.000398218632058019, 'epoch': 0.04}          \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003982174404874259, 'epoch': 0.04}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003982162485202248, 'epoch': 0.04}          \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039821505615641784, 'epoch': 0.04}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003982138633960075, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039821267023899614, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003982114766853862, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039821028273518, 'epoch': 0.04}           \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039820908838838, 'epoch': 0.04}           \n",
      "{'loss': 0.8432, 'learning_rate': 0.00039820789364498855, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039820669850500803, 'epoch': 0.04}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003982055029684409, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003982043070352894, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003982031107055561, 'epoch': 0.04}         \n",
      "  4%|█▎                             | 15000/351164 [3:48:55<84:32:12,  1.10it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8404, 'learning_rate': 0.00039820191397924325, 'epoch': 0.04}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039820071685635333, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003981995193368887, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039819832142085185, 'epoch': 0.04}        \n",
      "{'loss': 0.844, 'learning_rate': 0.000398197123108245, 'epoch': 0.04}           \n",
      "{'loss': 0.8449, 'learning_rate': 0.0003981959243990707, 'epoch': 0.04}         \n",
      "{'loss': 0.844, 'learning_rate': 0.00039819472529333124, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003981935257910292, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039819232589216667, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003981911255967464, 'epoch': 0.04}         \n",
      "{'loss': 0.8426, 'learning_rate': 0.00039818992490477047, 'epoch': 0.04}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003981887238162416, 'epoch': 0.04}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.00039818752233116187, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039818632044953396, 'epoch': 0.04}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003981851181713601, 'epoch': 0.04}         \n",
      "{'loss': 0.843, 'learning_rate': 0.0003981839154966427, 'epoch': 0.04}          \n",
      "{'loss': 0.842, 'learning_rate': 0.0003981827124253844, 'epoch': 0.04}          \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003981815089575873, 'epoch': 0.04}         \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003981803050932539, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039817910083238674, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003981778961749881, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003981766911210604, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003981754856706061, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003981742798236276, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003981730735801273, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003981718669401076, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003981706599035709, 'epoch': 0.04}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003981694524705197, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003981682446409563, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039816703641488326, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003981658277923029, 'epoch': 0.04}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039816461877321757, 'epoch': 0.04}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039816340935762987, 'epoch': 0.04}        \n",
      "{'loss': 0.839, 'learning_rate': 0.000398162199545542, 'epoch': 0.04}           \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003981609893369566, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039815977873187595, 'epoch': 0.04}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003981585677303025, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003981573563322388, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003981561445376871, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003981549323466498, 'epoch': 0.04}         \n",
      "{'loss': 0.8389, 'learning_rate': 0.0003981537197591295, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003981525067751285, 'epoch': 0.04}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003981512933946493, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039815007961769433, 'epoch': 0.04}        \n",
      "{'loss': 0.8428, 'learning_rate': 0.0003981488654442659, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.00039814765087436656, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003981464359079987, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003981452205451648, 'epoch': 0.04}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003981440047858672, 'epoch': 0.04}         \n",
      "{'loss': 0.8433, 'learning_rate': 0.00039814278863010836, 'epoch': 0.04}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003981415720778907, 'epoch': 0.04}         \n",
      "{'loss': 0.8425, 'learning_rate': 0.00039814035512921673, 'epoch': 0.04}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039813913778408887, 'epoch': 0.04}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003981379200425095, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003981367019044811, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039813548337000606, 'epoch': 0.04}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039813426443908686, 'epoch': 0.04}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039813304511172594, 'epoch': 0.04}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003981318253879256, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003981306052676886, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039812938475101707, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039812816383791365, 'epoch': 0.04}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039812694252838065, 'epoch': 0.04}          \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039812572082242057, 'epoch': 0.04}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039812449872003583, 'epoch': 0.04}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039812327622122895, 'epoch': 0.04}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039812205332600225, 'epoch': 0.04}          \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003981208300343583, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003981196063462995, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003981183822618283, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039811715778094713, 'epoch': 0.04}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039811593290365845, 'epoch': 0.04}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039811470762996475, 'epoch': 0.04}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003981134819598684, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003981122558933719, 'epoch': 0.04}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039811102943047773, 'epoch': 0.04}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003981098025711883, 'epoch': 0.04}         \n",
      "{'loss': 0.8438, 'learning_rate': 0.0003981085753155061, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039810734766343355, 'epoch': 0.04}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003981061196149731, 'epoch': 0.04}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003981048911701273, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003981036623288985, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003981024330912892, 'epoch': 0.04}         \n",
      "{'loss': 0.8435, 'learning_rate': 0.0003981012034573019, 'epoch': 0.04}         \n",
      "{'loss': 0.845, 'learning_rate': 0.00039809997342693895, 'epoch': 0.04}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039809874300020286, 'epoch': 0.04}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003980975121770962, 'epoch': 0.04}         \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003980962809576213, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003980950493417806, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.0003980938173295767, 'epoch': 0.04}          \n",
      "{'loss': 0.841, 'learning_rate': 0.000398092584921012, 'epoch': 0.04}           \n",
      "{'loss': 0.8418, 'learning_rate': 0.000398091352116089, 'epoch': 0.04}          \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039809011891481005, 'epoch': 0.04}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003980888853171777, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003980876513231945, 'epoch': 0.04}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003980864169328627, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.000398085182146185, 'epoch': 0.04}          \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003980839469631638, 'epoch': 0.04}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003980827113838015, 'epoch': 0.04}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003980814754081006, 'epoch': 0.04}         \n",
      "  4%|█▎                             | 15500/351164 [3:56:04<76:44:00,  1.22it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8406, 'learning_rate': 0.0003980802390360636, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039807900226769295, 'epoch': 0.04}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039807776510299115, 'epoch': 0.04}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003980765275419607, 'epoch': 0.04}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039807528958460403, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003980740512309236, 'epoch': 0.04}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003980728124809219, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039807157333460153, 'epoch': 0.04}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.00039807033379196476, 'epoch': 0.04}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003980690938530142, 'epoch': 0.04}          \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003980678535177523, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003980666127861816, 'epoch': 0.04}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039806537165830447, 'epoch': 0.04}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003980641301341234, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039806288821364106, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003980616458968597, 'epoch': 0.04}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039806040318378193, 'epoch': 0.04}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003980591600744102, 'epoch': 0.04}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039805791656874706, 'epoch': 0.04}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039805667266679497, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003980554283685563, 'epoch': 0.04}         \n",
      "{'loss': 0.8423, 'learning_rate': 0.0003980541836740337, 'epoch': 0.04}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039805293858322956, 'epoch': 0.04}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039805169309614646, 'epoch': 0.04}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003980504472127868, 'epoch': 0.04}         \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003980492009331532, 'epoch': 0.04}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039804795425724793, 'epoch': 0.04}        \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039804670718507373, 'epoch': 0.04}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.000398045459716633, 'epoch': 0.04}          \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003980442118519281, 'epoch': 0.04}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003980429635909618, 'epoch': 0.04}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003980417149337363, 'epoch': 0.04}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039804046588025435, 'epoch': 0.04}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003980392164305183, 'epoch': 0.04}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039803796658453074, 'epoch': 0.04}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039803671634229407, 'epoch': 0.04}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003980354657038109, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039803421466908363, 'epoch': 0.04}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039803296323811485, 'epoch': 0.04}        \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039803171141090704, 'epoch': 0.04}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003980304591874627, 'epoch': 0.04}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039802920656778425, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003980279535518743, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003980267001397354, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003980254463313699, 'epoch': 0.04}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003980241921267805, 'epoch': 0.04}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003980229375259695, 'epoch': 0.04}         \n",
      "{'loss': 0.84, 'learning_rate': 0.0003980216825289396, 'epoch': 0.04}           \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003980204271356932, 'epoch': 0.04}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039801917134623283, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039801791516056096, 'epoch': 0.04}        \n",
      "{'loss': 0.8422, 'learning_rate': 0.0003980166585786803, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039801540160059305, 'epoch': 0.04}        \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039801414422630205, 'epoch': 0.04}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003980128864558096, 'epoch': 0.04}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039801162828911825, 'epoch': 0.04}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039801036972623055, 'epoch': 0.04}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039800911076714904, 'epoch': 0.04}        \n",
      "{'loss': 0.8433, 'learning_rate': 0.0003980078514118762, 'epoch': 0.04}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003980065916604146, 'epoch': 0.04}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003980053315127667, 'epoch': 0.05}         \n",
      "{'loss': 0.8388, 'learning_rate': 0.000398004070968935, 'epoch': 0.05}          \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039800281002892214, 'epoch': 0.05}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039800154869273056, 'epoch': 0.05}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003980002869603627, 'epoch': 0.05}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039799902483182134, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039799776230710874, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039799649938622754, 'epoch': 0.05}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003979952360691802, 'epoch': 0.05}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003979939723559694, 'epoch': 0.05}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039799270824659755, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039799144374106716, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003979901788393809, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039798891354154113, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003979876478475505, 'epoch': 0.05}         \n",
      "{'loss': 0.842, 'learning_rate': 0.00039798638175741146, 'epoch': 0.05}         \n",
      "{'loss': 0.8425, 'learning_rate': 0.0003979851152711265, 'epoch': 0.05}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039798384838869835, 'epoch': 0.05}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003979825811101294, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003979813134354222, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.0003979800453645793, 'epoch': 0.05}           \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039797877689760333, 'epoch': 0.05}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003979775080344967, 'epoch': 0.05}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039797623877526185, 'epoch': 0.05}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003979749691199016, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.00039797369906841826, 'epoch': 0.05}          \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039797242862081453, 'epoch': 0.05}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003979711577770929, 'epoch': 0.05}         \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003979698865372558, 'epoch': 0.05}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003979686149013059, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003979673428692458, 'epoch': 0.05}         \n",
      "{'loss': 0.839, 'learning_rate': 0.0003979660704410778, 'epoch': 0.05}          \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003979647976168047, 'epoch': 0.05}         \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003979635243964289, 'epoch': 0.05}         \n",
      "{'loss': 0.8387, 'learning_rate': 0.0003979622507799531, 'epoch': 0.05}         \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039796097676737964, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003979597023587112, 'epoch': 0.05}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039795842755395027, 'epoch': 0.05}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003979571523530995, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039795587675616135, 'epoch': 0.05}        \n",
      "  5%|█▍                             | 16000/351164 [4:03:17<79:06:01,  1.18it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<00:59,  2.35it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:19,  1.75it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:29,  1.53it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:40,  1.35it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:43,  1.31it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:05<01:48,  1.24it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:05<01:47,  1.24it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:06<01:51,  1.19it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:49,  1.20it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:50,  1.17it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:49,  1.17it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:10<01:49,  1.17it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:11<01:48,  1.17it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:11<01:46,  1.18it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:12<01:47,  1.16it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:13<01:49,  1.13it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:14<01:48,  1.13it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:15<01:47,  1.13it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:16<01:46,  1.14it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:17<01:50,  1.09it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:18<01:46,  1.12it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:18<01:40,  1.17it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:19<01:39,  1.17it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:20<01:40,  1.15it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:40,  1.14it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:22<01:42,  1.11it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:23<01:40,  1.13it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:24<01:35,  1.17it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:25<01:36,  1.15it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:25<01:34,  1.17it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:26<01:34,  1.15it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:27<01:35,  1.13it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:28<01:36,  1.11it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:29<01:31,  1.15it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:30<01:29,  1.18it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:31<01:27,  1.18it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:32<01:29,  1.16it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:33<01:32,  1.11it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:33<01:30,  1.11it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:34<01:25,  1.16it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:35<01:25,  1.15it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:36<01:25,  1.15it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:37<01:21,  1.19it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:38<01:20,  1.19it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:38<01:21,  1.17it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:39<01:18,  1.20it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:40<01:19,  1.17it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:41<01:18,  1.17it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:42<01:17,  1.17it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:43<01:16,  1.17it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:44<01:15,  1.17it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:44<01:13,  1.20it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:45<01:11,  1.21it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:46<01:10,  1.22it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:47<01:11,  1.20it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:48<01:09,  1.21it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:48<01:10,  1.19it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:49<01:10,  1.16it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:50<01:07,  1.20it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:51<01:06,  1.21it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:52<01:06,  1.19it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:53<01:04,  1.22it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:53<01:02,  1.23it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:54<01:01,  1.23it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:55<01:01,  1.22it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:56<01:02,  1.19it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:57<01:01,  1.18it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:58<01:05,  1.09it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:59<01:03,  1.11it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [01:00<01:01,  1.13it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:00<00:58,  1.17it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:01<00:57,  1.18it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:02<00:57,  1.17it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:03<00:55,  1.19it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:04<00:55,  1.18it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:05<00:54,  1.16it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:05<00:53,  1.19it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:06<00:53,  1.17it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:07<00:51,  1.19it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:08<00:50,  1.20it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:09<00:49,  1.18it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:10<00:48,  1.19it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:10<00:47,  1.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:11<00:46,  1.20it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:12<00:46,  1.18it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:13<00:45,  1.19it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:14<00:43,  1.23it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:15<00:42,  1.22it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:15<00:42,  1.20it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:16<00:41,  1.21it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:17<00:40,  1.21it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:18<00:40,  1.18it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:19<00:38,  1.22it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:20<00:37,  1.21it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:20<00:36,  1.23it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:21<00:35,  1.24it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:22<00:34,  1.23it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:23<00:34,  1.23it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:24<00:33,  1.22it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:24<00:32,  1.23it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:25<00:32,  1.18it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:26<00:31,  1.21it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:27<00:30,  1.23it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:28<00:28,  1.25it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:29<00:29,  1.19it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:29<00:28,  1.18it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:30<00:28,  1.17it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:31<00:28,  1.11it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:32<00:27,  1.12it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:33<00:26,  1.12it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:34<00:25,  1.15it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:35<00:23,  1.19it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:36<00:22,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:36<00:21,  1.18it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:37<00:20,  1.20it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:38<00:20,  1.18it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:39<00:19,  1.17it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:40<00:18,  1.17it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:41<00:17,  1.17it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:42<00:17,  1.17it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:42<00:16,  1.18it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:43<00:15,  1.18it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:44<00:14,  1.21it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:45<00:13,  1.20it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:46<00:12,  1.19it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:47<00:11,  1.19it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:47<00:10,  1.18it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:48<00:10,  1.19it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:49<00:09,  1.19it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:50<00:08,  1.16it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:51<00:07,  1.16it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:52<00:06,  1.19it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:52<00:05,  1.19it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:53<00:05,  1.19it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:54<00:04,  1.24it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:55<00:03,  1.23it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:56<00:02,  1.21it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:57<00:01,  1.21it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [01:57<00:00,  1.21it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [01:58<00:00,  1.20it/s]\u001b[ACC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8387860655784607, 'eval_cer': 0.012466396983673014, 'eval_runtime': 126.6964, 'eval_samples_per_second': 70.965, 'eval_steps_per_second': 1.113, 'epoch': 0.05}\n",
      "  5%|█▍                             | 16000/351164 [4:05:23<79:06:01,  1.18it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [01:59<00:00,  1.20it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8399, 'learning_rate': 0.00039795460076313835, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039795332437403316, 'epoch': 0.05}          \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039795204758884825, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003979507704075862, 'epoch': 0.05}         \n",
      "{'loss': 0.8429, 'learning_rate': 0.00039794949283024957, 'epoch': 0.05}        \n",
      "{'loss': 0.8414, 'learning_rate': 0.00039794821485684094, 'epoch': 0.05}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039794693648736285, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003979456577218178, 'epoch': 0.05}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039794437856020836, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003979430990025372, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039794181904880677, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039794053869901964, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039793925795317844, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003979379768112857, 'epoch': 0.05}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039793669527334394, 'epoch': 0.05}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003979354133393558, 'epoch': 0.05}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039793413100932374, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003979328482832504, 'epoch': 0.05}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039793156516113834, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039793028164299013, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039792899772880835, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039792771341859553, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039792642871235424, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039792514361008713, 'epoch': 0.05}          \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003979238581117967, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039792257221748546, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003979212859271561, 'epoch': 0.05}         \n",
      "{'loss': 0.841, 'learning_rate': 0.0003979199992408112, 'epoch': 0.05}          \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039791871215845323, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003979174246800848, 'epoch': 0.05}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003979161368057086, 'epoch': 0.05}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.000397914848535327, 'epoch': 0.05}          \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003979135598689427, 'epoch': 0.05}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003979122708065583, 'epoch': 0.05}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003979109813481764, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.0003979096914937995, 'epoch': 0.05}           \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039790840124343023, 'epoch': 0.05}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.0003979071105970711, 'epoch': 0.05}         \n",
      "{'loss': 0.8436, 'learning_rate': 0.00039790581955472475, 'epoch': 0.05}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003979045281163937, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039790323628208067, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039790194405178817, 'epoch': 0.05}          \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003979006514255187, 'epoch': 0.05}         \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039789935840327506, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003978980649850596, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.000397896771170875, 'epoch': 0.05}          \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039789547696072395, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.0003978941823546089, 'epoch': 0.05}          \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003978928873525325, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039789159195449724, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003978902961605059, 'epoch': 0.05}         \n",
      "{'loss': 0.841, 'learning_rate': 0.000397888999970561, 'epoch': 0.05}           \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039788770338466505, 'epoch': 0.05}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039788640640282076, 'epoch': 0.05}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003978851090250306, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003978838112512973, 'epoch': 0.05}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039788251308162337, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003978812145160114, 'epoch': 0.05}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.000397879915554464, 'epoch': 0.05}          \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003978786161969839, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003978773164435735, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003978760162942355, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003978747157489725, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039787341480778705, 'epoch': 0.05}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039787211347068187, 'epoch': 0.05}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003978708117376594, 'epoch': 0.05}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003978695096087224, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039786820708387333, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039786690416311496, 'epoch': 0.05}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039786560084644976, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003978642971338804, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003978629930254095, 'epoch': 0.05}         \n",
      "{'loss': 0.839, 'learning_rate': 0.00039786168852103967, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039786038362077343, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003978590783246135, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003978577726325624, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039785646654462285, 'epoch': 0.05}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039785516006079737, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003978538531810886, 'epoch': 0.05}         \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039785254590549916, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039785123823403174, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003978499301666888, 'epoch': 0.05}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003978486217034731, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039784731284438717, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.0003978460035894337, 'epoch': 0.05}           \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039784469393861524, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039784338389193446, 'epoch': 0.05}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039784207344939395, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003978407626109964, 'epoch': 0.05}         \n",
      "{'loss': 0.8413, 'learning_rate': 0.0003978394513767443, 'epoch': 0.05}         \n",
      "{'loss': 0.839, 'learning_rate': 0.0003978381397466404, 'epoch': 0.05}          \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003978368277206872, 'epoch': 0.05}         \n",
      "{'loss': 0.8383, 'learning_rate': 0.00039783551529888746, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.0003978342024812437, 'epoch': 0.05}           \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039783288926775864, 'epoch': 0.05}        \n",
      "{'loss': 0.839, 'learning_rate': 0.00039783157565843484, 'epoch': 0.05}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039783026165327495, 'epoch': 0.05}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003978289472522816, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003978276324554575, 'epoch': 0.05}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003978263172628051, 'epoch': 0.05}         \n",
      "  5%|█▍                             | 16500/351164 [4:12:34<77:30:37,  1.20it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8393, 'learning_rate': 0.0003978250016743271, 'epoch': 0.05}         \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003978236856900262, 'epoch': 0.05}         \n",
      "{'loss': 0.8439, 'learning_rate': 0.000397822369309905, 'epoch': 0.05}          \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039782105253396613, 'epoch': 0.05}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039781973536221225, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039781841779464597, 'epoch': 0.05}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003978170998312699, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039781578147208673, 'epoch': 0.05}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039781446271709904, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003978131435663095, 'epoch': 0.05}         \n",
      "{'loss': 0.8389, 'learning_rate': 0.00039781182401972076, 'epoch': 0.05}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039781050407733544, 'epoch': 0.05}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003978091837391562, 'epoch': 0.05}         \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039780786300518573, 'epoch': 0.05}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039780654187542653, 'epoch': 0.05}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039780522034988134, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039780389842855276, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039780257611144354, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039780125339855624, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003977999302898935, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039779860678545797, 'epoch': 0.05}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003977972828852524, 'epoch': 0.05}         \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039779595858927924, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039779463389754137, 'epoch': 0.05}         \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039779330881004125, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003977922484550941, 'epoch': 0.05}         \n",
      "{'loss': 0.8388, 'learning_rate': 0.00039779092265522883, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039778959645960876, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003977882698682366, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003977869428811149, 'epoch': 0.05}         \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039778561549824655, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039778428771963396, 'epoch': 0.05}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003977829595452799, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039778163097518713, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.0003977803020093581, 'epoch': 0.05}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039777897264779564, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039777764289050226, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003977763127374808, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003977749821887337, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003977736512442639, 'epoch': 0.05}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003977723199040738, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003977709881681662, 'epoch': 0.05}         \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039776965603654374, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039776832350920906, 'epoch': 0.05}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003977669905861649, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003977656572674138, 'epoch': 0.05}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039776432355295856, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039776298944280174, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.00039776165493694615, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003977603200353943, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039775898473814894, 'epoch': 0.05}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003977576490452127, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039775631295658836, 'epoch': 0.05}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.0003977549764722785, 'epoch': 0.05}         \n",
      "{'loss': 0.8418, 'learning_rate': 0.0003977536395922858, 'epoch': 0.05}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.00039775230231661296, 'epoch': 0.05}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039775096464526264, 'epoch': 0.05}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003977496265782375, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003977482881155403, 'epoch': 0.05}         \n",
      "{'loss': 0.8389, 'learning_rate': 0.00039774694925717355, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039774561000314014, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039774427035344265, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.0003977429303080837, 'epoch': 0.05}           \n",
      "{'loss': 0.8386, 'learning_rate': 0.000397741589867066, 'epoch': 0.05}          \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039774024903039233, 'epoch': 0.05}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.00039773890779806525, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.0003977375661700875, 'epoch': 0.05}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039773622414646174, 'epoch': 0.05}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039773488172719073, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003977335389122771, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003977321957017235, 'epoch': 0.05}         \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003977308520955327, 'epoch': 0.05}         \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003977295080937073, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003977281636962501, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.00039772681890316364, 'epoch': 0.05}          \n",
      "{'loss': 0.8386, 'learning_rate': 0.0003977254737144508, 'epoch': 0.05}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.000397724128130114, 'epoch': 0.05}          \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003977227821501562, 'epoch': 0.05}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039772143577458, 'epoch': 0.05}           \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003977200890033881, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039771874183658313, 'epoch': 0.05}        \n",
      "{'loss': 0.8419, 'learning_rate': 0.00039771739427416785, 'epoch': 0.05}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039771604631614493, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039771469796251707, 'epoch': 0.05}        \n",
      "{'loss': 0.8427, 'learning_rate': 0.00039771334921328704, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039771200006845744, 'epoch': 0.05}          \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039771065052803103, 'epoch': 0.05}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.0003977093005920104, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039770795026039844, 'epoch': 0.05}        \n",
      "{'loss': 0.8423, 'learning_rate': 0.00039770659953319767, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003977052484104109, 'epoch': 0.05}         \n",
      "{'loss': 0.841, 'learning_rate': 0.0003977038968920408, 'epoch': 0.05}          \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003977025449780901, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.0003977011926685614, 'epoch': 0.05}           \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039769983996345757, 'epoch': 0.05}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039769848686278125, 'epoch': 0.05}        \n",
      "{'loss': 0.8389, 'learning_rate': 0.00039769713336653507, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003976957794747218, 'epoch': 0.05}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003976944251873442, 'epoch': 0.05}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039769307050440496, 'epoch': 0.05}        \n",
      "  5%|█▌                             | 17000/351164 [4:19:50<77:19:52,  1.20it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8387, 'learning_rate': 0.0003976917154259067, 'epoch': 0.05}         \n",
      "{'loss': 0.8389, 'learning_rate': 0.0003976903599518522, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039768900408224415, 'epoch': 0.05}        \n",
      "{'loss': 0.839, 'learning_rate': 0.00039768764781708527, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003976862911563783, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039768493410012595, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039768357664833094, 'epoch': 0.05}          \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039768221880099594, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003976808605581236, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039767950191971685, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003976781428857783, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003976767834563106, 'epoch': 0.05}         \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039767542363131655, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.0003976740634107988, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.0003976727027947602, 'epoch': 0.05}           \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039767134178320335, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.000397669980376131, 'epoch': 0.05}          \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003976686185735459, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003976672563754508, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003976658937818484, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039766453079274135, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039766316740813247, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.0003976618036280245, 'epoch': 0.05}          \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039766043945242013, 'epoch': 0.05}        \n",
      "{'loss': 0.8386, 'learning_rate': 0.00039765907488132203, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039765770991473306, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003976563445526558, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039765497879509315, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003976536126420477, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039765224609352226, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039765087914951956, 'epoch': 0.05}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003976495118100423, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039764814407509323, 'epoch': 0.05}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039764677594467514, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039764540741879067, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003976440384974426, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003976426691806337, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003976412994683667, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003976399293606443, 'epoch': 0.05}         \n",
      "{'loss': 0.841, 'learning_rate': 0.00039763855885746927, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039763718795884435, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039763581666477234, 'epoch': 0.05}          \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003976344449752559, 'epoch': 0.05}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039763307289029774, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003976317004099007, 'epoch': 0.05}         \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003976303275340675, 'epoch': 0.05}         \n",
      "{'loss': 0.8385, 'learning_rate': 0.0003976289542628009, 'epoch': 0.05}         \n",
      "{'loss': 0.839, 'learning_rate': 0.00039762758059610364, 'epoch': 0.05}         \n",
      "{'loss': 0.8387, 'learning_rate': 0.00039762620653397844, 'epoch': 0.05}        \n",
      "{'loss': 0.8389, 'learning_rate': 0.00039762483207642806, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003976234572234553, 'epoch': 0.05}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003976220819750628, 'epoch': 0.05}         \n",
      "{'loss': 0.8389, 'learning_rate': 0.0003976207063312534, 'epoch': 0.05}         \n",
      "{'loss': 0.84, 'learning_rate': 0.0003976193302920298, 'epoch': 0.05}           \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039761795385739483, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039761657702735124, 'epoch': 0.05}        \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003976151998019017, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.000397613822181049, 'epoch': 0.05}          \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039761244416479586, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003976110657531452, 'epoch': 0.05}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003976096869460996, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003976083077436618, 'epoch': 0.05}         \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039760692814583477, 'epoch': 0.05}        \n",
      "{'loss': 0.8412, 'learning_rate': 0.0003976055481526211, 'epoch': 0.05}         \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039760416776402356, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.000397602786980045, 'epoch': 0.05}          \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039760140580068806, 'epoch': 0.05}        \n",
      "{'loss': 0.8421, 'learning_rate': 0.00039760002422595557, 'epoch': 0.05}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.0003975986422558504, 'epoch': 0.05}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003975972598903751, 'epoch': 0.05}          \n",
      "{'loss': 0.8422, 'learning_rate': 0.00039759587712953257, 'epoch': 0.05}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.0003975944939733255, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003975931104217568, 'epoch': 0.05}         \n",
      "{'loss': 0.8427, 'learning_rate': 0.0003975917264748291, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039759034213254524, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.000397588957394908, 'epoch': 0.05}            \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039758757226192006, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.00039758618673358423, 'epoch': 0.05}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039758480080990334, 'epoch': 0.05}        \n",
      "{'loss': 0.8424, 'learning_rate': 0.00039758341449088017, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039758202777651736, 'epoch': 0.05}          \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003975806406668178, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039757925316178424, 'epoch': 0.05}        \n",
      "{'loss': 0.8403, 'learning_rate': 0.0003975778652614195, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039757647696572626, 'epoch': 0.05}        \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039757508827470737, 'epoch': 0.05}        \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003975736991883656, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.00039757230970670365, 'epoch': 0.05}        \n",
      "{'loss': 0.8416, 'learning_rate': 0.00039757091982972446, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039756952955743064, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039756813888982515, 'epoch': 0.05}        \n",
      "{'loss': 0.839, 'learning_rate': 0.0003975667478269106, 'epoch': 0.05}          \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003975653563686899, 'epoch': 0.05}         \n",
      "{'loss': 0.8424, 'learning_rate': 0.0003975639645151657, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039756257226634083, 'epoch': 0.05}        \n",
      "{'loss': 0.842, 'learning_rate': 0.00039756117962221825, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003975597865828005, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039755839314809053, 'epoch': 0.05}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.00039755699931809103, 'epoch': 0.05}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039755560509280487, 'epoch': 0.05}        \n",
      "  5%|█▌                             | 17500/351164 [4:27:13<77:21:19,  1.20it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8395, 'learning_rate': 0.0003975542104722348, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039755281545638353, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039755142004525406, 'epoch': 0.05}        \n",
      "{'loss': 0.8409, 'learning_rate': 0.000397550024238849, 'epoch': 0.05}          \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003975486280371712, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003975472314402234, 'epoch': 0.05}         \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039754583444800854, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039754443706052926, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003975430392777884, 'epoch': 0.05}         \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003975416410997888, 'epoch': 0.05}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039754024252653324, 'epoch': 0.05}        \n",
      "{'loss': 0.8445, 'learning_rate': 0.0003975388435580245, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039753744419426535, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039753604443525873, 'epoch': 0.05}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039753464428100724, 'epoch': 0.05}        \n",
      "{'loss': 0.84, 'learning_rate': 0.00039753324373151386, 'epoch': 0.05}          \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039753184278678124, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039753044144681237, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003975290397116098, 'epoch': 0.05}         \n",
      "{'loss': 0.839, 'learning_rate': 0.00039752763758117655, 'epoch': 0.05}         \n",
      "{'loss': 0.8384, 'learning_rate': 0.00039752623505551535, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.000397524832134629, 'epoch': 0.05}          \n",
      "{'loss': 0.8389, 'learning_rate': 0.0003975234288185203, 'epoch': 0.05}         \n",
      "{'loss': 0.8384, 'learning_rate': 0.0003975220251071921, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003975206210006471, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003975192164988883, 'epoch': 0.05}         \n",
      "{'loss': 0.8383, 'learning_rate': 0.00039751781160191833, 'epoch': 0.05}        \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003975164063097401, 'epoch': 0.05}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.00039751500062235637, 'epoch': 0.05}        \n",
      "{'loss': 0.8415, 'learning_rate': 0.00039751359453977, 'epoch': 0.05}           \n",
      "{'loss': 0.8426, 'learning_rate': 0.0003975121880619838, 'epoch': 0.05}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039751078118900054, 'epoch': 0.05}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.000397509373920823, 'epoch': 0.05}          \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003975079662574541, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039750655819889666, 'epoch': 0.05}        \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003975051497451534, 'epoch': 0.05}         \n",
      "{'loss': 0.8383, 'learning_rate': 0.0003975037408962272, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039750233165212085, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003975009220128372, 'epoch': 0.05}         \n",
      "{'loss': 0.8386, 'learning_rate': 0.000397499511978379, 'epoch': 0.05}          \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003974981015487492, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039749669072395053, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003974952795039858, 'epoch': 0.05}         \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003974938678888579, 'epoch': 0.05}         \n",
      "{'loss': 0.842, 'learning_rate': 0.0003974924558785696, 'epoch': 0.05}          \n",
      "{'loss': 0.8411, 'learning_rate': 0.00039749104347312373, 'epoch': 0.05}        \n",
      "{'loss': 0.8418, 'learning_rate': 0.00039748963067252316, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039748821747677074, 'epoch': 0.05}        \n",
      "{'loss': 0.8417, 'learning_rate': 0.0003974868038858691, 'epoch': 0.05}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039748538989982135, 'epoch': 0.05}        \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003974839755186301, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039748256074229835, 'epoch': 0.05}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003974811455708287, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039747973000422423, 'epoch': 0.05}        \n",
      "{'loss': 0.8399, 'learning_rate': 0.0003974783140424877, 'epoch': 0.05}         \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003974768976856218, 'epoch': 0.05}         \n",
      "{'loss': 0.8399, 'learning_rate': 0.00039747548093362956, 'epoch': 0.05}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.00039747406378651376, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003974726462442771, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039747122830692256, 'epoch': 0.05}        \n",
      "{'loss': 0.8385, 'learning_rate': 0.00039746980997445297, 'epoch': 0.05}        \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003974683912468711, 'epoch': 0.05}         \n",
      "{'loss': 0.8384, 'learning_rate': 0.00039746697212417984, 'epoch': 0.05}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039746555260638204, 'epoch': 0.05}        \n",
      "{'loss': 0.8405, 'learning_rate': 0.0003974641326934805, 'epoch': 0.05}         \n",
      "{'loss': 0.8385, 'learning_rate': 0.0003974627123854781, 'epoch': 0.05}         \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003974612916823776, 'epoch': 0.05}         \n",
      "{'loss': 0.8397, 'learning_rate': 0.0003974598705841819, 'epoch': 0.05}         \n",
      "{'loss': 0.8387, 'learning_rate': 0.00039745844909089387, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.0003974570272025163, 'epoch': 0.05}         \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039745560491905214, 'epoch': 0.05}        \n",
      "{'loss': 0.8407, 'learning_rate': 0.0003974541822405041, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039745275916687505, 'epoch': 0.05}        \n",
      "{'loss': 0.839, 'learning_rate': 0.000397451335698168, 'epoch': 0.05}           \n",
      "{'loss': 0.8394, 'learning_rate': 0.0003974499118343856, 'epoch': 0.05}         \n",
      "{'loss': 0.8393, 'learning_rate': 0.0003974484875755307, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003974470629216063, 'epoch': 0.05}         \n",
      "{'loss': 0.8383, 'learning_rate': 0.00039744563787261515, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039744421242856015, 'epoch': 0.05}        \n",
      "{'loss': 0.8404, 'learning_rate': 0.00039744278658944405, 'epoch': 0.05}        \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003974413603552698, 'epoch': 0.05}         \n",
      "{'loss': 0.8386, 'learning_rate': 0.0003974399337260403, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039743850670175825, 'epoch': 0.05}        \n",
      "{'loss': 0.8384, 'learning_rate': 0.00039743707928242665, 'epoch': 0.05}        \n",
      "{'loss': 0.8387, 'learning_rate': 0.00039743565146804825, 'epoch': 0.05}        \n",
      "{'loss': 0.8384, 'learning_rate': 0.000397434223258626, 'epoch': 0.05}          \n",
      "{'loss': 0.8408, 'learning_rate': 0.0003974327946541627, 'epoch': 0.05}         \n",
      "{'loss': 0.8386, 'learning_rate': 0.00039743136565466124, 'epoch': 0.05}        \n",
      "{'loss': 0.8381, 'learning_rate': 0.00039742993626012437, 'epoch': 0.05}        \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039742850647055513, 'epoch': 0.05}        \n",
      "{'loss': 0.8408, 'learning_rate': 0.00039742707628595623, 'epoch': 0.05}        \n",
      "{'loss': 0.842, 'learning_rate': 0.0003974256457063306, 'epoch': 0.05}          \n",
      "{'loss': 0.8406, 'learning_rate': 0.0003974242147316812, 'epoch': 0.05}         \n",
      "{'loss': 0.8412, 'learning_rate': 0.00039742278336201065, 'epoch': 0.05}        \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039742135159732196, 'epoch': 0.05}        \n",
      "{'loss': 0.839, 'learning_rate': 0.0003974199194376181, 'epoch': 0.05}          \n",
      "{'loss': 0.8388, 'learning_rate': 0.0003974184868829017, 'epoch': 0.05}         \n",
      "{'loss': 0.8411, 'learning_rate': 0.0003974170539331758, 'epoch': 0.05}         \n",
      "{'loss': 0.8403, 'learning_rate': 0.00039741562058844324, 'epoch': 0.05}        \n",
      "{'loss': 0.8391, 'learning_rate': 0.00039741418684870677, 'epoch': 0.05}        \n",
      "  5%|█▌                             | 18000/351164 [4:34:25<75:35:05,  1.22it/s]\n",
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▌                                          | 2/141 [00:00<00:59,  2.34it/s]\u001b[A\n",
      "  2%|▉                                          | 3/141 [00:01<01:23,  1.65it/s]\u001b[A\n",
      "  3%|█▏                                         | 4/141 [00:02<01:33,  1.47it/s]\u001b[A\n",
      "  4%|█▌                                         | 5/141 [00:03<01:37,  1.39it/s]\u001b[A\n",
      "  4%|█▊                                         | 6/141 [00:04<01:58,  1.14it/s]\u001b[A\n",
      "  5%|██▏                                        | 7/141 [00:05<01:55,  1.16it/s]\u001b[A\n",
      "  6%|██▍                                        | 8/141 [00:06<01:54,  1.16it/s]\u001b[A\n",
      "  6%|██▋                                        | 9/141 [00:07<01:52,  1.17it/s]\u001b[A\n",
      "  7%|██▉                                       | 10/141 [00:07<01:54,  1.14it/s]\u001b[A\n",
      "  8%|███▎                                      | 11/141 [00:08<01:53,  1.14it/s]\u001b[A\n",
      "  9%|███▌                                      | 12/141 [00:09<01:51,  1.16it/s]\u001b[A\n",
      "  9%|███▊                                      | 13/141 [00:10<01:52,  1.13it/s]\u001b[A\n",
      " 10%|████▏                                     | 14/141 [00:11<01:48,  1.17it/s]\u001b[A\n",
      " 11%|████▍                                     | 15/141 [00:12<01:45,  1.20it/s]\u001b[A\n",
      " 11%|████▊                                     | 16/141 [00:13<01:52,  1.11it/s]\u001b[A\n",
      " 12%|█████                                     | 17/141 [00:14<01:52,  1.11it/s]\u001b[A\n",
      " 13%|█████▎                                    | 18/141 [00:15<01:49,  1.12it/s]\u001b[A\n",
      " 13%|█████▋                                    | 19/141 [00:15<01:47,  1.13it/s]\u001b[A\n",
      " 14%|█████▉                                    | 20/141 [00:16<01:46,  1.14it/s]\u001b[A\n",
      " 15%|██████▎                                   | 21/141 [00:17<01:48,  1.11it/s]\u001b[A\n",
      " 16%|██████▌                                   | 22/141 [00:18<01:44,  1.14it/s]\u001b[A\n",
      " 16%|██████▊                                   | 23/141 [00:19<01:40,  1.18it/s]\u001b[A\n",
      " 17%|███████▏                                  | 24/141 [00:20<01:38,  1.19it/s]\u001b[A\n",
      " 18%|███████▍                                  | 25/141 [00:21<01:39,  1.17it/s]\u001b[A\n",
      " 18%|███████▋                                  | 26/141 [00:21<01:39,  1.16it/s]\u001b[A\n",
      " 19%|████████                                  | 27/141 [00:22<01:39,  1.15it/s]\u001b[A\n",
      " 20%|████████▎                                 | 28/141 [00:23<01:36,  1.17it/s]\u001b[A\n",
      " 21%|████████▋                                 | 29/141 [00:24<01:34,  1.18it/s]\u001b[A\n",
      " 21%|████████▉                                 | 30/141 [00:25<01:35,  1.16it/s]\u001b[A\n",
      " 22%|█████████▏                                | 31/141 [00:26<01:34,  1.16it/s]\u001b[A\n",
      " 23%|█████████▌                                | 32/141 [00:27<01:38,  1.10it/s]\u001b[A\n",
      " 23%|█████████▊                                | 33/141 [00:28<01:39,  1.08it/s]\u001b[A\n",
      " 24%|██████████▏                               | 34/141 [00:29<01:38,  1.09it/s]\u001b[A\n",
      " 25%|██████████▍                               | 35/141 [00:29<01:33,  1.13it/s]\u001b[A\n",
      " 26%|██████████▋                               | 36/141 [00:30<01:30,  1.16it/s]\u001b[A\n",
      " 26%|███████████                               | 37/141 [00:31<01:33,  1.12it/s]\u001b[A\n",
      " 27%|███████████▎                              | 38/141 [00:32<01:30,  1.14it/s]\u001b[A\n",
      " 28%|███████████▌                              | 39/141 [00:33<01:38,  1.03it/s]\u001b[A\n",
      " 28%|███████████▉                              | 40/141 [00:34<01:33,  1.08it/s]\u001b[A\n",
      " 29%|████████████▏                             | 41/141 [00:35<01:27,  1.15it/s]\u001b[A\n",
      " 30%|████████████▌                             | 42/141 [00:36<01:32,  1.08it/s]\u001b[A\n",
      " 30%|████████████▊                             | 43/141 [00:37<01:32,  1.05it/s]\u001b[A\n",
      " 31%|█████████████                             | 44/141 [00:38<01:26,  1.13it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 45/141 [00:38<01:22,  1.17it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 46/141 [00:39<01:22,  1.15it/s]\u001b[A\n",
      " 33%|██████████████                            | 47/141 [00:40<01:17,  1.21it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 48/141 [00:41<01:18,  1.19it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 49/141 [00:42<01:16,  1.21it/s]\u001b[A\n",
      " 35%|██████████████▉                           | 50/141 [00:42<01:15,  1.21it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 51/141 [00:43<01:14,  1.21it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 52/141 [00:44<01:15,  1.18it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 53/141 [00:45<01:14,  1.19it/s]\u001b[A\n",
      " 38%|████████████████                          | 54/141 [00:46<01:12,  1.20it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 55/141 [00:47<01:12,  1.18it/s]\u001b[A\n",
      " 40%|████████████████▋                         | 56/141 [00:48<01:11,  1.19it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 57/141 [00:48<01:09,  1.21it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 58/141 [00:49<01:09,  1.20it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 59/141 [00:50<01:06,  1.23it/s]\u001b[A\n",
      " 43%|█████████████████▊                        | 60/141 [00:51<01:05,  1.25it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 61/141 [00:52<01:04,  1.25it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 62/141 [00:52<01:05,  1.21it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 63/141 [00:53<01:02,  1.25it/s]\u001b[A\n",
      " 45%|███████████████████                       | 64/141 [00:54<01:01,  1.26it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 65/141 [00:55<01:05,  1.15it/s]\u001b[A\n",
      " 47%|███████████████████▋                      | 66/141 [00:56<01:04,  1.17it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 67/141 [00:57<01:02,  1.18it/s]\u001b[A\n",
      " 48%|████████████████████▎                     | 68/141 [00:57<01:00,  1.20it/s]\u001b[A\n",
      " 49%|████████████████████▌                     | 69/141 [00:58<01:01,  1.17it/s]\u001b[A\n",
      " 50%|████████████████████▊                     | 70/141 [00:59<00:59,  1.19it/s]\u001b[A\n",
      " 50%|█████████████████████▏                    | 71/141 [01:00<00:58,  1.19it/s]\u001b[A\n",
      " 51%|█████████████████████▍                    | 72/141 [01:01<00:58,  1.18it/s]\u001b[A\n",
      " 52%|█████████████████████▋                    | 73/141 [01:02<00:58,  1.17it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 74/141 [01:03<00:57,  1.16it/s]\u001b[A\n",
      " 53%|██████████████████████▎                   | 75/141 [01:03<00:56,  1.16it/s]\u001b[A\n",
      " 54%|██████████████████████▋                   | 76/141 [01:04<00:55,  1.18it/s]\u001b[A\n",
      " 55%|██████████████████████▉                   | 77/141 [01:05<00:56,  1.13it/s]\u001b[A\n",
      " 55%|███████████████████████▏                  | 78/141 [01:06<00:56,  1.11it/s]\u001b[A\n",
      " 56%|███████████████████████▌                  | 79/141 [01:07<00:56,  1.10it/s]\u001b[A\n",
      " 57%|███████████████████████▊                  | 80/141 [01:08<00:53,  1.14it/s]\u001b[A\n",
      " 57%|████████████████████████▏                 | 81/141 [01:09<00:52,  1.15it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 82/141 [01:10<00:52,  1.12it/s]\u001b[A\n",
      " 59%|████████████████████████▋                 | 83/141 [01:11<00:50,  1.14it/s]\u001b[A\n",
      " 60%|█████████████████████████                 | 84/141 [01:11<00:50,  1.14it/s]\u001b[A\n",
      " 60%|█████████████████████████▎                | 85/141 [01:12<00:49,  1.14it/s]\u001b[A\n",
      " 61%|█████████████████████████▌                | 86/141 [01:13<00:48,  1.13it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 87/141 [01:14<00:47,  1.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▏               | 88/141 [01:15<00:45,  1.16it/s]\u001b[A\n",
      " 63%|██████████████████████████▌               | 89/141 [01:16<00:44,  1.16it/s]\u001b[A\n",
      " 64%|██████████████████████████▊               | 90/141 [01:17<00:43,  1.17it/s]\u001b[A\n",
      " 65%|███████████████████████████               | 91/141 [01:17<00:41,  1.20it/s]\u001b[A\n",
      " 65%|███████████████████████████▍              | 92/141 [01:18<00:39,  1.23it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 93/141 [01:19<00:40,  1.20it/s]\u001b[A\n",
      " 67%|████████████████████████████              | 94/141 [01:20<00:39,  1.19it/s]\u001b[A\n",
      " 67%|████████████████████████████▎             | 95/141 [01:21<00:42,  1.08it/s]\u001b[A\n",
      " 68%|████████████████████████████▌             | 96/141 [01:22<00:40,  1.11it/s]\u001b[A\n",
      " 69%|████████████████████████████▉             | 97/141 [01:23<00:38,  1.14it/s]\u001b[A\n",
      " 70%|█████████████████████████████▏            | 98/141 [01:23<00:35,  1.20it/s]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 99/141 [01:24<00:36,  1.16it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 100/141 [01:25<00:35,  1.16it/s]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 101/141 [01:26<00:34,  1.17it/s]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 102/141 [01:27<00:35,  1.11it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 103/141 [01:28<00:33,  1.12it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 104/141 [01:29<00:33,  1.10it/s]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 105/141 [01:30<00:32,  1.12it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 106/141 [01:31<00:31,  1.12it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 107/141 [01:31<00:29,  1.15it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 108/141 [01:32<00:28,  1.17it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 109/141 [01:33<00:28,  1.14it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 110/141 [01:34<00:26,  1.16it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 111/141 [01:35<00:25,  1.16it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 112/141 [01:36<00:24,  1.17it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 113/141 [01:37<00:23,  1.17it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 114/141 [01:37<00:22,  1.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 115/141 [01:38<00:22,  1.14it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 116/141 [01:39<00:22,  1.12it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 117/141 [01:40<00:21,  1.10it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 118/141 [01:41<00:21,  1.09it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 119/141 [01:42<00:19,  1.13it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 120/141 [01:43<00:18,  1.15it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 121/141 [01:44<00:16,  1.18it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 122/141 [01:45<00:16,  1.13it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 123/141 [01:45<00:15,  1.13it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 124/141 [01:46<00:14,  1.18it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 125/141 [01:47<00:13,  1.18it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 126/141 [01:48<00:13,  1.15it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 127/141 [01:49<00:11,  1.17it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 128/141 [01:50<00:11,  1.14it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 129/141 [01:51<00:10,  1.15it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 130/141 [01:51<00:09,  1.17it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 131/141 [01:52<00:08,  1.17it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 132/141 [01:53<00:08,  1.11it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 133/141 [01:54<00:06,  1.15it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 134/141 [01:55<00:06,  1.15it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 135/141 [01:56<00:05,  1.16it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 136/141 [01:56<00:04,  1.21it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 137/141 [01:57<00:03,  1.20it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 138/141 [01:58<00:02,  1.18it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 139/141 [01:59<00:01,  1.17it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 140/141 [02:00<00:00,  1.17it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 141/141 [02:01<00:00,  1.10it/s]\u001b[A[Cd]CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4 [Cd]CC[NH+](CC)[CH](CNC(=O)c1ccc2c(c1)C[CH](OC2=O)c3ccccc3)c4ccco4\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.8385326266288757, 'eval_cer': 0.01328198662780583, 'eval_runtime': 129.7811, 'eval_samples_per_second': 69.278, 'eval_steps_per_second': 1.086, 'epoch': 0.05}\n",
      "  5%|█▌                             | 18000/351164 [4:36:35<75:35:05,  1.22it/s]\n",
      "100%|█████████████████████████████████████████| 141/141 [02:02<00:00,  1.10it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "{'loss': 0.8402, 'learning_rate': 0.0003974127527139694, 'epoch': 0.05}         \n",
      "{'loss': 0.8431, 'learning_rate': 0.00039741131818423397, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.00039740988325950334, 'epoch': 0.05}        \n",
      "{'loss': 0.8402, 'learning_rate': 0.00039740844793978035, 'epoch': 0.05}        \n",
      "{'loss': 0.8394, 'learning_rate': 0.00039740701222506787, 'epoch': 0.05}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003974055761153689, 'epoch': 0.05}         \n",
      "{'loss': 0.8385, 'learning_rate': 0.0003974041396106861, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003974027027110225, 'epoch': 0.05}         \n",
      "{'loss': 0.8406, 'learning_rate': 0.00039740126541638085, 'epoch': 0.05}        \n",
      "{'loss': 0.8395, 'learning_rate': 0.0003973998277267642, 'epoch': 0.05}         \n",
      "{'loss': 0.8395, 'learning_rate': 0.00039739838964217533, 'epoch': 0.05}        \n",
      "{'loss': 0.8396, 'learning_rate': 0.0003973969511626171, 'epoch': 0.05}         \n",
      "{'loss': 0.8389, 'learning_rate': 0.0003973955122880924, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039739407301860415, 'epoch': 0.05}        \n",
      "{'loss': 0.8375, 'learning_rate': 0.00039739263335415514, 'epoch': 0.05}        \n",
      "{'loss': 0.8393, 'learning_rate': 0.0003973911932947483, 'epoch': 0.05}         \n",
      "{'loss': 0.8391, 'learning_rate': 0.0003973897528403866, 'epoch': 0.05}         \n",
      "{'loss': 0.839, 'learning_rate': 0.00039738831199107277, 'epoch': 0.05}         \n",
      "{'loss': 0.8393, 'learning_rate': 0.0003973868707468098, 'epoch': 0.05}         \n",
      "{'loss': 0.8392, 'learning_rate': 0.00039738542910760057, 'epoch': 0.05}        \n",
      "{'loss': 0.8413, 'learning_rate': 0.00039738398707344784, 'epoch': 0.05}        \n",
      "{'loss': 0.8392, 'learning_rate': 0.0003973825446443546, 'epoch': 0.05}         \n",
      "{'loss': 0.8398, 'learning_rate': 0.0003973811018203238, 'epoch': 0.05}         \n",
      "{'loss': 0.8387, 'learning_rate': 0.0003973796586013582, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.0003973782149874607, 'epoch': 0.05}         \n",
      "{'loss': 0.8401, 'learning_rate': 0.00039737677097863435, 'epoch': 0.05}        \n",
      "{'loss': 0.841, 'learning_rate': 0.0003973753265748818, 'epoch': 0.05}          \n",
      "{'loss': 0.8414, 'learning_rate': 0.0003973738817762061, 'epoch': 0.05}         \n",
      "{'loss': 0.8404, 'learning_rate': 0.0003973724365826101, 'epoch': 0.05}         \n",
      "  5%|█▌                             | 18146/351164 [4:38:43<76:51:21,  1.20it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --mixed_precision=fp16 ./run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a4e574-b9b5-48c0-98f2-6889684beee9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303e3d8-2556-482f-b4e0-33ecfc365192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
