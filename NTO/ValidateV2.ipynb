{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bada03e-21f3-4ae7-9e16-e21299250b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DefaultDataCollator\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import requests\n",
    "from evaluate import load\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, load_from_disk, load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "from transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder import shift_tokens_right\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from rdkit import Chem, RDLogger\n",
    "import os\n",
    "from rdkit.Chem import Draw\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7114495b-c962-4c21-9363-16bb4fd3f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrey20007\u001b[0m (\u001b[33mandrey2007\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240318_154208-dhuizmhp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrey2007/DoHACK/runs/dhuizmhp\" target=\"_blank\">DONUT</a></strong> to <a href=\"https://wandb.ai/andrey2007/DoHACK\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RDLogger.DisableLog('rdApp.*')  \n",
    "wandb.login(key=\"673ae6e9b51cc896110db5327738b993795fffad\")\n",
    "os.environ['WANDB_API_KEY'] = \"673ae6e9b51cc896110db5327738b993795fffad\"\n",
    "wandb.init(project='DoHACK',name='DONUT')\n",
    "cer = load('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629b4e6e-f796-4dc3-9e59-aae8081d7159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 56\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 56) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3c608e-0929-4994-8241-8dcff869be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataset_val = load_dataset(\"csv\", data_files=\"molecula_val.csv\")['train']\n",
    "#zinc20 = load_dataset('sagawa/ZINC-canonicalized')['train']\n",
    "#zinc20 = zinc20.filter(lambda x: Chem.MolFromSmiles(x['smiles']) is not None and len(x['smiles']) < 128, num_proc=12)\n",
    "#ds = molecula_130m.train_test_split(0.0002, seed=56)\n",
    "#dataset_train = ds['train']\n",
    "#dataset_val = ds['test']\n",
    "tokenizer = AutoTokenizer.from_pretrained('sagawa/PubChem-10m-t5-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8378aa-3c57-474e-82e6-56a61301153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained('solution/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a91af0c-885b-4c46-8855-4810c15ab574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionEncoderDecoderSmooth(VisionEncoderDecoderModel):\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values = None,\n",
    "        decoder_input_ids = None,\n",
    "        decoder_attention_mask = None,\n",
    "        encoder_outputs = None,\n",
    "        past_key_values = None,\n",
    "        decoder_inputs_embeds = None,\n",
    "        labels=None,\n",
    "        use_cache = None,\n",
    "        output_attentions = None,\n",
    "        output_hidden_states = True,\n",
    "        return_dict = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        kwargs_encoder = {argument: value for argument, value in kwargs.items() if not argument.startswith(\"decoder_\")}\n",
    "\n",
    "        kwargs_decoder = {\n",
    "            argument[len(\"decoder_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"decoder_\")\n",
    "        }\n",
    "\n",
    "        if encoder_outputs is None:\n",
    "            if pixel_values is None:\n",
    "                raise ValueError(\"You have to specify pixel_values\")\n",
    "\n",
    "            encoder_outputs = self.encoder(\n",
    "                pixel_values,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "                **kwargs_encoder,\n",
    "            )\n",
    "        elif isinstance(encoder_outputs, tuple):\n",
    "            encoder_outputs = BaseModelOutput(*encoder_outputs)\n",
    "\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # optionally project encoder_hidden_states\n",
    "        if (\n",
    "            self.encoder.config.hidden_size != self.decoder.config.hidden_size\n",
    "            and self.decoder.config.cross_attention_hidden_size is None\n",
    "        ):\n",
    "            encoder_hidden_states = self.enc_to_dec_proj(encoder_hidden_states)\n",
    "\n",
    "        # else:\n",
    "        encoder_attention_mask = None\n",
    "\n",
    "        if (labels is not None) and (decoder_input_ids is None and decoder_inputs_embeds is None):\n",
    "            decoder_input_ids = shift_tokens_right(\n",
    "                labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "            )\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            use_cache=use_cache,\n",
    "            past_key_values=past_key_values,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs_decoder,\n",
    "        )\n",
    "\n",
    "        # Compute loss independent from decoder (as some shift the logits inside them)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            logits = decoder_outputs.logits if return_dict else decoder_outputs[0]\n",
    "            loss_fct = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "            loss = loss_fct(logits.reshape(-1, self.decoder.config.vocab_size), labels.reshape(-1))\n",
    "            \n",
    "            \n",
    "\n",
    "        if not return_dict:\n",
    "            if loss is not None:\n",
    "                return (loss,) + decoder_outputs + encoder_outputs\n",
    "            else:\n",
    "                return decoder_outputs + encoder_outputs\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=loss,\n",
    "            logits=decoder_outputs.logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "model = VisionEncoderDecoderSmooth.from_pretrained('trocr_augment/checkpoint-170000')\n",
    "#model.decoder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240e4a04-0739-44fd-9bbd-7f585aa30c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.cls_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "model.config.eos_token_id = processor.tokenizer.eos_token_id\n",
    "model.config.max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed9d365-b266-4cf5-8f24-365ca7b11571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/albumentations/augmentations/transforms.py:1725: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "     'unscaled_prob':0.5,\n",
    "     'scales':[16,32,48,64,80,128],\n",
    "     'additionalAtomLabelPadding_start':0.0,\n",
    "     'additionalAtomLabelPadding_end':0.25,\n",
    "     'comicMode':[True,False],\n",
    "     'baseFontSize_start':0.5,\n",
    "     'baseFontSize_end':0.9,\n",
    "     'bondLineWidth_start':1,\n",
    "     'bondLineWidth_end':3,\n",
    "     'fixedBondLength_start':25,\n",
    "     'fixedBondLength_end':35,\n",
    "     'bond_prob':0.5,\n",
    "     'fixedFontSize_start':15,\n",
    "     'fixedFontSize_end':25,\n",
    "     'fron_prob':0.5,\n",
    "     'multipleBondOffset_start':0.1,\n",
    "     'multipleBondOffset_end':0.3,\n",
    "     'rotate_prob':0.5,\n",
    "     'rotate_start':-30.0,\n",
    "     'rotate_end':30.0,\n",
    "     'hard_rotate_start':-60.0,\n",
    "     'hard_rotate_end':60.0,\n",
    "     'concat_types_h':['left','right'],\n",
    "     'concat_types_v':['high','low'],\n",
    "     'resize_prob':0.25,\n",
    "     'aug_sizes':[448,448,448,384,384,320],\n",
    "     'types_unscales':['h','w','hw'],\n",
    "     'dims':['h','w']\n",
    "}\n",
    "\n",
    "pil_aug = A.Compose([\n",
    "    A.PixelDropout(p=0.25),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.RGBShift(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=6),\n",
    "        A.GaussianBlur(blur_limit=(5,5)),\n",
    "        A.Downscale(scale_min=0.99, scale_max=0.99)\n",
    "    ],p=0.1),\n",
    "    A.OneOf([\n",
    "        A.Sharpen(),\n",
    "        A.Spatter(),\n",
    "        A.RandomSnow(snow_point_lower=0.3, snow_point_upper=0.5)\n",
    "    ],p=0.1),\n",
    "    A.RandomShadow(p=0.05)\n",
    "])\n",
    "\n",
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "def draw_aug_smiles(smiles,cfg):\n",
    "    h,w = 512, 512\n",
    "    unscaled = cfg['unscaled_prob'] >= random.random()\n",
    "    if unscaled:\n",
    "      typ = random.choice(cfg['types_unscales'])\n",
    "      if typ == 'h':\n",
    "        scale = random.choice(cfg['scales'])\n",
    "        h -= scale\n",
    "      elif typ == 'w':\n",
    "        scale = random.choice(cfg['scales'])\n",
    "        w -= scale\n",
    "      elif typ == 'hw':\n",
    "        scale_h = random.choice(cfg['scales'])\n",
    "        scale_w = random.choice(cfg['scales'])\n",
    "        w -= scale_w\n",
    "        h -= scale_h\n",
    "\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    d2d = Draw.MolDraw2DCairo(h,w)\n",
    "    dopts = d2d.drawOptions()\n",
    "    dopts.useBWAtomPalette()\n",
    "\n",
    "    dopts.additionalAtomLabelPadding = random.uniform(cfg['additionalAtomLabelPadding_start'],cfg['additionalAtomLabelPadding_end'])\n",
    "    dopts.baseFontSize = random.uniform(cfg['baseFontSize_start'],cfg['baseFontSize_end'])\n",
    "    dopts.bondLineWidth = random.uniform(cfg['bondLineWidth_start'],cfg['bondLineWidth_end'])\n",
    "    dopts.comicMode = random.choice(cfg['comicMode'])\n",
    "    dopts.fixedBondLength = random.randint(cfg['fixedBondLength_start'],cfg['fixedBondLength_end']) if cfg['bond_prob'] > random.random() else -1\n",
    "    dopts.fixedFontSize = random.randint(cfg['fixedFontSize_start'],cfg['fixedFontSize_end']) if cfg['fron_prob'] > random.random() else -1\n",
    "    dopts.multipleBondOffset = random.uniform(cfg['multipleBondOffset_start'],cfg['multipleBondOffset_end'])\n",
    "    if cfg['rotate_prob'] >= random.random():\n",
    "      dopts.rotate = random.choice([random.uniform(cfg['rotate_start'],cfg['rotate_end']),\n",
    "                                    random.uniform(cfg['hard_rotate_start'],cfg['hard_rotate_end'])])\n",
    "\n",
    "    d2d.DrawMolecule(m)\n",
    "    d2d.FinishDrawing()\n",
    "    bio = BytesIO(d2d.GetDrawingText())\n",
    "    img = Image.open(bio).convert('RGB')\n",
    "\n",
    "    if unscaled:\n",
    "      if typ == 'h':\n",
    "        pallete = Image.new('RGB', (scale, w),(255, 255, 255))\n",
    "\n",
    "        if random.choice(cfg['concat_types_h']) == 'left':\n",
    "          img = get_concat_h(img,pallete)\n",
    "        else:\n",
    "          img = get_concat_h(pallete,img)\n",
    "\n",
    "      elif typ == 'w':\n",
    "        pallete = Image.new('RGB', (h, scale),(255, 255, 255))\n",
    "\n",
    "        if random.choice(cfg['concat_types_v']) == 'high':\n",
    "          img = get_concat_v(img,pallete)\n",
    "        else:\n",
    "          img = get_concat_v(pallete,img)\n",
    "\n",
    "      elif typ == 'hw':\n",
    "        if random.choice(cfg['dims']) == 'h':\n",
    "          pallete = Image.new('RGB', (scale_h, w),(255, 255, 255))\n",
    "          if random.choice(cfg['concat_types_h']) == 'left':\n",
    "            img = get_concat_h(img,pallete)\n",
    "          else:\n",
    "            img = get_concat_h(pallete,img)\n",
    "\n",
    "          pallete = Image.new('RGB', (scale_h+h, scale_w),(255, 255, 255))\n",
    "          if random.choice(cfg['concat_types_v']) == 'high':\n",
    "            img = get_concat_v(img,pallete)\n",
    "          else:\n",
    "            img = get_concat_v(pallete,img)\n",
    "\n",
    "        else:\n",
    "          pallete = Image.new('RGB', (h, scale_w),(255, 255, 255))\n",
    "          if random.choice(cfg['concat_types_v']) == 'high':\n",
    "            img = get_concat_v(img,pallete)\n",
    "          else:\n",
    "            img = get_concat_v(pallete,img)\n",
    "\n",
    "          pallete = Image.new('RGB', (scale_h, w+scale_w),(255, 255, 255))\n",
    "          if random.choice(cfg['concat_types_h']) == 'left':\n",
    "            img = get_concat_h(img,pallete)\n",
    "          else:\n",
    "            img = get_concat_h(pallete,img)\n",
    "\n",
    "    if cfg['resize_prob'] >= random.random() and not unscaled:\n",
    "      size = random.choice(cfg['aug_sizes'])\n",
    "      img = img.resize((size,size)).resize((512,512))\n",
    "\n",
    "    return img\n",
    "\n",
    "def draw_total(smile):\n",
    "    try:\n",
    "        img = draw_aug_smiles(smile,cfg)\n",
    "        img_np = pil_aug(image=np.array(img))['image']\n",
    "        img_aug = Image.fromarray(img_np)\n",
    "        return img_aug\n",
    "    except:\n",
    "        return draw_smiles('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "217a19ff-38f1-42ef-87fe-dbf4c1ee864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_smiles(smiles):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    d2d = Draw.MolDraw2DCairo(512,512)\n",
    "    dopts = d2d.drawOptions()\n",
    "    dopts.useBWAtomPalette()\n",
    "    d2d.DrawMolecule(m)\n",
    "    d2d.FinishDrawing()\n",
    "    bio = BytesIO(d2d.GetDrawingText())\n",
    "    return Image.open(bio).convert('RGB')\n",
    "\n",
    "MERGE_PROB = -1\n",
    "merge_i = 0\n",
    "ORGANIC_SET = ['B', 'C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I']\n",
    "ELEMENTS = [\n",
    "    \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\n",
    "    \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\",\n",
    "    \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\",\n",
    "    \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\",\n",
    "    \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\",\n",
    "    \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\",\n",
    "    \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\",\n",
    "    \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\",\n",
    "    \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\",\n",
    "    \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\",\n",
    "    \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\", \"Bh\", \"Hs\", \"Mt\", \"Ds\",\n",
    "    \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n",
    "]\n",
    "\n",
    "ATOMS = ORGANIC_SET + [f'[{e}]' for e in ELEMENTS]\n",
    "\n",
    "def aug_smiles(smiles):\n",
    "    global merge_i\n",
    "    \n",
    "    if False:\n",
    "        mode = random.choice(['long', 'short'])\n",
    "        if mode == 'long':\n",
    "            pass\n",
    "            #add_smiles_idx = merge_i % len_merge\n",
    "            #merge_i += 1\n",
    "            #smileses = [smiles, zinc20[add_smiles_idx]['smiles']]\n",
    "            #smileses.sort(key=len)\n",
    "            #smiles = '.'.join(smileses)\n",
    "        else:\n",
    "            count = random.randint(1, 3)\n",
    "            add_atoms = np.random.choice(ATOMS, count)\n",
    "            smileses = [smiles]\n",
    "            smileses.extend(list(add_atoms))\n",
    "            smileses.sort(key=len)\n",
    "            smiles = '.'.join(smileses)\n",
    "    #smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), kekuleSmiles=True)\n",
    "    return smiles\n",
    "\n",
    "def prepare_features(examples):\n",
    "    smileses = [ s for s in examples['smiles']]\n",
    "    images = [draw_total(s) for s in smileses]\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    target_encoding = processor.tokenizer(\n",
    "        [f'{i}' for i in smileses],\n",
    "        padding=\"longest\",\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    tokenized_examples = {'pixel_values': pixel_values}\n",
    "    labels = target_encoding.input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    tokenized_examples['labels'] = labels\n",
    "    return tokenized_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5668ea30-1e08-47ea-8294-411f8ae55eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_val = dataset_val.with_transform(\n",
    "    prepare_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97279114-9450-4415-9156-dbba683c9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    'donut_model',\n",
    "    remove_unused_columns=False,\n",
    "    save_safetensors = False,\n",
    "    evaluation_strategy = 'steps',\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    learning_rate = 4e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps = 5,\n",
    "    save_strategy = 'steps',\n",
    "    eval_steps = 2_000,\n",
    "    save_steps=2_000,\n",
    "    report_to = 'wandb',\n",
    "    gradient_accumulation_steps=4,\n",
    "    dataloader_num_workers=12,\n",
    "    lr_scheduler_type = 'cosine',\n",
    "    predict_with_generate = True,\n",
    "    save_total_limit = 10,\n",
    "    optim='adamw_torch',\n",
    "    adam_beta2 = 0.98,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259caaa3-734d-4d2c-b1ec-f4b919cf6de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/51 14:07 < 01:13, 0.05 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(preds):\n",
    "    labels, predictions = preds.label_ids, preds.predictions\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    print(labels[-1], predictions[-1])\n",
    "    y_true = [x.strip() for x in labels]\n",
    "    y_pred = [x.strip() for x in predictions]\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    return {f'cer': cer.compute(predictions=y_pred, references=y_true),'accuracy':accuracy}\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    #train_dataset = tokenized_dataset_train,\n",
    "    eval_dataset = tokenized_dataset_val,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    data_collator=DefaultDataCollator()\n",
    ")\n",
    "\n",
    "preds = trainer.evaluate(tokenized_dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a466a9-190d-4c15-a9fd-26e0075dbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150af3b-0d40-48ab-a327-9a3099db29c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
