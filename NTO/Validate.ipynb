{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bada03e-21f3-4ae7-9e16-e21299250b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DefaultDataCollator\n",
    "from PIL import Image\n",
    "import requests\n",
    "from evaluate import load\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, load_from_disk, load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "from transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder import shift_tokens_right\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from rdkit import Chem, RDLogger\n",
    "import os\n",
    "from rdkit.Chem import Draw\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7114495b-c962-4c21-9363-16bb4fd3f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrey20007\u001b[0m (\u001b[33mandrey2007\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240214_125255-2hjtjgl4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrey2007/DoHACK/runs/2hjtjgl4\" target=\"_blank\">DONUT</a></strong> to <a href=\"https://wandb.ai/andrey2007/DoHACK\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RDLogger.DisableLog('rdApp.*')  \n",
    "wandb.login(key=\"673ae6e9b51cc896110db5327738b993795fffad\")\n",
    "os.environ['WANDB_API_KEY'] = \"673ae6e9b51cc896110db5327738b993795fffad\"\n",
    "wandb.init(project='DoHACK',name='DONUT')\n",
    "cer = load('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629b4e6e-f796-4dc3-9e59-aae8081d7159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 56\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 56) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3c608e-0929-4994-8241-8dcff869be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataset_val = load_dataset(\"csv\", data_files=\"ZINC_valv2.csv\")['train']\n",
    "#zinc20 = load_dataset('sagawa/ZINC-canonicalized')['train']\n",
    "#zinc20 = zinc20.filter(lambda x: Chem.MolFromSmiles(x['smiles']) is not None and len(x['smiles']) < 128, num_proc=12)\n",
    "#ds = molecula_130m.train_test_split(0.0002, seed=56)\n",
    "#dataset_train = ds['train']\n",
    "#dataset_val = ds['test']\n",
    "tokenizer = AutoTokenizer.from_pretrained('sagawa/PubChem-10m-t5-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8378aa-3c57-474e-82e6-56a61301153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = DonutProcessor.from_pretrained('donut_modelv2/checkpoint-127500')\n",
    "processor.tokenizer= tokenizer\n",
    "processor.image_processor.size = {'height': 384, 'width': 384}#{'height': 512, 'width': 512}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a91af0c-885b-4c46-8855-4810c15ab574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "class VisionEncoderDecoderSmooth(VisionEncoderDecoderModel):\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values = None,\n",
    "        decoder_input_ids = None,\n",
    "        decoder_attention_mask = None,\n",
    "        encoder_outputs = None,\n",
    "        past_key_values = None,\n",
    "        decoder_inputs_embeds = None,\n",
    "        labels=None,\n",
    "        use_cache = None,\n",
    "        output_attentions = None,\n",
    "        output_hidden_states = True,\n",
    "        return_dict = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        kwargs_encoder = {argument: value for argument, value in kwargs.items() if not argument.startswith(\"decoder_\")}\n",
    "\n",
    "        kwargs_decoder = {\n",
    "            argument[len(\"decoder_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"decoder_\")\n",
    "        }\n",
    "\n",
    "        if encoder_outputs is None:\n",
    "            if pixel_values is None:\n",
    "                raise ValueError(\"You have to specify pixel_values\")\n",
    "\n",
    "            encoder_outputs = self.encoder(\n",
    "                pixel_values,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "                **kwargs_encoder,\n",
    "            )\n",
    "        elif isinstance(encoder_outputs, tuple):\n",
    "            encoder_outputs = BaseModelOutput(*encoder_outputs)\n",
    "\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # optionally project encoder_hidden_states\n",
    "        if (\n",
    "            self.encoder.config.hidden_size != self.decoder.config.hidden_size\n",
    "            and self.decoder.config.cross_attention_hidden_size is None\n",
    "        ):\n",
    "            encoder_hidden_states = self.enc_to_dec_proj(encoder_hidden_states)\n",
    "\n",
    "        # else:\n",
    "        encoder_attention_mask = None\n",
    "\n",
    "        if (labels is not None) and (decoder_input_ids is None and decoder_inputs_embeds is None):\n",
    "            decoder_input_ids = shift_tokens_right(\n",
    "                labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "            )\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            use_cache=use_cache,\n",
    "            past_key_values=past_key_values,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs_decoder,\n",
    "        )\n",
    "\n",
    "        # Compute loss independent from decoder (as some shift the logits inside them)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            logits = decoder_outputs.logits if return_dict else decoder_outputs[0]\n",
    "            loss_fct = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "            loss = loss_fct(logits.reshape(-1, self.decoder.config.vocab_size), labels.reshape(-1))\n",
    "            \n",
    "            \n",
    "\n",
    "        if not return_dict:\n",
    "            if loss is not None:\n",
    "                return (loss,) + decoder_outputs + encoder_outputs\n",
    "            else:\n",
    "                return decoder_outputs + encoder_outputs\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=loss,\n",
    "            logits=decoder_outputs.logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "model = VisionEncoderDecoderSmooth.from_pretrained('donut_modelv2/checkpoint-127500')\n",
    "#model.decoder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240e4a04-0739-44fd-9bbd-7f585aa30c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.cls_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "model.config.eos_token_id = processor.tokenizer.eos_token_id\n",
    "model.config.max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217a19ff-38f1-42ef-87fe-dbf4c1ee864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_smiles(smiles):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    d2d = Draw.MolDraw2DCairo(512,512)\n",
    "    dopts = d2d.drawOptions()\n",
    "    dopts.useBWAtomPalette()\n",
    "    d2d.DrawMolecule(m)\n",
    "    d2d.FinishDrawing()\n",
    "    bio = BytesIO(d2d.GetDrawingText())\n",
    "    return Image.open(bio).convert('RGB')\n",
    "\n",
    "MERGE_PROB = -1\n",
    "merge_i = 0\n",
    "ORGANIC_SET = ['B', 'C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I']\n",
    "ELEMENTS = [\n",
    "    \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\n",
    "    \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\",\n",
    "    \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\",\n",
    "    \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\",\n",
    "    \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\",\n",
    "    \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\",\n",
    "    \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\",\n",
    "    \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\",\n",
    "    \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\",\n",
    "    \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\",\n",
    "    \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\", \"Bh\", \"Hs\", \"Mt\", \"Ds\",\n",
    "    \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n",
    "]\n",
    "\n",
    "ATOMS = ORGANIC_SET + [f'[{e}]' for e in ELEMENTS]\n",
    "\n",
    "def aug_smiles(smiles):\n",
    "    global merge_i\n",
    "    \n",
    "    if False:\n",
    "        mode = random.choice(['long', 'short'])\n",
    "        if mode == 'long':\n",
    "            pass\n",
    "            #add_smiles_idx = merge_i % len_merge\n",
    "            #merge_i += 1\n",
    "            #smileses = [smiles, zinc20[add_smiles_idx]['smiles']]\n",
    "            #smileses.sort(key=len)\n",
    "            #smiles = '.'.join(smileses)\n",
    "        else:\n",
    "            count = random.randint(1, 3)\n",
    "            add_atoms = np.random.choice(ATOMS, count)\n",
    "            smileses = [smiles]\n",
    "            smileses.extend(list(add_atoms))\n",
    "            smileses.sort(key=len)\n",
    "            smiles = '.'.join(smileses)\n",
    "    #smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), kekuleSmiles=True)\n",
    "    return smiles\n",
    "\n",
    "def prepare_features(examples):\n",
    "    smileses = [ s for s in examples['smiles']]\n",
    "    images = [draw_smiles(s) for s in smileses]\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    target_encoding = processor.tokenizer(\n",
    "        [f'{i}' for i in smileses],\n",
    "        padding=\"longest\",\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    tokenized_examples = {'pixel_values': pixel_values}\n",
    "    labels = target_encoding.input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    tokenized_examples['labels'] = labels\n",
    "    return tokenized_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5668ea30-1e08-47ea-8294-411f8ae55eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_val = dataset_val.with_transform(\n",
    "    prepare_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97279114-9450-4415-9156-dbba683c9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    'donut_model',\n",
    "    remove_unused_columns=False,\n",
    "    save_safetensors = False,\n",
    "    evaluation_strategy = 'steps',\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    learning_rate = 4e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps = 5,\n",
    "    save_strategy = 'steps',\n",
    "    eval_steps = 2_000,\n",
    "    save_steps=2_000,\n",
    "    report_to = 'wandb',\n",
    "    gradient_accumulation_steps=4,\n",
    "    dataloader_num_workers=12,\n",
    "    lr_scheduler_type = 'cosine',\n",
    "    predict_with_generate = True,\n",
    "    save_total_limit = 10,\n",
    "    optim='adamw_torch',\n",
    "    adam_beta2 = 0.98,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259caaa3-734d-4d2c-b1ec-f4b919cf6de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cc1nc2sccn2c1C(=O)N1CCC2(CN(C(=O)c3[nH]nc(C4CC4)c3F)CCO2)C1 Cc1nc2sccn2c1C(=O)N1CCC2(CN(C(=O)c3[nH]nc(C4CC4)c3F)CCO2)C1\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(preds):\n",
    "    labels, predictions = preds.label_ids, preds.predictions\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    print(labels[-1], predictions[-1])\n",
    "    y_true = [x.strip() for x in labels]\n",
    "    y_pred = [x.strip() for x in predictions]\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    return {f'cer': cer.compute(predictions=y_pred, references=y_true),'accuracy':accuracy}\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    #train_dataset = tokenized_dataset_train,\n",
    "    eval_dataset = tokenized_dataset_val,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    data_collator=DefaultDataCollator()\n",
    ")\n",
    "\n",
    "preds = trainer.predict(tokenized_dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2834dc3a-2281-4e79-a333-ec52b00ec650",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.predictions\n",
    "predictions[predictions < 0] = 0\n",
    "test_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5cd2bec-d301-4439-b7e1-e979d971049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ZINC_valv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "156f2863-71fd-4e9b-b5c2-a1b1f80404ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_sym1 = df['smiles'][4][34:35]\n",
    "del_sym2 = df['smiles'][4][38:39]\n",
    "prepared_test = [x.replace(del_sym1,'').replace(del_sym2,'') for x in df['smiles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "720ce9e8-e30f-4227-8b17-bd39021839ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620de68b-4e5a-4a91-b72b-e149a7e67c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332639989599844"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prepared_test,test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e55662-bac8-4e43-839c-3ad0fc7d462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016764173730922375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import cer\n",
    "np.mean([cer(y_t,y_p) for y_t,y_p in zip(prepared_test,test_preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93cf2d62-9ca1-4300-8a4f-36ab99918f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:20_000].to_csv('new_val.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9240e9b5-0dd9-48ec-a539-a35281c633fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prepared_test[:20_000],test_preds[:20_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70176752-d3ba-45ab-878b-83bac1560fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01805624625772689"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import cer\n",
    "np.mean([cer(y_t,y_p) for y_t,y_p in zip(prepared_test[:20_000],test_preds[:20_000])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b44266cb-1e50-447f-8b4d-33acd6d9d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_ast_preds = pd.read_csv('AlexAst_newVal2.csv')[:20_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc68ceb1-dd63-4988-aea6-8f7d24905077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96515"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prepared_test[:20_000],alex_ast_preds[:20_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1999483f-fdbf-44af-8ec8-5f205617418d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008770892340006468"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import cer\n",
    "np.mean([cer(y_t,y_p) for y_t,y_p in zip(prepared_test[:20_000],alex_ast_preds[:20_000]['smiles'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "090966fe-b233-4615-a0f5-e488e4c95f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1ncoc1C(=O)N1CCOC(CNC(=O)C#CC(C)C)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1ccc(OCc2nnc(N3CCN(C)C(=O)C3C)n2CCC2(O)CCOCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COC(=O)CSCC(=O)N1CCCCC1c1cc(NC(=O)C2CCCC(C(=O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=CCN(C(=O)c1cc(S(=O)(=O)N(C)Cc2ccccc2)ccc1Cl)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1nccn1C(C)C(=O)N1CCOC2(CCN(C(=O)C=CC(=O)NC3C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Cc1ccc(C(=O)NC2C3COCC2CN(C(=O)c2ccc(OC(F)F)cc2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Cc1nnc(CC(=O)NC2C3COCC2CN(C(=O)COc2ccccc2C)C3)o1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>C=CCn1cccc1C(=O)N(C)C1CC[NH+](C(C)C(=O)NC)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>CCC(C)NC(=O)c1cccc(CNc2ccc(C(=O)c3nccn3C)cc2[N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>O=C1NCCn2nc(C(=O)N3CCCCC3C3CCN(C(=O)C4CCc5ccoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  smiles\n",
       "0                 Cc1ncoc1C(=O)N1CCOC(CNC(=O)C#CC(C)C)C1\n",
       "1      Cc1ccc(OCc2nnc(N3CCN(C)C(=O)C3C)n2CCC2(O)CCOCC...\n",
       "2      COC(=O)CSCC(=O)N1CCCCC1c1cc(NC(=O)C2CCCC(C(=O)...\n",
       "3      C=CCN(C(=O)c1cc(S(=O)(=O)N(C)Cc2ccccc2)ccc1Cl)...\n",
       "4      Cc1nccn1C(C)C(=O)N1CCOC2(CCN(C(=O)C=CC(=O)NC3C...\n",
       "...                                                  ...\n",
       "19995  Cc1ccc(C(=O)NC2C3COCC2CN(C(=O)c2ccc(OC(F)F)cc2...\n",
       "19996   Cc1nnc(CC(=O)NC2C3COCC2CN(C(=O)COc2ccccc2C)C3)o1\n",
       "19997       C=CCn1cccc1C(=O)N(C)C1CC[NH+](C(C)C(=O)NC)C1\n",
       "19998  CCC(C)NC(=O)c1cccc(CNc2ccc(C(=O)c3nccn3C)cc2[N...\n",
       "19999  O=C1NCCn2nc(C(=O)N3CCCCC3C3CCN(C(=O)C4CCc5ccoc...\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_ast_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a466a9-190d-4c15-a9fd-26e0075dbe32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
